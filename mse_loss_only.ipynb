{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f73b9994-d2e1-41fe-aaee-07d7f139cfcf",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "858e238c-3336-4532-84b3-998ec097d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from unet import *\n",
    "from train import *\n",
    "from loss import *\n",
    "\n",
    "base_path = \"gs://leap-persistent/YueWang/SSH/data\"\n",
    "\n",
    "def open_zarr(path):\n",
    "    return xr.open_zarr(path, consolidated=True)\n",
    "\n",
    "train = open_zarr(f\"{base_path}/train_80_sst.zarr\").compute()\n",
    "val = open_zarr(f\"{base_path}/val_80_sst.zarr\").compute()\n",
    "zca = open_zarr(f\"{base_path}/zca_80_sst.zarr\").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21c1c780-b5d2-4667-92f2-4645c22d50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(tensor, min_values=None, max_values=None, feature_range=(0, 1)):\n",
    "\n",
    "    num_channels = tensor.shape[1]\n",
    "    \n",
    "    if min_values is None:\n",
    "        min_values = torch.zeros(num_channels, device=tensor.device)\n",
    "        for c in range(num_channels):\n",
    "            min_values[c] = tensor[:, c, :, :].min()\n",
    "    \n",
    "    if max_values is None:\n",
    "        max_values = torch.zeros(num_channels, device=tensor.device)\n",
    "        for c in range(num_channels):\n",
    "            max_values[c] = tensor[:, c, :, :].max()\n",
    "    \n",
    "    normalized_tensor = torch.zeros_like(tensor)\n",
    "    scale = (feature_range[1] - feature_range[0])\n",
    "    \n",
    "    # Normalize each channel independently\n",
    "    for c in range(num_channels):\n",
    "        channel_range = max_values[c] - min_values[c]\n",
    "        \n",
    "        # Handle edge case where min and max are the same\n",
    "        if channel_range == 0:\n",
    "            normalized_tensor[:, c, :, :] = feature_range[0]\n",
    "        else:\n",
    "            # Apply min-max formula: (x - min) / (max - min) * scale + min_range\n",
    "            normalized_tensor[:, c, :, :] = (\n",
    "                (tensor[:, c, :, :] - min_values[c]) / channel_range\n",
    "            ) * scale + feature_range[0]\n",
    "    \n",
    "    return normalized_tensor, min_values, max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "927b5d79-a48d-4ce0-88c7-9744d909c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Prepare training data\n",
    "x_train_channel_0 = torch.from_numpy(train.ssh.values).float().unsqueeze(1).to(device)\n",
    "x_train_channel_1 = torch.from_numpy(train.sst.values).float().unsqueeze(1).to(device)\n",
    "x_train = torch.cat([x_train_channel_0, x_train_channel_1], dim=1)\n",
    "x_train_normalized, min_values, max_values = min_max_normalize(x_train)\n",
    "\n",
    "y_train_channel_0 = torch.from_numpy(train.ubm.values).float().unsqueeze(1).to(device)\n",
    "y_train_channel_1 = torch.from_numpy(train.zca_ubm.values).float().unsqueeze(1).to(device)\n",
    "y_train = torch.cat([y_train_channel_0, y_train_channel_1], dim=1)\n",
    "\n",
    "# Prepare validation data \n",
    "x_val_channel_0 = torch.from_numpy(val.ssh.values).float().unsqueeze(1).to(device)\n",
    "x_val_channel_1 = torch.from_numpy(val.sst.values).float().unsqueeze(1).to(device)\n",
    "x_val = torch.cat([x_val_channel_0, x_val_channel_1], dim=1)\n",
    "x_val_normalized, _, _ = min_max_normalize(x_val, min_values=min_values, max_values=max_values)\n",
    "\n",
    "y_val_channel_0 = torch.from_numpy(val.ubm.values).float().unsqueeze(1).to(device)\n",
    "y_val_channel_1 = torch.from_numpy(val.zca_ubm.values).float().unsqueeze(1).to(device)  # Add this!\n",
    "y_val = torch.cat([y_val_channel_0, y_val_channel_1], dim=1)  # Concatenate both channels\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(x_train_normalized, y_train)\n",
    "val_dataset = TensorDataset(x_val_normalized, y_val)  # Now both have 2 channels\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "Vt = torch.from_numpy(zca.zca_Vt_ubm.values).float().to(device)\n",
    "scale = torch.from_numpy(zca.zca_scale_ubm.values).float().to(device)\n",
    "mean = torch.from_numpy(zca.zca_mean_ubm.values).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20388e9-fe72-46ad-b9ad-56d79ce36828",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc2209e8-1b02-4892-8039-25d81c196df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 8.71e-05 (ZCA-NLL: 5.93e-01, MSE-Phys: 8.71e-05, Grad-Phys: 2.34e-04), Val Loss: 2.32e+00, Epoch Time: 127.99s\n",
      "Best model so far saved at epoch 1 (Val Loss: 2.324e+00)\n",
      "Epoch 2, Train Loss: 7.12e-05 (ZCA-NLL: 5.83e-01, MSE-Phys: 7.12e-05, Grad-Phys: 2.21e-04), Val Loss: 2.32e+00, Epoch Time: 125.48s\n",
      "Best model so far saved at epoch 2 (Val Loss: 2.321e+00)\n",
      "Epoch 3, Train Loss: 6.65e-05 (ZCA-NLL: 5.61e-01, MSE-Phys: 6.65e-05, Grad-Phys: 2.15e-04), Val Loss: 2.32e+00, Epoch Time: 125.69s\n",
      "Best model so far saved at epoch 3 (Val Loss: 2.319e+00)\n",
      "Epoch 4, Train Loss: 6.38e-05 (ZCA-NLL: 5.51e-01, MSE-Phys: 6.38e-05, Grad-Phys: 2.12e-04), Val Loss: 2.32e+00, Epoch Time: 125.83s\n",
      "Best model so far saved at epoch 4 (Val Loss: 2.316e+00)\n",
      "Epoch 5, Train Loss: 6.08e-05 (ZCA-NLL: 5.41e-01, MSE-Phys: 6.08e-05, Grad-Phys: 2.09e-04), Val Loss: 2.31e+00, Epoch Time: 125.74s\n",
      "Best model so far saved at epoch 5 (Val Loss: 2.315e+00)\n",
      "Epoch 6, Train Loss: 5.82e-05 (ZCA-NLL: 5.33e-01, MSE-Phys: 5.82e-05, Grad-Phys: 2.06e-04), Val Loss: 2.31e+00, Epoch Time: 125.95s\n",
      "Best model so far saved at epoch 6 (Val Loss: 2.314e+00)\n",
      "Epoch 7, Train Loss: 5.58e-05 (ZCA-NLL: 5.25e-01, MSE-Phys: 5.58e-05, Grad-Phys: 2.04e-04), Val Loss: 2.31e+00, Epoch Time: 125.81s\n",
      "Best model so far saved at epoch 7 (Val Loss: 2.313e+00)\n",
      "Epoch 8, Train Loss: 5.40e-05 (ZCA-NLL: 5.22e-01, MSE-Phys: 5.40e-05, Grad-Phys: 2.03e-04), Val Loss: 2.31e+00, Epoch Time: 125.73s\n",
      "Best model so far saved at epoch 8 (Val Loss: 2.313e+00)\n",
      "Epoch 9, Train Loss: 5.04e-05 (ZCA-NLL: 5.19e-01, MSE-Phys: 5.04e-05, Grad-Phys: 1.99e-04), Val Loss: 2.31e+00, Epoch Time: 125.87s\n",
      "Best model so far saved at epoch 9 (Val Loss: 2.313e+00)\n",
      "Epoch 10, Train Loss: 4.69e-05 (ZCA-NLL: 5.18e-01, MSE-Phys: 4.69e-05, Grad-Phys: 1.96e-04), Val Loss: 2.31e+00, Epoch Time: 125.96s\n",
      "Best model so far saved at epoch 10 (Val Loss: 2.313e+00)\n",
      "Epoch 11, Train Loss: 4.41e-05 (ZCA-NLL: 5.16e-01, MSE-Phys: 4.41e-05, Grad-Phys: 1.94e-04), Val Loss: 2.31e+00, Epoch Time: 125.70s\n",
      "Patience counter: 1/50\n",
      "Epoch 12, Train Loss: 4.11e-05 (ZCA-NLL: 5.15e-01, MSE-Phys: 4.11e-05, Grad-Phys: 1.91e-04), Val Loss: 2.31e+00, Epoch Time: 125.72s\n",
      "Best model so far saved at epoch 12 (Val Loss: 2.312e+00)\n",
      "Epoch 13, Train Loss: 3.81e-05 (ZCA-NLL: 5.15e-01, MSE-Phys: 3.81e-05, Grad-Phys: 1.88e-04), Val Loss: 2.31e+00, Epoch Time: 125.64s\n",
      "Patience counter: 1/50\n",
      "Epoch 14, Train Loss: 3.58e-05 (ZCA-NLL: 5.14e-01, MSE-Phys: 3.58e-05, Grad-Phys: 1.85e-04), Val Loss: 2.31e+00, Epoch Time: 125.76s\n",
      "Patience counter: 2/50\n",
      "Epoch 15, Train Loss: 3.35e-05 (ZCA-NLL: 5.15e-01, MSE-Phys: 3.35e-05, Grad-Phys: 1.83e-04), Val Loss: 2.31e+00, Epoch Time: 125.67s\n",
      "Patience counter: 3/50\n",
      "Epoch 16, Train Loss: 3.14e-05 (ZCA-NLL: 5.15e-01, MSE-Phys: 3.14e-05, Grad-Phys: 1.80e-04), Val Loss: 2.31e+00, Epoch Time: 125.57s\n",
      "Best model so far saved at epoch 16 (Val Loss: 2.312e+00)\n",
      "Epoch 17, Train Loss: 2.95e-05 (ZCA-NLL: 5.14e-01, MSE-Phys: 2.95e-05, Grad-Phys: 1.78e-04), Val Loss: 2.31e+00, Epoch Time: 125.53s\n",
      "Best model so far saved at epoch 17 (Val Loss: 2.312e+00)\n",
      "Epoch 18, Train Loss: 2.79e-05 (ZCA-NLL: 5.14e-01, MSE-Phys: 2.79e-05, Grad-Phys: 1.76e-04), Val Loss: 2.31e+00, Epoch Time: 125.72s\n",
      "Best model so far saved at epoch 18 (Val Loss: 2.311e+00)\n",
      "Epoch 19, Train Loss: 2.64e-05 (ZCA-NLL: 5.13e-01, MSE-Phys: 2.64e-05, Grad-Phys: 1.74e-04), Val Loss: 2.31e+00, Epoch Time: 125.73s\n",
      "Best model so far saved at epoch 19 (Val Loss: 2.311e+00)\n",
      "Epoch 20, Train Loss: 2.49e-05 (ZCA-NLL: 5.13e-01, MSE-Phys: 2.49e-05, Grad-Phys: 1.72e-04), Val Loss: 2.31e+00, Epoch Time: 125.75s\n",
      "Best model so far saved at epoch 20 (Val Loss: 2.311e+00)\n",
      "Epoch 21, Train Loss: 2.36e-05 (ZCA-NLL: 5.12e-01, MSE-Phys: 2.36e-05, Grad-Phys: 1.70e-04), Val Loss: 2.31e+00, Epoch Time: 125.45s\n",
      "Best model so far saved at epoch 21 (Val Loss: 2.311e+00)\n",
      "Epoch 22, Train Loss: 2.24e-05 (ZCA-NLL: 5.12e-01, MSE-Phys: 2.24e-05, Grad-Phys: 1.68e-04), Val Loss: 2.31e+00, Epoch Time: 125.67s\n",
      "Best model so far saved at epoch 22 (Val Loss: 2.310e+00)\n",
      "Epoch 23, Train Loss: 2.14e-05 (ZCA-NLL: 5.11e-01, MSE-Phys: 2.14e-05, Grad-Phys: 1.66e-04), Val Loss: 2.31e+00, Epoch Time: 125.41s\n",
      "Best model so far saved at epoch 23 (Val Loss: 2.309e+00)\n",
      "Epoch 24, Train Loss: 2.04e-05 (ZCA-NLL: 5.10e-01, MSE-Phys: 2.04e-05, Grad-Phys: 1.64e-04), Val Loss: 2.31e+00, Epoch Time: 125.66s\n",
      "Best model so far saved at epoch 24 (Val Loss: 2.309e+00)\n",
      "Epoch 25, Train Loss: 1.96e-05 (ZCA-NLL: 5.10e-01, MSE-Phys: 1.96e-05, Grad-Phys: 1.62e-04), Val Loss: 2.31e+00, Epoch Time: 125.69s\n",
      "Best model so far saved at epoch 25 (Val Loss: 2.309e+00)\n",
      "Epoch 26, Train Loss: 1.87e-05 (ZCA-NLL: 5.10e-01, MSE-Phys: 1.87e-05, Grad-Phys: 1.60e-04), Val Loss: 2.31e+00, Epoch Time: 125.75s\n",
      "Best model so far saved at epoch 26 (Val Loss: 2.308e+00)\n",
      "Epoch 27, Train Loss: 1.81e-05 (ZCA-NLL: 5.10e-01, MSE-Phys: 1.81e-05, Grad-Phys: 1.58e-04), Val Loss: 2.31e+00, Epoch Time: 125.71s\n",
      "Best model so far saved at epoch 27 (Val Loss: 2.307e+00)\n",
      "Epoch 28, Train Loss: 1.73e-05 (ZCA-NLL: 5.09e-01, MSE-Phys: 1.73e-05, Grad-Phys: 1.55e-04), Val Loss: 2.31e+00, Epoch Time: 125.57s\n",
      "Best model so far saved at epoch 28 (Val Loss: 2.306e+00)\n",
      "Epoch 29, Train Loss: 1.66e-05 (ZCA-NLL: 5.09e-01, MSE-Phys: 1.66e-05, Grad-Phys: 1.52e-04), Val Loss: 2.30e+00, Epoch Time: 125.76s\n",
      "Best model so far saved at epoch 29 (Val Loss: 2.305e+00)\n",
      "Epoch 30, Train Loss: 1.59e-05 (ZCA-NLL: 5.08e-01, MSE-Phys: 1.59e-05, Grad-Phys: 1.48e-04), Val Loss: 2.30e+00, Epoch Time: 125.74s\n",
      "Best model so far saved at epoch 30 (Val Loss: 2.303e+00)\n",
      "Epoch 31, Train Loss: 1.52e-05 (ZCA-NLL: 5.08e-01, MSE-Phys: 1.52e-05, Grad-Phys: 1.43e-04), Val Loss: 2.30e+00, Epoch Time: 125.62s\n",
      "Best model so far saved at epoch 31 (Val Loss: 2.301e+00)\n",
      "Epoch 32, Train Loss: 1.46e-05 (ZCA-NLL: 5.08e-01, MSE-Phys: 1.46e-05, Grad-Phys: 1.39e-04), Val Loss: 2.30e+00, Epoch Time: 125.86s\n",
      "Best model so far saved at epoch 32 (Val Loss: 2.299e+00)\n",
      "Epoch 33, Train Loss: 1.40e-05 (ZCA-NLL: 5.07e-01, MSE-Phys: 1.40e-05, Grad-Phys: 1.36e-04), Val Loss: 2.30e+00, Epoch Time: 125.62s\n",
      "Best model so far saved at epoch 33 (Val Loss: 2.297e+00)\n",
      "Epoch 34, Train Loss: 1.35e-05 (ZCA-NLL: 5.07e-01, MSE-Phys: 1.35e-05, Grad-Phys: 1.32e-04), Val Loss: 2.30e+00, Epoch Time: 125.61s\n",
      "Best model so far saved at epoch 34 (Val Loss: 2.296e+00)\n",
      "Epoch 35, Train Loss: 1.31e-05 (ZCA-NLL: 5.06e-01, MSE-Phys: 1.31e-05, Grad-Phys: 1.30e-04), Val Loss: 2.29e+00, Epoch Time: 125.61s\n",
      "Best model so far saved at epoch 35 (Val Loss: 2.294e+00)\n",
      "Epoch 36, Train Loss: 1.26e-05 (ZCA-NLL: 5.06e-01, MSE-Phys: 1.26e-05, Grad-Phys: 1.27e-04), Val Loss: 2.29e+00, Epoch Time: 125.60s\n",
      "Best model so far saved at epoch 36 (Val Loss: 2.292e+00)\n",
      "Epoch 37, Train Loss: 1.23e-05 (ZCA-NLL: 5.06e-01, MSE-Phys: 1.23e-05, Grad-Phys: 1.25e-04), Val Loss: 2.29e+00, Epoch Time: 125.60s\n",
      "Best model so far saved at epoch 37 (Val Loss: 2.292e+00)\n",
      "Epoch 38, Train Loss: 1.19e-05 (ZCA-NLL: 5.05e-01, MSE-Phys: 1.19e-05, Grad-Phys: 1.23e-04), Val Loss: 2.29e+00, Epoch Time: 125.73s\n",
      "Best model so far saved at epoch 38 (Val Loss: 2.290e+00)\n",
      "Epoch 39, Train Loss: 1.16e-05 (ZCA-NLL: 5.05e-01, MSE-Phys: 1.16e-05, Grad-Phys: 1.22e-04), Val Loss: 2.29e+00, Epoch Time: 125.63s\n",
      "Best model so far saved at epoch 39 (Val Loss: 2.288e+00)\n",
      "Epoch 40, Train Loss: 1.13e-05 (ZCA-NLL: 5.05e-01, MSE-Phys: 1.13e-05, Grad-Phys: 1.20e-04), Val Loss: 2.29e+00, Epoch Time: 125.59s\n",
      "Patience counter: 1/50\n",
      "Epoch 41, Train Loss: 1.09e-05 (ZCA-NLL: 5.05e-01, MSE-Phys: 1.09e-05, Grad-Phys: 1.18e-04), Val Loss: 2.29e+00, Epoch Time: 125.70s\n",
      "Best model so far saved at epoch 41 (Val Loss: 2.286e+00)\n",
      "Epoch 42, Train Loss: 1.07e-05 (ZCA-NLL: 5.05e-01, MSE-Phys: 1.07e-05, Grad-Phys: 1.17e-04), Val Loss: 2.29e+00, Epoch Time: 125.55s\n",
      "Patience counter: 1/50\n",
      "Epoch 43, Train Loss: 1.04e-05 (ZCA-NLL: 5.04e-01, MSE-Phys: 1.04e-05, Grad-Phys: 1.16e-04), Val Loss: 2.28e+00, Epoch Time: 125.55s\n",
      "Best model so far saved at epoch 43 (Val Loss: 2.284e+00)\n",
      "Epoch 44, Train Loss: 1.01e-05 (ZCA-NLL: 5.04e-01, MSE-Phys: 1.01e-05, Grad-Phys: 1.15e-04), Val Loss: 2.28e+00, Epoch Time: 125.49s\n",
      "Best model so far saved at epoch 44 (Val Loss: 2.284e+00)\n",
      "Epoch 45, Train Loss: 9.96e-06 (ZCA-NLL: 5.04e-01, MSE-Phys: 9.96e-06, Grad-Phys: 1.14e-04), Val Loss: 2.28e+00, Epoch Time: 125.76s\n",
      "Patience counter: 1/50\n",
      "Epoch 46, Train Loss: 9.82e-06 (ZCA-NLL: 5.04e-01, MSE-Phys: 9.82e-06, Grad-Phys: 1.13e-04), Val Loss: 2.28e+00, Epoch Time: 125.78s\n",
      "Best model so far saved at epoch 46 (Val Loss: 2.282e+00)\n",
      "Epoch 47, Train Loss: 9.50e-06 (ZCA-NLL: 5.03e-01, MSE-Phys: 9.50e-06, Grad-Phys: 1.12e-04), Val Loss: 2.28e+00, Epoch Time: 125.62s\n",
      "Patience counter: 1/50\n",
      "Epoch 48, Train Loss: 9.40e-06 (ZCA-NLL: 5.03e-01, MSE-Phys: 9.40e-06, Grad-Phys: 1.11e-04), Val Loss: 2.28e+00, Epoch Time: 125.57s\n",
      "Patience counter: 2/50\n",
      "Epoch 49, Train Loss: 9.19e-06 (ZCA-NLL: 5.03e-01, MSE-Phys: 9.19e-06, Grad-Phys: 1.11e-04), Val Loss: 2.28e+00, Epoch Time: 125.57s\n",
      "Best model so far saved at epoch 49 (Val Loss: 2.281e+00)\n",
      "Epoch 50, Train Loss: 9.02e-06 (ZCA-NLL: 5.03e-01, MSE-Phys: 9.02e-06, Grad-Phys: 1.10e-04), Val Loss: 2.28e+00, Epoch Time: 125.66s\n",
      "Best model so far saved at epoch 50 (Val Loss: 2.281e+00)\n",
      "Epoch 51, Train Loss: 8.88e-06 (ZCA-NLL: 5.03e-01, MSE-Phys: 8.88e-06, Grad-Phys: 1.09e-04), Val Loss: 2.28e+00, Epoch Time: 125.67s\n",
      "Patience counter: 1/50\n",
      "Epoch 52, Train Loss: 8.73e-06 (ZCA-NLL: 5.03e-01, MSE-Phys: 8.73e-06, Grad-Phys: 1.09e-04), Val Loss: 2.28e+00, Epoch Time: 125.74s\n",
      "Patience counter: 2/50\n",
      "Epoch 53, Train Loss: 8.54e-06 (ZCA-NLL: 5.03e-01, MSE-Phys: 8.54e-06, Grad-Phys: 1.08e-04), Val Loss: 2.28e+00, Epoch Time: 125.65s\n",
      "Best model so far saved at epoch 53 (Val Loss: 2.280e+00)\n",
      "Epoch 54, Train Loss: 8.43e-06 (ZCA-NLL: 5.02e-01, MSE-Phys: 8.43e-06, Grad-Phys: 1.07e-04), Val Loss: 2.28e+00, Epoch Time: 125.57s\n",
      "Best model so far saved at epoch 54 (Val Loss: 2.280e+00)\n",
      "Epoch 55, Train Loss: 8.27e-06 (ZCA-NLL: 5.02e-01, MSE-Phys: 8.27e-06, Grad-Phys: 1.07e-04), Val Loss: 2.28e+00, Epoch Time: 125.51s\n",
      "Patience counter: 1/50\n",
      "Epoch 56, Train Loss: 8.19e-06 (ZCA-NLL: 5.02e-01, MSE-Phys: 8.19e-06, Grad-Phys: 1.06e-04), Val Loss: 2.28e+00, Epoch Time: 125.69s\n",
      "Best model so far saved at epoch 56 (Val Loss: 2.279e+00)\n",
      "Epoch 57, Train Loss: 8.05e-06 (ZCA-NLL: 5.02e-01, MSE-Phys: 8.05e-06, Grad-Phys: 1.06e-04), Val Loss: 2.28e+00, Epoch Time: 125.58s\n",
      "Best model so far saved at epoch 57 (Val Loss: 2.279e+00)\n",
      "Epoch 58, Train Loss: 7.89e-06 (ZCA-NLL: 5.02e-01, MSE-Phys: 7.89e-06, Grad-Phys: 1.05e-04), Val Loss: 2.28e+00, Epoch Time: 125.69s\n",
      "Best model so far saved at epoch 58 (Val Loss: 2.278e+00)\n",
      "Epoch 59, Train Loss: 7.83e-06 (ZCA-NLL: 5.02e-01, MSE-Phys: 7.83e-06, Grad-Phys: 1.05e-04), Val Loss: 2.28e+00, Epoch Time: 125.76s\n",
      "Best model so far saved at epoch 59 (Val Loss: 2.278e+00)\n",
      "Epoch 60, Train Loss: 7.69e-06 (ZCA-NLL: 5.02e-01, MSE-Phys: 7.69e-06, Grad-Phys: 1.04e-04), Val Loss: 2.28e+00, Epoch Time: 125.62s\n",
      "Patience counter: 1/50\n",
      "Epoch 61, Train Loss: 7.57e-06 (ZCA-NLL: 5.02e-01, MSE-Phys: 7.57e-06, Grad-Phys: 1.03e-04), Val Loss: 2.28e+00, Epoch Time: 125.46s\n",
      "Best model so far saved at epoch 61 (Val Loss: 2.276e+00)\n",
      "Epoch 62, Train Loss: 7.49e-06 (ZCA-NLL: 5.02e-01, MSE-Phys: 7.49e-06, Grad-Phys: 1.03e-04), Val Loss: 2.28e+00, Epoch Time: 125.67s\n",
      "Patience counter: 1/50\n",
      "Epoch 63, Train Loss: 7.43e-06 (ZCA-NLL: 5.01e-01, MSE-Phys: 7.43e-06, Grad-Phys: 1.02e-04), Val Loss: 2.28e+00, Epoch Time: 125.57s\n",
      "Best model so far saved at epoch 63 (Val Loss: 2.275e+00)\n",
      "Epoch 64, Train Loss: 7.29e-06 (ZCA-NLL: 5.02e-01, MSE-Phys: 7.29e-06, Grad-Phys: 1.01e-04), Val Loss: 2.27e+00, Epoch Time: 125.61s\n",
      "Best model so far saved at epoch 64 (Val Loss: 2.275e+00)\n",
      "Epoch 65, Train Loss: 7.17e-06 (ZCA-NLL: 5.01e-01, MSE-Phys: 7.17e-06, Grad-Phys: 1.00e-04), Val Loss: 2.27e+00, Epoch Time: 125.75s\n",
      "Best model so far saved at epoch 65 (Val Loss: 2.274e+00)\n",
      "Epoch 66, Train Loss: 7.14e-06 (ZCA-NLL: 5.02e-01, MSE-Phys: 7.14e-06, Grad-Phys: 1.00e-04), Val Loss: 2.27e+00, Epoch Time: 125.54s\n",
      "Best model so far saved at epoch 66 (Val Loss: 2.273e+00)\n",
      "Epoch 67, Train Loss: 7.01e-06 (ZCA-NLL: 5.03e-01, MSE-Phys: 7.01e-06, Grad-Phys: 9.92e-05), Val Loss: 2.27e+00, Epoch Time: 125.61s\n",
      "Best model so far saved at epoch 67 (Val Loss: 2.273e+00)\n",
      "Epoch 68, Train Loss: 6.93e-06 (ZCA-NLL: 5.04e-01, MSE-Phys: 6.93e-06, Grad-Phys: 9.85e-05), Val Loss: 2.27e+00, Epoch Time: 125.58s\n",
      "Best model so far saved at epoch 68 (Val Loss: 2.272e+00)\n",
      "Epoch 69, Train Loss: 6.85e-06 (ZCA-NLL: 5.16e-01, MSE-Phys: 6.85e-06, Grad-Phys: 9.77e-05), Val Loss: 2.27e+00, Epoch Time: 125.73s\n",
      "Best model so far saved at epoch 69 (Val Loss: 2.271e+00)\n",
      "Epoch 70, Train Loss: 6.77e-06 (ZCA-NLL: 5.06e-01, MSE-Phys: 6.77e-06, Grad-Phys: 9.70e-05), Val Loss: 2.27e+00, Epoch Time: 125.90s\n",
      "Best model so far saved at epoch 70 (Val Loss: 2.271e+00)\n",
      "Epoch 71, Train Loss: 6.68e-06 (ZCA-NLL: 5.08e-01, MSE-Phys: 6.68e-06, Grad-Phys: 9.63e-05), Val Loss: 2.27e+00, Epoch Time: 125.64s\n",
      "Best model so far saved at epoch 71 (Val Loss: 2.269e+00)\n",
      "Epoch 72, Train Loss: 6.64e-06 (ZCA-NLL: 5.24e-01, MSE-Phys: 6.64e-06, Grad-Phys: 9.56e-05), Val Loss: 2.27e+00, Epoch Time: 125.57s\n",
      "Best model so far saved at epoch 72 (Val Loss: 2.268e+00)\n",
      "Epoch 73, Train Loss: 6.56e-06 (ZCA-NLL: 5.10e-01, MSE-Phys: 6.56e-06, Grad-Phys: 9.50e-05), Val Loss: 2.27e+00, Epoch Time: 125.79s\n",
      "Best model so far saved at epoch 73 (Val Loss: 2.268e+00)\n",
      "Epoch 74, Train Loss: 6.47e-06 (ZCA-NLL: 5.09e-01, MSE-Phys: 6.47e-06, Grad-Phys: 9.43e-05), Val Loss: 2.27e+00, Epoch Time: 125.89s\n",
      "Best model so far saved at epoch 74 (Val Loss: 2.266e+00)\n",
      "Epoch 75, Train Loss: 6.36e-06 (ZCA-NLL: 5.23e-01, MSE-Phys: 6.36e-06, Grad-Phys: 9.34e-05), Val Loss: 2.26e+00, Epoch Time: 125.91s\n",
      "Best model so far saved at epoch 75 (Val Loss: 2.265e+00)\n",
      "Epoch 76, Train Loss: 6.31e-06 (ZCA-NLL: 5.01e-01, MSE-Phys: 6.31e-06, Grad-Phys: 9.28e-05), Val Loss: 2.26e+00, Epoch Time: 125.66s\n",
      "Best model so far saved at epoch 76 (Val Loss: 2.265e+00)\n",
      "Epoch 77, Train Loss: 6.28e-06 (ZCA-NLL: 5.05e-01, MSE-Phys: 6.28e-06, Grad-Phys: 9.23e-05), Val Loss: 2.26e+00, Epoch Time: 125.72s\n",
      "Best model so far saved at epoch 77 (Val Loss: 2.263e+00)\n",
      "Epoch 78, Train Loss: 6.24e-06 (ZCA-NLL: 5.04e-01, MSE-Phys: 6.24e-06, Grad-Phys: 9.17e-05), Val Loss: 2.26e+00, Epoch Time: 125.75s\n",
      "Best model so far saved at epoch 78 (Val Loss: 2.262e+00)\n",
      "Epoch 79, Train Loss: 6.14e-06 (ZCA-NLL: 5.34e-01, MSE-Phys: 6.14e-06, Grad-Phys: 9.10e-05), Val Loss: 2.26e+00, Epoch Time: 125.64s\n",
      "Best model so far saved at epoch 79 (Val Loss: 2.259e+00)\n",
      "Epoch 80, Train Loss: 6.10e-06 (ZCA-NLL: 5.03e-01, MSE-Phys: 6.10e-06, Grad-Phys: 9.05e-05), Val Loss: 2.26e+00, Epoch Time: 125.78s\n",
      "Patience counter: 1/50\n",
      "Epoch 81, Train Loss: 6.02e-06 (ZCA-NLL: 4.98e-01, MSE-Phys: 6.02e-06, Grad-Phys: 8.97e-05), Val Loss: 2.26e+00, Epoch Time: 125.56s\n",
      "Best model so far saved at epoch 81 (Val Loss: 2.258e+00)\n",
      "Epoch 82, Train Loss: 5.96e-06 (ZCA-NLL: 5.14e-01, MSE-Phys: 5.96e-06, Grad-Phys: 8.90e-05), Val Loss: 2.26e+00, Epoch Time: 125.54s\n",
      "Best model so far saved at epoch 82 (Val Loss: 2.257e+00)\n",
      "Epoch 83, Train Loss: 5.93e-06 (ZCA-NLL: 5.02e-01, MSE-Phys: 5.93e-06, Grad-Phys: 8.83e-05), Val Loss: 2.26e+00, Epoch Time: 125.56s\n",
      "Patience counter: 1/50\n",
      "Epoch 84, Train Loss: 5.86e-06 (ZCA-NLL: 5.02e-01, MSE-Phys: 5.86e-06, Grad-Phys: 8.75e-05), Val Loss: 2.25e+00, Epoch Time: 125.49s\n",
      "Best model so far saved at epoch 84 (Val Loss: 2.254e+00)\n",
      "Epoch 85, Train Loss: 5.77e-06 (ZCA-NLL: 5.08e-01, MSE-Phys: 5.77e-06, Grad-Phys: 8.67e-05), Val Loss: 2.25e+00, Epoch Time: 125.68s\n",
      "Best model so far saved at epoch 85 (Val Loss: 2.252e+00)\n",
      "Epoch 86, Train Loss: 5.88e-06 (ZCA-NLL: 5.18e-01, MSE-Phys: 5.88e-06, Grad-Phys: 8.66e-05), Val Loss: 2.25e+00, Epoch Time: 125.63s\n",
      "Best model so far saved at epoch 86 (Val Loss: 2.252e+00)\n",
      "Epoch 87, Train Loss: 5.72e-06 (ZCA-NLL: 5.01e-01, MSE-Phys: 5.72e-06, Grad-Phys: 8.57e-05), Val Loss: 2.25e+00, Epoch Time: 125.67s\n",
      "Best model so far saved at epoch 87 (Val Loss: 2.250e+00)\n",
      "Epoch 88, Train Loss: 5.61e-06 (ZCA-NLL: 5.02e-01, MSE-Phys: 5.61e-06, Grad-Phys: 8.50e-05), Val Loss: 2.25e+00, Epoch Time: 125.64s\n",
      "Best model so far saved at epoch 88 (Val Loss: 2.250e+00)\n",
      "Epoch 89, Train Loss: 5.56e-06 (ZCA-NLL: 4.96e-01, MSE-Phys: 5.56e-06, Grad-Phys: 8.43e-05), Val Loss: 2.25e+00, Epoch Time: 125.47s\n",
      "Best model so far saved at epoch 89 (Val Loss: 2.247e+00)\n",
      "Epoch 90, Train Loss: 5.53e-06 (ZCA-NLL: 4.96e-01, MSE-Phys: 5.53e-06, Grad-Phys: 8.38e-05), Val Loss: 2.25e+00, Epoch Time: 125.61s\n",
      "Best model so far saved at epoch 90 (Val Loss: 2.246e+00)\n",
      "Epoch 91, Train Loss: 5.47e-06 (ZCA-NLL: 4.96e-01, MSE-Phys: 5.47e-06, Grad-Phys: 8.33e-05), Val Loss: 2.25e+00, Epoch Time: 125.53s\n",
      "Patience counter: 1/50\n",
      "Epoch 92, Train Loss: 5.45e-06 (ZCA-NLL: 4.97e-01, MSE-Phys: 5.45e-06, Grad-Phys: 8.28e-05), Val Loss: 2.25e+00, Epoch Time: 125.45s\n",
      "Patience counter: 2/50\n",
      "Epoch 93, Train Loss: 5.38e-06 (ZCA-NLL: 4.95e-01, MSE-Phys: 5.38e-06, Grad-Phys: 8.23e-05), Val Loss: 2.24e+00, Epoch Time: 125.49s\n",
      "Best model so far saved at epoch 93 (Val Loss: 2.241e+00)\n",
      "Epoch 94, Train Loss: 5.33e-06 (ZCA-NLL: 4.94e-01, MSE-Phys: 5.33e-06, Grad-Phys: 8.17e-05), Val Loss: 2.24e+00, Epoch Time: 125.64s\n",
      "Patience counter: 1/50\n",
      "Epoch 95, Train Loss: 5.28e-06 (ZCA-NLL: 4.94e-01, MSE-Phys: 5.28e-06, Grad-Phys: 8.11e-05), Val Loss: 2.24e+00, Epoch Time: 125.80s\n",
      "Patience counter: 2/50\n",
      "Epoch 96, Train Loss: 5.25e-06 (ZCA-NLL: 4.94e-01, MSE-Phys: 5.25e-06, Grad-Phys: 8.05e-05), Val Loss: 2.24e+00, Epoch Time: 125.64s\n",
      "Best model so far saved at epoch 96 (Val Loss: 2.238e+00)\n",
      "Epoch 97, Train Loss: 5.20e-06 (ZCA-NLL: 4.93e-01, MSE-Phys: 5.20e-06, Grad-Phys: 7.99e-05), Val Loss: 2.24e+00, Epoch Time: 125.43s\n",
      "Best model so far saved at epoch 97 (Val Loss: 2.236e+00)\n",
      "Epoch 98, Train Loss: 5.14e-06 (ZCA-NLL: 4.92e-01, MSE-Phys: 5.14e-06, Grad-Phys: 7.91e-05), Val Loss: 2.23e+00, Epoch Time: 125.60s\n",
      "Best model so far saved at epoch 98 (Val Loss: 2.231e+00)\n",
      "Epoch 99, Train Loss: 5.10e-06 (ZCA-NLL: 4.91e-01, MSE-Phys: 5.10e-06, Grad-Phys: 7.83e-05), Val Loss: 2.23e+00, Epoch Time: 125.86s\n",
      "Best model so far saved at epoch 99 (Val Loss: 2.230e+00)\n",
      "Epoch 100, Train Loss: 5.09e-06 (ZCA-NLL: 4.89e-01, MSE-Phys: 5.09e-06, Grad-Phys: 7.74e-05), Val Loss: 2.23e+00, Epoch Time: 125.59s\n",
      "Best model so far saved at epoch 100 (Val Loss: 2.225e+00)\n",
      "Epoch 101, Train Loss: 5.01e-06 (ZCA-NLL: 4.89e-01, MSE-Phys: 5.01e-06, Grad-Phys: 7.64e-05), Val Loss: 2.22e+00, Epoch Time: 125.38s\n",
      "Best model so far saved at epoch 101 (Val Loss: 2.219e+00)\n",
      "Epoch 102, Train Loss: 5.01e-06 (ZCA-NLL: 4.89e-01, MSE-Phys: 5.01e-06, Grad-Phys: 7.56e-05), Val Loss: 2.21e+00, Epoch Time: 125.49s\n",
      "Best model so far saved at epoch 102 (Val Loss: 2.214e+00)\n",
      "Epoch 103, Train Loss: 4.92e-06 (ZCA-NLL: 4.87e-01, MSE-Phys: 4.92e-06, Grad-Phys: 7.44e-05), Val Loss: 2.21e+00, Epoch Time: 125.63s\n",
      "Best model so far saved at epoch 103 (Val Loss: 2.211e+00)\n",
      "Epoch 104, Train Loss: 4.90e-06 (ZCA-NLL: 4.88e-01, MSE-Phys: 4.90e-06, Grad-Phys: 7.34e-05), Val Loss: 2.21e+00, Epoch Time: 125.72s\n",
      "Best model so far saved at epoch 104 (Val Loss: 2.209e+00)\n",
      "Epoch 105, Train Loss: 4.85e-06 (ZCA-NLL: 4.87e-01, MSE-Phys: 4.85e-06, Grad-Phys: 7.25e-05), Val Loss: 2.20e+00, Epoch Time: 125.74s\n",
      "Best model so far saved at epoch 105 (Val Loss: 2.204e+00)\n",
      "Epoch 106, Train Loss: 4.82e-06 (ZCA-NLL: 4.86e-01, MSE-Phys: 4.82e-06, Grad-Phys: 7.16e-05), Val Loss: 2.20e+00, Epoch Time: 125.50s\n",
      "Patience counter: 1/50\n",
      "Epoch 107, Train Loss: 4.76e-06 (ZCA-NLL: 4.85e-01, MSE-Phys: 4.76e-06, Grad-Phys: 7.09e-05), Val Loss: 2.20e+00, Epoch Time: 125.45s\n",
      "Best model so far saved at epoch 107 (Val Loss: 2.195e+00)\n",
      "Epoch 108, Train Loss: 4.71e-06 (ZCA-NLL: 4.85e-01, MSE-Phys: 4.71e-06, Grad-Phys: 6.99e-05), Val Loss: 2.19e+00, Epoch Time: 125.63s\n",
      "Best model so far saved at epoch 108 (Val Loss: 2.192e+00)\n",
      "Epoch 109, Train Loss: 4.68e-06 (ZCA-NLL: 4.83e-01, MSE-Phys: 4.68e-06, Grad-Phys: 6.91e-05), Val Loss: 2.19e+00, Epoch Time: 125.74s\n",
      "Best model so far saved at epoch 109 (Val Loss: 2.190e+00)\n",
      "Epoch 110, Train Loss: 4.65e-06 (ZCA-NLL: 4.83e-01, MSE-Phys: 4.65e-06, Grad-Phys: 6.85e-05), Val Loss: 2.19e+00, Epoch Time: 125.61s\n",
      "Patience counter: 1/50\n",
      "Epoch 111, Train Loss: 4.63e-06 (ZCA-NLL: 4.83e-01, MSE-Phys: 4.63e-06, Grad-Phys: 6.78e-05), Val Loss: 2.18e+00, Epoch Time: 125.66s\n",
      "Best model so far saved at epoch 111 (Val Loss: 2.183e+00)\n",
      "Epoch 112, Train Loss: 4.60e-06 (ZCA-NLL: 4.82e-01, MSE-Phys: 4.60e-06, Grad-Phys: 6.70e-05), Val Loss: 2.20e+00, Epoch Time: 125.55s\n",
      "Patience counter: 1/50\n",
      "Epoch 113, Train Loss: 4.53e-06 (ZCA-NLL: 4.81e-01, MSE-Phys: 4.53e-06, Grad-Phys: 6.63e-05), Val Loss: 2.17e+00, Epoch Time: 125.61s\n",
      "Best model so far saved at epoch 113 (Val Loss: 2.174e+00)\n",
      "Epoch 114, Train Loss: 4.50e-06 (ZCA-NLL: 4.84e-01, MSE-Phys: 4.50e-06, Grad-Phys: 6.57e-05), Val Loss: 2.17e+00, Epoch Time: 125.42s\n",
      "Best model so far saved at epoch 114 (Val Loss: 2.173e+00)\n",
      "Epoch 115, Train Loss: 4.49e-06 (ZCA-NLL: 4.81e-01, MSE-Phys: 4.49e-06, Grad-Phys: 6.53e-05), Val Loss: 2.17e+00, Epoch Time: 125.52s\n",
      "Best model so far saved at epoch 115 (Val Loss: 2.166e+00)\n",
      "Epoch 116, Train Loss: 4.44e-06 (ZCA-NLL: 4.81e-01, MSE-Phys: 4.44e-06, Grad-Phys: 6.44e-05), Val Loss: 2.17e+00, Epoch Time: 125.55s\n",
      "Patience counter: 1/50\n",
      "Epoch 117, Train Loss: 4.37e-06 (ZCA-NLL: 4.78e-01, MSE-Phys: 4.37e-06, Grad-Phys: 6.37e-05), Val Loss: 2.17e+00, Epoch Time: 125.64s\n",
      "Patience counter: 2/50\n",
      "Epoch 118, Train Loss: 4.43e-06 (ZCA-NLL: 4.83e-01, MSE-Phys: 4.43e-06, Grad-Phys: 6.38e-05), Val Loss: 2.16e+00, Epoch Time: 125.45s\n",
      "Best model so far saved at epoch 118 (Val Loss: 2.163e+00)\n",
      "Epoch 119, Train Loss: 4.34e-06 (ZCA-NLL: 4.79e-01, MSE-Phys: 4.34e-06, Grad-Phys: 6.29e-05), Val Loss: 2.16e+00, Epoch Time: 125.68s\n",
      "Patience counter: 1/50\n",
      "Epoch 120, Train Loss: 4.31e-06 (ZCA-NLL: 4.77e-01, MSE-Phys: 4.31e-06, Grad-Phys: 6.24e-05), Val Loss: 2.16e+00, Epoch Time: 125.52s\n",
      "Best model so far saved at epoch 120 (Val Loss: 2.158e+00)\n",
      "Epoch 121, Train Loss: 4.27e-06 (ZCA-NLL: 4.78e-01, MSE-Phys: 4.27e-06, Grad-Phys: 6.18e-05), Val Loss: 2.16e+00, Epoch Time: 125.60s\n",
      "Best model so far saved at epoch 121 (Val Loss: 2.158e+00)\n",
      "Epoch 122, Train Loss: 4.24e-06 (ZCA-NLL: 4.77e-01, MSE-Phys: 4.24e-06, Grad-Phys: 6.13e-05), Val Loss: 2.15e+00, Epoch Time: 125.53s\n",
      "Best model so far saved at epoch 122 (Val Loss: 2.153e+00)\n",
      "Epoch 123, Train Loss: 4.23e-06 (ZCA-NLL: 4.77e-01, MSE-Phys: 4.23e-06, Grad-Phys: 6.10e-05), Val Loss: 2.16e+00, Epoch Time: 125.58s\n",
      "Patience counter: 1/50\n",
      "Epoch 124, Train Loss: 4.37e-06 (ZCA-NLL: 4.75e-01, MSE-Phys: 4.37e-06, Grad-Phys: 6.13e-05), Val Loss: 2.15e+00, Epoch Time: 125.67s\n",
      "Best model so far saved at epoch 124 (Val Loss: 2.150e+00)\n",
      "Epoch 125, Train Loss: 4.23e-06 (ZCA-NLL: 4.76e-01, MSE-Phys: 4.23e-06, Grad-Phys: 6.03e-05), Val Loss: 2.15e+00, Epoch Time: 125.68s\n",
      "Best model so far saved at epoch 125 (Val Loss: 2.148e+00)\n",
      "Epoch 126, Train Loss: 4.13e-06 (ZCA-NLL: 4.75e-01, MSE-Phys: 4.13e-06, Grad-Phys: 5.96e-05), Val Loss: 2.15e+00, Epoch Time: 125.69s\n",
      "Best model so far saved at epoch 126 (Val Loss: 2.145e+00)\n",
      "Epoch 127, Train Loss: 4.12e-06 (ZCA-NLL: 4.76e-01, MSE-Phys: 4.12e-06, Grad-Phys: 5.94e-05), Val Loss: 2.15e+00, Epoch Time: 125.74s\n",
      "Patience counter: 1/50\n",
      "Epoch 128, Train Loss: 4.07e-06 (ZCA-NLL: 4.74e-01, MSE-Phys: 4.07e-06, Grad-Phys: 5.88e-05), Val Loss: 2.15e+00, Epoch Time: 125.76s\n",
      "Patience counter: 2/50\n",
      "Epoch 129, Train Loss: 4.07e-06 (ZCA-NLL: 4.74e-01, MSE-Phys: 4.07e-06, Grad-Phys: 5.85e-05), Val Loss: 2.14e+00, Epoch Time: 125.67s\n",
      "Best model so far saved at epoch 129 (Val Loss: 2.144e+00)\n",
      "Epoch 130, Train Loss: 4.05e-06 (ZCA-NLL: 4.75e-01, MSE-Phys: 4.05e-06, Grad-Phys: 5.82e-05), Val Loss: 2.14e+00, Epoch Time: 125.80s\n",
      "Patience counter: 1/50\n",
      "Epoch 131, Train Loss: 4.03e-06 (ZCA-NLL: 4.74e-01, MSE-Phys: 4.03e-06, Grad-Phys: 5.78e-05), Val Loss: 2.15e+00, Epoch Time: 125.69s\n",
      "Patience counter: 2/50\n",
      "Epoch 132, Train Loss: 3.99e-06 (ZCA-NLL: 4.73e-01, MSE-Phys: 3.99e-06, Grad-Phys: 5.74e-05), Val Loss: 2.14e+00, Epoch Time: 125.67s\n",
      "Best model so far saved at epoch 132 (Val Loss: 2.140e+00)\n",
      "Epoch 133, Train Loss: 3.95e-06 (ZCA-NLL: 4.71e-01, MSE-Phys: 3.95e-06, Grad-Phys: 5.70e-05), Val Loss: 2.15e+00, Epoch Time: 125.64s\n",
      "Patience counter: 1/50\n",
      "Epoch 134, Train Loss: 3.98e-06 (ZCA-NLL: 4.73e-01, MSE-Phys: 3.98e-06, Grad-Phys: 5.70e-05), Val Loss: 2.13e+00, Epoch Time: 125.49s\n",
      "Best model so far saved at epoch 134 (Val Loss: 2.134e+00)\n",
      "Epoch 135, Train Loss: 3.92e-06 (ZCA-NLL: 4.71e-01, MSE-Phys: 3.92e-06, Grad-Phys: 5.65e-05), Val Loss: 2.14e+00, Epoch Time: 125.49s\n",
      "Patience counter: 1/50\n",
      "Epoch 136, Train Loss: 3.90e-06 (ZCA-NLL: 4.72e-01, MSE-Phys: 3.90e-06, Grad-Phys: 5.63e-05), Val Loss: 2.13e+00, Epoch Time: 125.58s\n",
      "Patience counter: 2/50\n",
      "Epoch 137, Train Loss: 3.88e-06 (ZCA-NLL: 4.72e-01, MSE-Phys: 3.88e-06, Grad-Phys: 5.59e-05), Val Loss: 2.14e+00, Epoch Time: 125.54s\n",
      "Patience counter: 3/50\n",
      "Epoch 138, Train Loss: 3.88e-06 (ZCA-NLL: 4.71e-01, MSE-Phys: 3.88e-06, Grad-Phys: 5.59e-05), Val Loss: 2.14e+00, Epoch Time: 125.85s\n",
      "Patience counter: 4/50\n",
      "Epoch 139, Train Loss: 3.82e-06 (ZCA-NLL: 4.72e-01, MSE-Phys: 3.82e-06, Grad-Phys: 5.55e-05), Val Loss: 2.13e+00, Epoch Time: 125.94s\n",
      "Patience counter: 5/50\n",
      "Epoch 140, Train Loss: 3.81e-06 (ZCA-NLL: 4.72e-01, MSE-Phys: 3.81e-06, Grad-Phys: 5.53e-05), Val Loss: 2.14e+00, Epoch Time: 125.79s\n",
      "Patience counter: 6/50\n",
      "Epoch 141, Train Loss: 3.48e-06 (ZCA-NLL: 4.70e-01, MSE-Phys: 3.48e-06, Grad-Phys: 5.37e-05), Val Loss: 2.13e+00, Epoch Time: 125.84s\n",
      "Best model so far saved at epoch 141 (Val Loss: 2.133e+00)\n",
      "Epoch 142, Train Loss: 3.35e-06 (ZCA-NLL: 4.72e-01, MSE-Phys: 3.35e-06, Grad-Phys: 5.32e-05), Val Loss: 2.13e+00, Epoch Time: 125.80s\n",
      "Best model so far saved at epoch 142 (Val Loss: 2.128e+00)\n",
      "Epoch 143, Train Loss: 3.30e-06 (ZCA-NLL: 4.69e-01, MSE-Phys: 3.30e-06, Grad-Phys: 5.30e-05), Val Loss: 2.13e+00, Epoch Time: 125.76s\n",
      "Best model so far saved at epoch 143 (Val Loss: 2.128e+00)\n",
      "Epoch 144, Train Loss: 3.28e-06 (ZCA-NLL: 4.68e-01, MSE-Phys: 3.28e-06, Grad-Phys: 5.27e-05), Val Loss: 2.13e+00, Epoch Time: 125.72s\n",
      "Best model so far saved at epoch 144 (Val Loss: 2.125e+00)\n",
      "Epoch 145, Train Loss: 3.28e-06 (ZCA-NLL: 4.70e-01, MSE-Phys: 3.28e-06, Grad-Phys: 5.27e-05), Val Loss: 2.13e+00, Epoch Time: 125.57s\n",
      "Patience counter: 1/50\n",
      "Epoch 146, Train Loss: 3.24e-06 (ZCA-NLL: 4.68e-01, MSE-Phys: 3.24e-06, Grad-Phys: 5.24e-05), Val Loss: 2.13e+00, Epoch Time: 125.52s\n",
      "Patience counter: 2/50\n",
      "Epoch 147, Train Loss: 3.23e-06 (ZCA-NLL: 4.69e-01, MSE-Phys: 3.23e-06, Grad-Phys: 5.22e-05), Val Loss: 2.12e+00, Epoch Time: 125.72s\n",
      "Best model so far saved at epoch 147 (Val Loss: 2.124e+00)\n",
      "Epoch 148, Train Loss: 3.21e-06 (ZCA-NLL: 4.71e-01, MSE-Phys: 3.21e-06, Grad-Phys: 5.21e-05), Val Loss: 2.13e+00, Epoch Time: 125.57s\n",
      "Patience counter: 1/50\n",
      "Epoch 149, Train Loss: 3.20e-06 (ZCA-NLL: 4.69e-01, MSE-Phys: 3.20e-06, Grad-Phys: 5.19e-05), Val Loss: 2.13e+00, Epoch Time: 125.53s\n",
      "Patience counter: 2/50\n",
      "Epoch 150, Train Loss: 3.19e-06 (ZCA-NLL: 4.68e-01, MSE-Phys: 3.19e-06, Grad-Phys: 5.18e-05), Val Loss: 2.13e+00, Epoch Time: 125.52s\n",
      "Patience counter: 3/50\n",
      "Epoch 151, Train Loss: 3.17e-06 (ZCA-NLL: 4.71e-01, MSE-Phys: 3.17e-06, Grad-Phys: 5.16e-05), Val Loss: 2.12e+00, Epoch Time: 125.58s\n",
      "Best model so far saved at epoch 151 (Val Loss: 2.122e+00)\n",
      "Epoch 152, Train Loss: 3.18e-06 (ZCA-NLL: 4.70e-01, MSE-Phys: 3.18e-06, Grad-Phys: 5.16e-05), Val Loss: 2.12e+00, Epoch Time: 125.66s\n",
      "Patience counter: 1/50\n",
      "Epoch 153, Train Loss: 3.16e-06 (ZCA-NLL: 4.69e-01, MSE-Phys: 3.16e-06, Grad-Phys: 5.15e-05), Val Loss: 2.12e+00, Epoch Time: 125.72s\n",
      "Best model so far saved at epoch 153 (Val Loss: 2.121e+00)\n",
      "Epoch 154, Train Loss: 3.15e-06 (ZCA-NLL: 4.69e-01, MSE-Phys: 3.15e-06, Grad-Phys: 5.12e-05), Val Loss: 2.12e+00, Epoch Time: 125.61s\n",
      "Best model so far saved at epoch 154 (Val Loss: 2.120e+00)\n",
      "Epoch 155, Train Loss: 3.12e-06 (ZCA-NLL: 4.72e-01, MSE-Phys: 3.12e-06, Grad-Phys: 5.11e-05), Val Loss: 2.12e+00, Epoch Time: 125.49s\n",
      "Best model so far saved at epoch 155 (Val Loss: 2.120e+00)\n",
      "Epoch 156, Train Loss: 3.14e-06 (ZCA-NLL: 4.71e-01, MSE-Phys: 3.14e-06, Grad-Phys: 5.12e-05), Val Loss: 2.12e+00, Epoch Time: 125.44s\n",
      "Patience counter: 1/50\n",
      "Epoch 157, Train Loss: 3.12e-06 (ZCA-NLL: 4.69e-01, MSE-Phys: 3.12e-06, Grad-Phys: 5.09e-05), Val Loss: 2.12e+00, Epoch Time: 125.75s\n",
      "Best model so far saved at epoch 157 (Val Loss: 2.116e+00)\n",
      "Epoch 158, Train Loss: 3.12e-06 (ZCA-NLL: 4.69e-01, MSE-Phys: 3.12e-06, Grad-Phys: 5.09e-05), Val Loss: 2.12e+00, Epoch Time: 125.52s\n",
      "Patience counter: 1/50\n",
      "Epoch 159, Train Loss: 3.12e-06 (ZCA-NLL: 4.74e-01, MSE-Phys: 3.12e-06, Grad-Phys: 5.07e-05), Val Loss: 2.12e+00, Epoch Time: 126.20s\n",
      "Patience counter: 2/50\n",
      "Epoch 160, Train Loss: 3.10e-06 (ZCA-NLL: 4.76e-01, MSE-Phys: 3.10e-06, Grad-Phys: 5.07e-05), Val Loss: 2.12e+00, Epoch Time: 126.20s\n",
      "Patience counter: 3/50\n",
      "Epoch 161, Train Loss: 3.06e-06 (ZCA-NLL: 4.70e-01, MSE-Phys: 3.06e-06, Grad-Phys: 5.04e-05), Val Loss: 2.12e+00, Epoch Time: 125.92s\n",
      "Patience counter: 4/50\n",
      "Epoch 162, Train Loss: 3.08e-06 (ZCA-NLL: 4.69e-01, MSE-Phys: 3.08e-06, Grad-Phys: 5.04e-05), Val Loss: 2.12e+00, Epoch Time: 126.01s\n",
      "Patience counter: 5/50\n",
      "Epoch 163, Train Loss: 3.07e-06 (ZCA-NLL: 4.70e-01, MSE-Phys: 3.07e-06, Grad-Phys: 5.03e-05), Val Loss: 2.12e+00, Epoch Time: 126.28s\n",
      "Patience counter: 6/50\n",
      "Epoch 164, Train Loss: 2.94e-06 (ZCA-NLL: 4.69e-01, MSE-Phys: 2.94e-06, Grad-Phys: 4.98e-05), Val Loss: 2.12e+00, Epoch Time: 125.80s\n",
      "Patience counter: 7/50\n",
      "Epoch 165, Train Loss: 2.93e-06 (ZCA-NLL: 4.71e-01, MSE-Phys: 2.93e-06, Grad-Phys: 4.96e-05), Val Loss: 2.12e+00, Epoch Time: 125.67s\n",
      "Patience counter: 8/50\n",
      "Epoch 166, Train Loss: 2.91e-06 (ZCA-NLL: 4.74e-01, MSE-Phys: 2.91e-06, Grad-Phys: 4.96e-05), Val Loss: 2.12e+00, Epoch Time: 125.55s\n",
      "Patience counter: 9/50\n",
      "Epoch 167, Train Loss: 2.89e-06 (ZCA-NLL: 4.75e-01, MSE-Phys: 2.89e-06, Grad-Phys: 4.94e-05), Val Loss: 2.12e+00, Epoch Time: 125.72s\n",
      "Best model so far saved at epoch 167 (Val Loss: 2.116e+00)\n",
      "Epoch 168, Train Loss: 2.89e-06 (ZCA-NLL: 4.74e-01, MSE-Phys: 2.89e-06, Grad-Phys: 4.93e-05), Val Loss: 2.11e+00, Epoch Time: 125.50s\n",
      "Best model so far saved at epoch 168 (Val Loss: 2.113e+00)\n",
      "Epoch 169, Train Loss: 2.88e-06 (ZCA-NLL: 4.71e-01, MSE-Phys: 2.88e-06, Grad-Phys: 4.92e-05), Val Loss: 2.12e+00, Epoch Time: 125.81s\n",
      "Patience counter: 1/50\n",
      "Epoch 170, Train Loss: 2.88e-06 (ZCA-NLL: 4.75e-01, MSE-Phys: 2.88e-06, Grad-Phys: 4.92e-05), Val Loss: 2.12e+00, Epoch Time: 125.59s\n",
      "Patience counter: 2/50\n",
      "Epoch 171, Train Loss: 2.87e-06 (ZCA-NLL: 4.73e-01, MSE-Phys: 2.87e-06, Grad-Phys: 4.92e-05), Val Loss: 2.11e+00, Epoch Time: 125.51s\n",
      "Patience counter: 3/50\n",
      "Epoch 172, Train Loss: 2.84e-06 (ZCA-NLL: 4.71e-01, MSE-Phys: 2.84e-06, Grad-Phys: 4.90e-05), Val Loss: 2.11e+00, Epoch Time: 125.69s\n",
      "Patience counter: 4/50\n",
      "Epoch 173, Train Loss: 2.85e-06 (ZCA-NLL: 4.81e-01, MSE-Phys: 2.85e-06, Grad-Phys: 4.90e-05), Val Loss: 2.11e+00, Epoch Time: 125.67s\n",
      "Best model so far saved at epoch 173 (Val Loss: 2.111e+00)\n",
      "Epoch 174, Train Loss: 2.84e-06 (ZCA-NLL: 4.71e-01, MSE-Phys: 2.84e-06, Grad-Phys: 4.89e-05), Val Loss: 2.11e+00, Epoch Time: 125.73s\n",
      "Patience counter: 1/50\n",
      "Epoch 175, Train Loss: 2.85e-06 (ZCA-NLL: 4.72e-01, MSE-Phys: 2.85e-06, Grad-Phys: 4.89e-05), Val Loss: 2.11e+00, Epoch Time: 125.60s\n",
      "Patience counter: 2/50\n",
      "Epoch 176, Train Loss: 2.84e-06 (ZCA-NLL: 4.69e-01, MSE-Phys: 2.84e-06, Grad-Phys: 4.89e-05), Val Loss: 2.11e+00, Epoch Time: 125.54s\n",
      "Patience counter: 3/50\n",
      "Epoch 177, Train Loss: 2.84e-06 (ZCA-NLL: 4.73e-01, MSE-Phys: 2.84e-06, Grad-Phys: 4.89e-05), Val Loss: 2.11e+00, Epoch Time: 125.44s\n",
      "Patience counter: 4/50\n",
      "Epoch 178, Train Loss: 2.84e-06 (ZCA-NLL: 4.73e-01, MSE-Phys: 2.84e-06, Grad-Phys: 4.88e-05), Val Loss: 2.11e+00, Epoch Time: 125.74s\n",
      "Patience counter: 5/50\n",
      "Epoch 179, Train Loss: 2.84e-06 (ZCA-NLL: 4.73e-01, MSE-Phys: 2.84e-06, Grad-Phys: 4.88e-05), Val Loss: 2.12e+00, Epoch Time: 125.59s\n",
      "Patience counter: 6/50\n",
      "Epoch 180, Train Loss: 2.78e-06 (ZCA-NLL: 4.72e-01, MSE-Phys: 2.78e-06, Grad-Phys: 4.84e-05), Val Loss: 2.11e+00, Epoch Time: 125.60s\n",
      "Patience counter: 7/50\n",
      "Epoch 181, Train Loss: 2.76e-06 (ZCA-NLL: 4.77e-01, MSE-Phys: 2.76e-06, Grad-Phys: 4.83e-05), Val Loss: 2.11e+00, Epoch Time: 125.71s\n",
      "Patience counter: 8/50\n",
      "Epoch 182, Train Loss: 2.77e-06 (ZCA-NLL: 4.73e-01, MSE-Phys: 2.77e-06, Grad-Phys: 4.84e-05), Val Loss: 2.11e+00, Epoch Time: 125.56s\n",
      "Patience counter: 9/50\n",
      "Epoch 183, Train Loss: 2.76e-06 (ZCA-NLL: 4.73e-01, MSE-Phys: 2.76e-06, Grad-Phys: 4.83e-05), Val Loss: 2.12e+00, Epoch Time: 125.50s\n",
      "Patience counter: 10/50\n",
      "Epoch 184, Train Loss: 2.76e-06 (ZCA-NLL: 4.81e-01, MSE-Phys: 2.76e-06, Grad-Phys: 4.84e-05), Val Loss: 2.11e+00, Epoch Time: 125.57s\n",
      "Patience counter: 11/50\n",
      "Epoch 185, Train Loss: 2.75e-06 (ZCA-NLL: 4.74e-01, MSE-Phys: 2.75e-06, Grad-Phys: 4.82e-05), Val Loss: 2.11e+00, Epoch Time: 125.60s\n",
      "Patience counter: 12/50\n",
      "Epoch 186, Train Loss: 2.74e-06 (ZCA-NLL: 4.72e-01, MSE-Phys: 2.74e-06, Grad-Phys: 4.82e-05), Val Loss: 2.11e+00, Epoch Time: 125.58s\n",
      "Patience counter: 13/50\n",
      "Epoch 187, Train Loss: 2.72e-06 (ZCA-NLL: 4.76e-01, MSE-Phys: 2.72e-06, Grad-Phys: 4.80e-05), Val Loss: 2.11e+00, Epoch Time: 125.65s\n",
      "Patience counter: 14/50\n",
      "Epoch 188, Train Loss: 2.71e-06 (ZCA-NLL: 4.72e-01, MSE-Phys: 2.71e-06, Grad-Phys: 4.79e-05), Val Loss: 2.11e+00, Epoch Time: 125.77s\n",
      "Patience counter: 15/50\n",
      "Epoch 189, Train Loss: 2.71e-06 (ZCA-NLL: 4.75e-01, MSE-Phys: 2.71e-06, Grad-Phys: 4.80e-05), Val Loss: 2.11e+00, Epoch Time: 125.76s\n",
      "Patience counter: 16/50\n",
      "Epoch 190, Train Loss: 2.71e-06 (ZCA-NLL: 4.84e-01, MSE-Phys: 2.71e-06, Grad-Phys: 4.81e-05), Val Loss: 2.11e+00, Epoch Time: 125.56s\n",
      "Patience counter: 17/50\n",
      "Epoch 191, Train Loss: 2.71e-06 (ZCA-NLL: 4.77e-01, MSE-Phys: 2.71e-06, Grad-Phys: 4.80e-05), Val Loss: 2.11e+00, Epoch Time: 125.72s\n",
      "Best model so far saved at epoch 191 (Val Loss: 2.110e+00)\n",
      "Epoch 192, Train Loss: 2.71e-06 (ZCA-NLL: 4.85e-01, MSE-Phys: 2.71e-06, Grad-Phys: 4.80e-05), Val Loss: 2.11e+00, Epoch Time: 125.61s\n",
      "Patience counter: 1/50\n",
      "Epoch 193, Train Loss: 2.71e-06 (ZCA-NLL: 4.80e-01, MSE-Phys: 2.71e-06, Grad-Phys: 4.80e-05), Val Loss: 2.11e+00, Epoch Time: 125.65s\n",
      "Patience counter: 2/50\n",
      "Epoch 194, Train Loss: 2.70e-06 (ZCA-NLL: 4.83e-01, MSE-Phys: 2.70e-06, Grad-Phys: 4.79e-05), Val Loss: 2.11e+00, Epoch Time: 125.71s\n",
      "Patience counter: 3/50\n",
      "Epoch 195, Train Loss: 2.71e-06 (ZCA-NLL: 4.83e-01, MSE-Phys: 2.71e-06, Grad-Phys: 4.80e-05), Val Loss: 2.11e+00, Epoch Time: 125.59s\n",
      "Best model so far saved at epoch 195 (Val Loss: 2.109e+00)\n",
      "Epoch 196, Train Loss: 2.70e-06 (ZCA-NLL: 4.72e-01, MSE-Phys: 2.70e-06, Grad-Phys: 4.79e-05), Val Loss: 2.11e+00, Epoch Time: 125.70s\n",
      "Patience counter: 1/50\n",
      "Epoch 197, Train Loss: 2.69e-06 (ZCA-NLL: 4.73e-01, MSE-Phys: 2.69e-06, Grad-Phys: 4.79e-05), Val Loss: 2.11e+00, Epoch Time: 125.62s\n",
      "Patience counter: 2/50\n",
      "Epoch 198, Train Loss: 2.70e-06 (ZCA-NLL: 4.75e-01, MSE-Phys: 2.70e-06, Grad-Phys: 4.79e-05), Val Loss: 2.11e+00, Epoch Time: 125.53s\n",
      "Patience counter: 3/50\n",
      "Epoch 199, Train Loss: 2.69e-06 (ZCA-NLL: 4.76e-01, MSE-Phys: 2.69e-06, Grad-Phys: 4.79e-05), Val Loss: 2.11e+00, Epoch Time: 125.58s\n",
      "Patience counter: 4/50\n",
      "Epoch 200, Train Loss: 2.70e-06 (ZCA-NLL: 4.86e-01, MSE-Phys: 2.70e-06, Grad-Phys: 4.79e-05), Val Loss: 2.11e+00, Epoch Time: 125.53s\n",
      "Patience counter: 5/50\n",
      "Epoch 201, Train Loss: 2.70e-06 (ZCA-NLL: 4.79e-01, MSE-Phys: 2.70e-06, Grad-Phys: 4.79e-05), Val Loss: 2.11e+00, Epoch Time: 125.59s\n",
      "Patience counter: 6/50\n",
      "Epoch 202, Train Loss: 2.69e-06 (ZCA-NLL: 4.81e-01, MSE-Phys: 2.69e-06, Grad-Phys: 4.79e-05), Val Loss: 2.11e+00, Epoch Time: 125.56s\n",
      "Patience counter: 7/50\n",
      "Epoch 203, Train Loss: 2.67e-06 (ZCA-NLL: 4.80e-01, MSE-Phys: 2.67e-06, Grad-Phys: 4.78e-05), Val Loss: 2.11e+00, Epoch Time: 125.57s\n",
      "Patience counter: 8/50\n",
      "Epoch 204, Train Loss: 2.67e-06 (ZCA-NLL: 4.83e-01, MSE-Phys: 2.67e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.55s\n",
      "Patience counter: 9/50\n",
      "Epoch 205, Train Loss: 2.68e-06 (ZCA-NLL: 4.95e-01, MSE-Phys: 2.68e-06, Grad-Phys: 4.78e-05), Val Loss: 2.11e+00, Epoch Time: 125.57s\n",
      "Patience counter: 10/50\n",
      "Epoch 206, Train Loss: 2.68e-06 (ZCA-NLL: 4.75e-01, MSE-Phys: 2.68e-06, Grad-Phys: 4.78e-05), Val Loss: 2.11e+00, Epoch Time: 125.55s\n",
      "Patience counter: 11/50\n",
      "Epoch 207, Train Loss: 2.67e-06 (ZCA-NLL: 4.74e-01, MSE-Phys: 2.67e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.66s\n",
      "Patience counter: 12/50\n",
      "Epoch 208, Train Loss: 2.66e-06 (ZCA-NLL: 4.79e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.67s\n",
      "Patience counter: 13/50\n",
      "Epoch 209, Train Loss: 2.67e-06 (ZCA-NLL: 4.77e-01, MSE-Phys: 2.67e-06, Grad-Phys: 4.78e-05), Val Loss: 2.11e+00, Epoch Time: 125.55s\n",
      "Patience counter: 14/50\n",
      "Epoch 210, Train Loss: 2.68e-06 (ZCA-NLL: 4.77e-01, MSE-Phys: 2.68e-06, Grad-Phys: 4.78e-05), Val Loss: 2.11e+00, Epoch Time: 125.68s\n",
      "Patience counter: 15/50\n",
      "Epoch 211, Train Loss: 2.66e-06 (ZCA-NLL: 4.76e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.58s\n",
      "Patience counter: 16/50\n",
      "Epoch 212, Train Loss: 2.67e-06 (ZCA-NLL: 4.73e-01, MSE-Phys: 2.67e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.53s\n",
      "Patience counter: 17/50\n",
      "Epoch 213, Train Loss: 2.66e-06 (ZCA-NLL: 4.76e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.60s\n",
      "Patience counter: 18/50\n",
      "Epoch 214, Train Loss: 2.67e-06 (ZCA-NLL: 5.01e-01, MSE-Phys: 2.67e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.57s\n",
      "Patience counter: 19/50\n",
      "Epoch 215, Train Loss: 2.66e-06 (ZCA-NLL: 4.77e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.66s\n",
      "Patience counter: 20/50\n",
      "Epoch 216, Train Loss: 2.67e-06 (ZCA-NLL: 5.03e-01, MSE-Phys: 2.67e-06, Grad-Phys: 4.78e-05), Val Loss: 2.11e+00, Epoch Time: 125.61s\n",
      "Patience counter: 21/50\n",
      "Epoch 217, Train Loss: 2.66e-06 (ZCA-NLL: 4.77e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.66s\n",
      "Patience counter: 22/50\n",
      "Epoch 218, Train Loss: 2.66e-06 (ZCA-NLL: 4.77e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.58s\n",
      "Patience counter: 23/50\n",
      "Epoch 219, Train Loss: 2.67e-06 (ZCA-NLL: 4.87e-01, MSE-Phys: 2.67e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.56s\n",
      "Patience counter: 24/50\n",
      "Epoch 220, Train Loss: 2.66e-06 (ZCA-NLL: 4.87e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.54s\n",
      "Patience counter: 25/50\n",
      "Epoch 221, Train Loss: 2.66e-06 (ZCA-NLL: 4.85e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.55s\n",
      "Patience counter: 26/50\n",
      "Epoch 222, Train Loss: 2.65e-06 (ZCA-NLL: 4.73e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.51s\n",
      "Patience counter: 27/50\n",
      "Epoch 223, Train Loss: 2.66e-06 (ZCA-NLL: 4.70e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.63s\n",
      "Patience counter: 28/50\n",
      "Epoch 224, Train Loss: 2.65e-06 (ZCA-NLL: 4.76e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.62s\n",
      "Patience counter: 29/50\n",
      "Epoch 225, Train Loss: 2.67e-06 (ZCA-NLL: 4.95e-01, MSE-Phys: 2.67e-06, Grad-Phys: 4.78e-05), Val Loss: 2.11e+00, Epoch Time: 125.56s\n",
      "Patience counter: 30/50\n",
      "Epoch 226, Train Loss: 2.66e-06 (ZCA-NLL: 4.89e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.62s\n",
      "Patience counter: 31/50\n",
      "Epoch 227, Train Loss: 2.66e-06 (ZCA-NLL: 4.86e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.68s\n",
      "Patience counter: 32/50\n",
      "Epoch 228, Train Loss: 2.65e-06 (ZCA-NLL: 4.88e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.68s\n",
      "Patience counter: 33/50\n",
      "Epoch 229, Train Loss: 2.65e-06 (ZCA-NLL: 4.74e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.65s\n",
      "Patience counter: 34/50\n",
      "Epoch 230, Train Loss: 2.66e-06 (ZCA-NLL: 4.80e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.57s\n",
      "Patience counter: 35/50\n",
      "Epoch 231, Train Loss: 2.66e-06 (ZCA-NLL: 4.83e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.81s\n",
      "Patience counter: 36/50\n",
      "Epoch 232, Train Loss: 2.65e-06 (ZCA-NLL: 4.78e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.73s\n",
      "Patience counter: 37/50\n",
      "Epoch 233, Train Loss: 2.67e-06 (ZCA-NLL: 4.84e-01, MSE-Phys: 2.67e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.68s\n",
      "Patience counter: 38/50\n",
      "Epoch 234, Train Loss: 2.67e-06 (ZCA-NLL: 4.85e-01, MSE-Phys: 2.67e-06, Grad-Phys: 4.78e-05), Val Loss: 2.11e+00, Epoch Time: 125.60s\n",
      "Patience counter: 39/50\n",
      "Epoch 235, Train Loss: 2.66e-06 (ZCA-NLL: 4.91e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.47s\n",
      "Patience counter: 40/50\n",
      "Epoch 236, Train Loss: 2.65e-06 (ZCA-NLL: 4.79e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.47s\n",
      "Patience counter: 41/50\n",
      "Epoch 237, Train Loss: 2.66e-06 (ZCA-NLL: 4.93e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.48s\n",
      "Patience counter: 42/50\n",
      "Epoch 238, Train Loss: 2.66e-06 (ZCA-NLL: 4.83e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.56s\n",
      "Patience counter: 43/50\n",
      "Epoch 239, Train Loss: 2.66e-06 (ZCA-NLL: 4.86e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.56s\n",
      "Patience counter: 44/50\n",
      "Epoch 240, Train Loss: 2.65e-06 (ZCA-NLL: 4.75e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.60s\n",
      "Patience counter: 45/50\n",
      "Epoch 241, Train Loss: 2.66e-06 (ZCA-NLL: 4.83e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.73s\n",
      "Patience counter: 46/50\n",
      "Epoch 242, Train Loss: 2.66e-06 (ZCA-NLL: 4.84e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.58s\n",
      "Patience counter: 47/50\n",
      "Epoch 243, Train Loss: 2.65e-06 (ZCA-NLL: 4.76e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.65s\n",
      "Patience counter: 48/50\n",
      "Epoch 244, Train Loss: 2.65e-06 (ZCA-NLL: 4.83e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.73s\n",
      "Patience counter: 49/50\n",
      "Epoch 245, Train Loss: 2.66e-06 (ZCA-NLL: 4.80e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.79s\n",
      "Best model so far saved at epoch 245 (Val Loss: 2.109e+00)\n",
      "Epoch 246, Train Loss: 2.66e-06 (ZCA-NLL: 4.79e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.53s\n",
      "Patience counter: 1/50\n",
      "Epoch 247, Train Loss: 2.66e-06 (ZCA-NLL: 4.77e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.60s\n",
      "Patience counter: 2/50\n",
      "Epoch 248, Train Loss: 2.65e-06 (ZCA-NLL: 4.95e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.64s\n",
      "Patience counter: 3/50\n",
      "Epoch 249, Train Loss: 2.66e-06 (ZCA-NLL: 4.91e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.69s\n",
      "Patience counter: 4/50\n",
      "Epoch 250, Train Loss: 2.65e-06 (ZCA-NLL: 4.79e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.32s\n",
      "Patience counter: 5/50\n",
      "Epoch 251, Train Loss: 2.65e-06 (ZCA-NLL: 4.77e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.38s\n",
      "Patience counter: 6/50\n",
      "Epoch 252, Train Loss: 2.65e-06 (ZCA-NLL: 4.86e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.62s\n",
      "Patience counter: 7/50\n",
      "Epoch 253, Train Loss: 2.65e-06 (ZCA-NLL: 4.78e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.72s\n",
      "Patience counter: 8/50\n",
      "Epoch 254, Train Loss: 2.66e-06 (ZCA-NLL: 4.81e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.68s\n",
      "Patience counter: 9/50\n",
      "Epoch 255, Train Loss: 2.65e-06 (ZCA-NLL: 4.78e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.75s\n",
      "Patience counter: 10/50\n",
      "Epoch 256, Train Loss: 2.66e-06 (ZCA-NLL: 4.82e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.64s\n",
      "Patience counter: 11/50\n",
      "Epoch 257, Train Loss: 2.66e-06 (ZCA-NLL: 4.80e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.75s\n",
      "Patience counter: 12/50\n",
      "Epoch 258, Train Loss: 2.66e-06 (ZCA-NLL: 4.76e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.66s\n",
      "Patience counter: 13/50\n",
      "Epoch 259, Train Loss: 2.66e-06 (ZCA-NLL: 4.77e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.73s\n",
      "Patience counter: 14/50\n",
      "Epoch 260, Train Loss: 2.65e-06 (ZCA-NLL: 4.80e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.72s\n",
      "Patience counter: 15/50\n",
      "Epoch 261, Train Loss: 2.66e-06 (ZCA-NLL: 4.79e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.47s\n",
      "Patience counter: 16/50\n",
      "Epoch 262, Train Loss: 2.66e-06 (ZCA-NLL: 4.78e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.78e-05), Val Loss: 2.11e+00, Epoch Time: 125.63s\n",
      "Patience counter: 17/50\n",
      "Epoch 263, Train Loss: 2.66e-06 (ZCA-NLL: 4.84e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.49s\n",
      "Patience counter: 18/50\n",
      "Epoch 264, Train Loss: 2.65e-06 (ZCA-NLL: 4.83e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.51s\n",
      "Patience counter: 19/50\n",
      "Epoch 265, Train Loss: 2.65e-06 (ZCA-NLL: 4.70e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.75e-05), Val Loss: 2.11e+00, Epoch Time: 125.69s\n",
      "Best model so far saved at epoch 265 (Val Loss: 2.109e+00)\n",
      "Epoch 266, Train Loss: 2.66e-06 (ZCA-NLL: 4.81e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.76s\n",
      "Patience counter: 1/50\n",
      "Epoch 267, Train Loss: 2.64e-06 (ZCA-NLL: 4.78e-01, MSE-Phys: 2.64e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.68s\n",
      "Patience counter: 2/50\n",
      "Epoch 268, Train Loss: 2.65e-06 (ZCA-NLL: 4.86e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.49s\n",
      "Patience counter: 3/50\n",
      "Epoch 269, Train Loss: 2.66e-06 (ZCA-NLL: 4.89e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.41s\n",
      "Patience counter: 4/50\n",
      "Epoch 270, Train Loss: 2.66e-06 (ZCA-NLL: 4.79e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.64s\n",
      "Patience counter: 5/50\n",
      "Epoch 271, Train Loss: 2.65e-06 (ZCA-NLL: 4.78e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.77s\n",
      "Patience counter: 6/50\n",
      "Epoch 272, Train Loss: 2.65e-06 (ZCA-NLL: 4.71e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.75e-05), Val Loss: 2.11e+00, Epoch Time: 125.73s\n",
      "Patience counter: 7/50\n",
      "Epoch 273, Train Loss: 2.65e-06 (ZCA-NLL: 4.77e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.69s\n",
      "Patience counter: 8/50\n",
      "Epoch 274, Train Loss: 2.65e-06 (ZCA-NLL: 4.79e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.72s\n",
      "Patience counter: 9/50\n",
      "Epoch 275, Train Loss: 2.65e-06 (ZCA-NLL: 4.98e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.51s\n",
      "Patience counter: 10/50\n",
      "Epoch 276, Train Loss: 2.66e-06 (ZCA-NLL: 4.83e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.65s\n",
      "Patience counter: 11/50\n",
      "Epoch 277, Train Loss: 2.65e-06 (ZCA-NLL: 4.83e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.54s\n",
      "Patience counter: 12/50\n",
      "Epoch 278, Train Loss: 2.65e-06 (ZCA-NLL: 4.79e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.63s\n",
      "Patience counter: 13/50\n",
      "Epoch 279, Train Loss: 2.66e-06 (ZCA-NLL: 4.84e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.79s\n",
      "Patience counter: 14/50\n",
      "Epoch 280, Train Loss: 2.67e-06 (ZCA-NLL: 4.85e-01, MSE-Phys: 2.67e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.75s\n",
      "Patience counter: 15/50\n",
      "Epoch 281, Train Loss: 2.66e-06 (ZCA-NLL: 4.75e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.75s\n",
      "Patience counter: 16/50\n",
      "Epoch 282, Train Loss: 2.65e-06 (ZCA-NLL: 4.81e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.76s\n",
      "Patience counter: 17/50\n",
      "Epoch 283, Train Loss: 2.66e-06 (ZCA-NLL: 4.94e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.58s\n",
      "Patience counter: 18/50\n",
      "Epoch 284, Train Loss: 2.64e-06 (ZCA-NLL: 4.74e-01, MSE-Phys: 2.64e-06, Grad-Phys: 4.75e-05), Val Loss: 2.11e+00, Epoch Time: 125.62s\n",
      "Patience counter: 19/50\n",
      "Epoch 285, Train Loss: 2.65e-06 (ZCA-NLL: 4.75e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.56s\n",
      "Patience counter: 20/50\n",
      "Epoch 286, Train Loss: 2.66e-06 (ZCA-NLL: 4.78e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.52s\n",
      "Patience counter: 21/50\n",
      "Epoch 287, Train Loss: 2.67e-06 (ZCA-NLL: 4.83e-01, MSE-Phys: 2.67e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.57s\n",
      "Patience counter: 22/50\n",
      "Epoch 288, Train Loss: 2.66e-06 (ZCA-NLL: 4.70e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.71s\n",
      "Patience counter: 23/50\n",
      "Epoch 289, Train Loss: 2.66e-06 (ZCA-NLL: 4.84e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.65s\n",
      "Patience counter: 24/50\n",
      "Epoch 290, Train Loss: 2.64e-06 (ZCA-NLL: 4.75e-01, MSE-Phys: 2.64e-06, Grad-Phys: 4.75e-05), Val Loss: 2.11e+00, Epoch Time: 125.74s\n",
      "Patience counter: 25/50\n",
      "Epoch 291, Train Loss: 2.66e-06 (ZCA-NLL: 4.79e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.65s\n",
      "Patience counter: 26/50\n",
      "Epoch 292, Train Loss: 2.65e-06 (ZCA-NLL: 4.76e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.37s\n",
      "Patience counter: 27/50\n",
      "Epoch 293, Train Loss: 2.66e-06 (ZCA-NLL: 4.74e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.58s\n",
      "Patience counter: 28/50\n",
      "Epoch 294, Train Loss: 2.66e-06 (ZCA-NLL: 4.81e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.56s\n",
      "Patience counter: 29/50\n",
      "Epoch 295, Train Loss: 2.65e-06 (ZCA-NLL: 4.89e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.45s\n",
      "Patience counter: 30/50\n",
      "Epoch 296, Train Loss: 2.66e-06 (ZCA-NLL: 4.87e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.62s\n",
      "Patience counter: 31/50\n",
      "Epoch 297, Train Loss: 2.65e-06 (ZCA-NLL: 4.82e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.66s\n",
      "Patience counter: 32/50\n",
      "Epoch 298, Train Loss: 2.65e-06 (ZCA-NLL: 4.81e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.52s\n",
      "Patience counter: 33/50\n",
      "Epoch 299, Train Loss: 2.67e-06 (ZCA-NLL: 4.79e-01, MSE-Phys: 2.67e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.52s\n",
      "Patience counter: 34/50\n",
      "Epoch 300, Train Loss: 2.66e-06 (ZCA-NLL: 4.80e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.53s\n",
      "Patience counter: 35/50\n",
      "Epoch 301, Train Loss: 2.66e-06 (ZCA-NLL: 4.89e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.50s\n",
      "Patience counter: 36/50\n",
      "Epoch 302, Train Loss: 2.65e-06 (ZCA-NLL: 4.75e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.54s\n",
      "Patience counter: 37/50\n",
      "Epoch 303, Train Loss: 2.66e-06 (ZCA-NLL: 4.87e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.73s\n",
      "Patience counter: 38/50\n",
      "Epoch 304, Train Loss: 2.66e-06 (ZCA-NLL: 4.81e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.67s\n",
      "Patience counter: 39/50\n",
      "Epoch 305, Train Loss: 2.65e-06 (ZCA-NLL: 4.73e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.63s\n",
      "Patience counter: 40/50\n",
      "Epoch 306, Train Loss: 2.66e-06 (ZCA-NLL: 4.87e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.58s\n",
      "Patience counter: 41/50\n",
      "Epoch 307, Train Loss: 2.66e-06 (ZCA-NLL: 4.92e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.53s\n",
      "Patience counter: 42/50\n",
      "Epoch 308, Train Loss: 2.65e-06 (ZCA-NLL: 4.80e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.53s\n",
      "Patience counter: 43/50\n",
      "Epoch 309, Train Loss: 2.65e-06 (ZCA-NLL: 4.77e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.50s\n",
      "Patience counter: 44/50\n",
      "Epoch 310, Train Loss: 2.65e-06 (ZCA-NLL: 4.81e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.57s\n",
      "Patience counter: 45/50\n",
      "Epoch 311, Train Loss: 2.65e-06 (ZCA-NLL: 4.78e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.55s\n",
      "Patience counter: 46/50\n",
      "Epoch 312, Train Loss: 2.66e-06 (ZCA-NLL: 4.83e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.63s\n",
      "Patience counter: 47/50\n",
      "Epoch 313, Train Loss: 2.65e-06 (ZCA-NLL: 4.75e-01, MSE-Phys: 2.65e-06, Grad-Phys: 4.76e-05), Val Loss: 2.11e+00, Epoch Time: 125.53s\n",
      "Patience counter: 48/50\n",
      "Epoch 314, Train Loss: 2.66e-06 (ZCA-NLL: 4.84e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.52s\n",
      "Patience counter: 49/50\n",
      "Epoch 315, Train Loss: 2.66e-06 (ZCA-NLL: 4.95e-01, MSE-Phys: 2.66e-06, Grad-Phys: 4.77e-05), Val Loss: 2.11e+00, Epoch Time: 125.64s\n",
      "Patience counter: 50/50\n",
      "Early stopping triggered.\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n",
    "# Create model and optimizer\n",
    "model = UNet(in_channels=2, out_channels=2, initial_features=32, depth=4)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "train_model(model, train_loader, val_loader,\n",
    "            Vt, scale, mean,  \n",
    "            optimizer, device,\n",
    "            grad_loss_weight=0.0,      # Weight for gradient loss in physical space\n",
    "            mse_loss_weight=1.0,       # Weight for MSE loss in physical space  \n",
    "            zca_nll_weight=0.0,        # Weight for ZCA Gaussian NLL loss\n",
    "            save_path='/home/jovyan/GRL_ssh/checkpoints/mse_loss_only.pth',\n",
    "            n_epochs=2000,\n",
    "            patience=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
