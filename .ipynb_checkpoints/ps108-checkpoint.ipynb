{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f73b9994-d2e1-41fe-aaee-07d7f139cfcf",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858e238c-3336-4532-84b3-998ec097d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from unet import *\n",
    "from train import *\n",
    "from loss import *\n",
    "\n",
    "base_path = \"gs://leap-persistent/YueWang/SSH/data\"\n",
    "\n",
    "def open_zarr(path):\n",
    "    return xr.open_zarr(path, consolidated=True)\n",
    "\n",
    "train = open_zarr(f\"{base_path}/train_54_sst.zarr\").compute()\n",
    "val = open_zarr(f\"{base_path}/val_54_sst.zarr\").compute()\n",
    "zca = open_zarr(f\"{base_path}/zca_54_sst.zarr\").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c1c780-b5d2-4667-92f2-4645c22d50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(tensor, min_values=None, max_values=None, feature_range=(0, 1)):\n",
    "\n",
    "    num_channels = tensor.shape[1]\n",
    "    \n",
    "    if min_values is None:\n",
    "        min_values = torch.zeros(num_channels, device=tensor.device)\n",
    "        for c in range(num_channels):\n",
    "            min_values[c] = tensor[:, c, :, :].min()\n",
    "    \n",
    "    if max_values is None:\n",
    "        max_values = torch.zeros(num_channels, device=tensor.device)\n",
    "        for c in range(num_channels):\n",
    "            max_values[c] = tensor[:, c, :, :].max()\n",
    "    \n",
    "    normalized_tensor = torch.zeros_like(tensor)\n",
    "    scale = (feature_range[1] - feature_range[0])\n",
    "    \n",
    "    # Normalize each channel independently\n",
    "    for c in range(num_channels):\n",
    "        channel_range = max_values[c] - min_values[c]\n",
    "        \n",
    "        # Handle edge case where min and max are the same\n",
    "        if channel_range == 0:\n",
    "            normalized_tensor[:, c, :, :] = feature_range[0]\n",
    "        else:\n",
    "            # Apply min-max formula: (x - min) / (max - min) * scale + min_range\n",
    "            normalized_tensor[:, c, :, :] = (\n",
    "                (tensor[:, c, :, :] - min_values[c]) / channel_range\n",
    "            ) * scale + feature_range[0]\n",
    "    \n",
    "    return normalized_tensor, min_values, max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "927b5d79-a48d-4ce0-88c7-9744d909c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Prepare training data\n",
    "x_train_channel_0 = torch.from_numpy(train.ssh.values).float().unsqueeze(1).to(device)\n",
    "x_train_channel_1 = torch.from_numpy(train.sst.values).float().unsqueeze(1).to(device)\n",
    "x_train = torch.cat([x_train_channel_0, x_train_channel_1], dim=1)\n",
    "x_train_normalized, min_values, max_values = min_max_normalize(x_train)\n",
    "\n",
    "y_train_channel_0 = torch.from_numpy(train.ubm.values).float().unsqueeze(1).to(device)\n",
    "y_train_channel_1 = torch.from_numpy(train.zca_ubm.values).float().unsqueeze(1).to(device)\n",
    "y_train = torch.cat([y_train_channel_0, y_train_channel_1], dim=1)\n",
    "\n",
    "\n",
    "# Prepare validation data \n",
    "x_val_channel_0 = torch.from_numpy(val.ssh.values).float().unsqueeze(1).to(device)\n",
    "x_val_channel_1 = torch.from_numpy(val.sst.values).float().unsqueeze(1).to(device)\n",
    "x_val = torch.cat([x_val_channel_0, x_val_channel_1], dim=1)\n",
    "x_val_normalized, _, _ = min_max_normalize(x_val, min_values=min_values, max_values=max_values)\n",
    "\n",
    "y_val_channel_0 = torch.from_numpy(val.ubm.values).float().unsqueeze(1).to(device)\n",
    "y_val_channel_1 = torch.from_numpy(val.zca_ubm.values).float().unsqueeze(1).to(device)  \n",
    "y_val = torch.cat([y_val_channel_0, y_val_channel_1], dim=1)  \n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(x_train_normalized, y_train)\n",
    "val_dataset = TensorDataset(x_val_normalized, y_val)\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "Vt = torch.from_numpy(zca.zca_Vt_ubm.values).float().to(device)\n",
    "scale = torch.from_numpy(zca.zca_scale_ubm.values).float().to(device)\n",
    "mean = torch.from_numpy(zca.zca_mean_ubm.values).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20388e9-fe72-46ad-b9ad-56d79ce36828",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc2209e8-1b02-4892-8039-25d81c196df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 3.39e-01 (ZCA-NLL: 3.39e-01, MSE-Phys: 1.05e-04, Grad-Phys: 2.60e-04), Val Loss: 1.57e+00, Epoch Time: 152.95s\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory /home/jovyan/grl_final/checkpoints does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mVt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgrad_loss_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Weight for gradient loss in physical space\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmse_loss_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# Weight for MSE loss in physical space  \u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43mzca_nll_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Weight for ZCA Gaussian NLL loss\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/jovyan/grl_final/checkpoints/zca_sst.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GRL_ssh/train.py:164\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, Vt, scale, mean, optimizer, device, grad_loss_weight, mse_loss_weight, zca_nll_weight, save_path, n_epochs, patience)\u001b[0m\n\u001b[1;32m    153\u001b[0m     patience_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    154\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch,\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_losses\u001b[39m\u001b[38;5;124m'\u001b[39m: val_losses\n\u001b[1;32m    163\u001b[0m     }\n\u001b[0;32m--> 164\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest model so far saved at epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_val_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/torch/serialization.py:849\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    846\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 849\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    850\u001b[0m         _save(\n\u001b[1;32m    851\u001b[0m             obj,\n\u001b[1;32m    852\u001b[0m             opened_zipfile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    855\u001b[0m             _disable_byteorder_record,\n\u001b[1;32m    856\u001b[0m         )\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/torch/serialization.py:716\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/torch/serialization.py:687\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 687\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory /home/jovyan/grl_final/checkpoints does not exist."
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n",
    "# Create model and optimizer\n",
    "model = UNet(in_channels=2, out_channels=2, initial_features=32, depth=4)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "train_model(model, train_loader, val_loader,\n",
    "            Vt, scale, mean,  \n",
    "            optimizer, device,\n",
    "            grad_loss_weight=0.0,      # Weight for gradient loss in physical space\n",
    "            mse_loss_weight=0.0,       # Weight for MSE loss in physical space  \n",
    "            zca_nll_weight=1.0,        # Weight for ZCA Gaussian NLL loss\n",
    "            save_path='/home/jovyan/grl_final/checkpoints/zca_sst.pth',\n",
    "            n_epochs=2000,\n",
    "            patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce76193b-c957-4cda-b61c-19cbb3eacfd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
