{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f73b9994-d2e1-41fe-aaee-07d7f139cfcf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3da2a7-6377-478f-99d4-45d86852f069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/zarr/storage/_fsspec.py:256: UserWarning: fs (<gcsfs.core.GCSFileSystem object at 0x7b83d1ab6030>) was not created with `asynchronous=True`, this may lead to surprising behavior\n",
      "  return cls(fs=fs, path=path, read_only=read_only, allowed_exceptions=allowed_exceptions)\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/zarr/storage/_fsspec.py:256: UserWarning: fs (<gcsfs.core.GCSFileSystem object at 0x7b83d1ab6030>) was not created with `asynchronous=True`, this may lead to surprising behavior\n",
      "  return cls(fs=fs, path=path, read_only=read_only, allowed_exceptions=allowed_exceptions)\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/zarr/storage/_fsspec.py:256: UserWarning: fs (<gcsfs.core.GCSFileSystem object at 0x7b83d1ab6030>) was not created with `asynchronous=True`, this may lead to surprising behavior\n",
      "  return cls(fs=fs, path=path, read_only=read_only, allowed_exceptions=allowed_exceptions)\n",
      "/tmp/ipykernel_287/2914359427.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('/home/jovyan/GRL_ssh/checkpoints/sst_ssh.pth', map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 evaluation complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287/2914359427.py:137: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('/home/jovyan/GRL_ssh/checkpoints/ssh_input_only.pth', map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 evaluation complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287/2914359427.py:205: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('/home/jovyan/GRL_ssh/checkpoints/mse_loss_only.pth', map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 evaluation complete!\n",
      "Creating dataset for sst_ssh...\n",
      "Adding ensemble data with shape: (3645, 30, 1, 80, 80)\n",
      "Creating dataset for ssh_only...\n",
      "Adding ensemble data with shape: (3645, 30, 1, 80, 80)\n",
      "Creating dataset for mse_only...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from train import apply_inverse_zca_whitening_4d_torch\n",
    "from unet import UNet  \n",
    "from utils import *\n",
    "\n",
    "setup_random_seeds(42)\n",
    "device = get_device()\n",
    "\n",
    "base_path = \"gs://leap-persistent/YueWang/SSH/data\"\n",
    "storage_opts = {\"token\": \"cloud\", \"asynchronous\": False}\n",
    "\n",
    "train = open_zarr(f\"{base_path}/train_80_sst.zarr\", storage_opts)\n",
    "test = open_zarr(f\"{base_path}/test_80_sst.zarr\", storage_opts)\n",
    "zca = open_zarr(f\"{base_path}/zca_80.zarr\", storage_opts)\n",
    "\n",
    "Vt = torch.from_numpy(zca.ubm_Vt.values).float().to(device)\n",
    "scale = torch.from_numpy(zca.ubm_scale.values).float().to(device)\n",
    "mean = torch.from_numpy(zca.ubm_mean.values).float().to(device)\n",
    "\n",
    "# Model 1: ZCA NLL Loss with SSH+SST input\n",
    "\n",
    "# Prepare training data for normalization statistics (SSH+SST)\n",
    "x_train_ssh = torch.from_numpy(train.ssh.values).float().unsqueeze(1).to(device)\n",
    "x_train_sst = torch.from_numpy(train.sst.values).float().unsqueeze(1).to(device)\n",
    "x_train = torch.cat([x_train_ssh, x_train_sst], dim=1)\n",
    "x_train_normalized, min_vals_sst, max_vals_sst = min_max_normalize(x_train)\n",
    "\n",
    "# Prepare test data (SSH+SST) \n",
    "x_test_ssh_original = torch.from_numpy(test.ssh.values).float().unsqueeze(1).to(device)\n",
    "x_test_sst_original = torch.from_numpy(test.sst.values).float().unsqueeze(1).to(device)\n",
    "x_test_original = torch.cat([x_test_ssh_original, x_test_sst_original], dim=1)\n",
    "\n",
    "# Normalize test data for model input\n",
    "x_test_normalized, _, _ = min_max_normalize(x_test_original, min_vals_sst, max_vals_sst)\n",
    "\n",
    "# Prepare test targets\n",
    "y_test_physical = torch.from_numpy(test.ubm.values).float().unsqueeze(1).to(device)\n",
    "y_test_zca = torch.from_numpy(test.zca_ubm.values).float().unsqueeze(1).to(device)\n",
    "y_test = torch.cat([y_test_physical, y_test_zca], dim=1)\n",
    "\n",
    "# Create test dataset and loader\n",
    "test_dataset_sst = TensorDataset(x_test_normalized, y_test)\n",
    "test_loader_sst = DataLoader(test_dataset_sst, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load model\n",
    "model_sst_ssh = UNet(in_channels=2, out_channels=2, initial_features=32, depth=4)\n",
    "model_sst_ssh.to(device)\n",
    "\n",
    "checkpoint = torch.load('/home/jovyan/GRL_ssh/checkpoints/sst_ssh.pth', map_location=device)\n",
    "model_sst_ssh.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Evaluate model\n",
    "model_sst_ssh.eval()\n",
    "results_sst_ssh = {\n",
    "    'ssh': [], 'sst': [], 'ubm_true': [], 'bm_true': [],\n",
    "    'ubm_pred_mu': [], 'bm_pred_mu': [],\n",
    "    'ubm_pred_ensembles': [], 'bm_pred_ensembles': []\n",
    "}\n",
    "\n",
    "sample_indices = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (batch_x, batch_y) in enumerate(test_loader_sst):\n",
    "        \n",
    "        batch_start = i * test_loader_sst.batch_size\n",
    "        batch_end = min(batch_start + test_loader_sst.batch_size, len(test_dataset_sst))\n",
    "        current_batch_indices = list(range(batch_start, batch_end))\n",
    "        sample_indices.extend(current_batch_indices)\n",
    "        \n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y_physical = batch_y[:, 0:1, ...].to(device)\n",
    "\n",
    "        outputs = model_sst_ssh(batch_x)\n",
    "        \n",
    "        ssh_batch_original = x_test_ssh_original[current_batch_indices]\n",
    "        sst_batch_original = x_test_sst_original[current_batch_indices]\n",
    "        \n",
    "        ubm_true = batch_y_physical\n",
    "        bm_true = ssh_batch_original - ubm_true\n",
    "        \n",
    "        # Predicted mean in physical space\n",
    "        mu_zca = outputs[:, 0, ...]\n",
    "        log_sigma_zca = outputs[:, 1, ...]\n",
    "        mu_zca_expanded = mu_zca.unsqueeze(1)\n",
    "        ubm_pred_mu = apply_inverse_zca_whitening_4d_torch(mu_zca_expanded, Vt, scale, mean)\n",
    "        \n",
    "        bm_pred_mu = ssh_batch_original - ubm_pred_mu\n",
    "        \n",
    "        # Generate ensemble samples\n",
    "        zca_samples = generate_gaussian_samples(mu_zca, log_sigma_zca, n_samples=30)\n",
    "        B, n_samples, H, W = zca_samples.shape\n",
    "        zca_samples_flat = zca_samples.reshape(B * n_samples, 1, H, W)\n",
    "        ubm_samples_flat = apply_inverse_zca_whitening_4d_torch(zca_samples_flat, Vt, scale, mean)\n",
    "        ubm_samples = ubm_samples_flat.reshape(B, n_samples, 1, H, W)\n",
    "        \n",
    "        # Use original SSH for ensemble BM calculation\n",
    "        ssh_expanded = ssh_batch_original.unsqueeze(1).expand(-1, n_samples, -1, -1, -1)\n",
    "        bm_samples = ssh_expanded - ubm_samples\n",
    "        \n",
    "        # Store results \n",
    "        results_sst_ssh['ssh'].append(ssh_batch_original.cpu().numpy())\n",
    "        results_sst_ssh['sst'].append(sst_batch_original.cpu().numpy())\n",
    "        results_sst_ssh['ubm_true'].append(ubm_true.cpu().numpy())\n",
    "        results_sst_ssh['bm_true'].append(bm_true.cpu().numpy())\n",
    "        results_sst_ssh['ubm_pred_mu'].append(ubm_pred_mu.cpu().numpy())\n",
    "        results_sst_ssh['bm_pred_mu'].append(bm_pred_mu.cpu().numpy())\n",
    "        results_sst_ssh['ubm_pred_ensembles'].append(ubm_samples.cpu().numpy())\n",
    "        results_sst_ssh['bm_pred_ensembles'].append(bm_samples.cpu().numpy())\n",
    "\n",
    "for key in results_sst_ssh:\n",
    "    results_sst_ssh[key] = np.concatenate(results_sst_ssh[key], axis=0)\n",
    "\n",
    "print(\"Model 1 evaluation complete!\")\n",
    "\n",
    "# Model 2: SSH input only\n",
    "\n",
    "# Prepare training data for normalization statistics (SSH only)\n",
    "x_train_ssh_only = torch.from_numpy(train.ssh.values).float().unsqueeze(1).to(device)\n",
    "x_train_normalized_ssh, min_vals_ssh, max_vals_ssh = min_max_normalize(x_train_ssh_only)\n",
    "\n",
    "# Prepare test data (SSH only)\n",
    "x_test_ssh_only_original = torch.from_numpy(test.ssh.values).float().unsqueeze(1).to(device)\n",
    "x_test_normalized_ssh, _, _ = min_max_normalize(x_test_ssh_only_original, min_vals_ssh, max_vals_ssh)\n",
    "\n",
    "# Create test dataset and loader\n",
    "test_dataset_ssh = TensorDataset(x_test_normalized_ssh, y_test)\n",
    "test_loader_ssh = DataLoader(test_dataset_ssh, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load model\n",
    "model_ssh_only = UNet(in_channels=1, out_channels=2, initial_features=32, depth=4)\n",
    "model_ssh_only.to(device)\n",
    "\n",
    "checkpoint = torch.load('/home/jovyan/GRL_ssh/checkpoints/ssh_input_only.pth', map_location=device)\n",
    "model_ssh_only.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Evaluate model\n",
    "model_ssh_only.eval()\n",
    "results_ssh_only = {\n",
    "    'ssh': [], 'ubm_true': [], 'bm_true': [],\n",
    "    'ubm_pred_mu': [], 'bm_pred_mu': [],\n",
    "    'ubm_pred_ensembles': [], 'bm_pred_ensembles': []\n",
    "}\n",
    "\n",
    "sample_indices_ssh = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (batch_x, batch_y) in enumerate(test_loader_ssh):\n",
    "        \n",
    "        batch_start = i * test_loader_ssh.batch_size\n",
    "        batch_end = min(batch_start + test_loader_ssh.batch_size, len(test_dataset_ssh))\n",
    "        current_batch_indices = list(range(batch_start, batch_end))\n",
    "        sample_indices_ssh.extend(current_batch_indices)\n",
    "            \n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y_physical = batch_y[:, 0:1, ...].to(device)\n",
    "        \n",
    "        outputs = model_ssh_only(batch_x)\n",
    "        \n",
    "        ssh_batch_original = x_test_ssh_only_original[current_batch_indices]\n",
    "        \n",
    "        ubm_true = batch_y_physical\n",
    "        bm_true = ssh_batch_original - ubm_true\n",
    "        \n",
    "        # Predicted mean in physical space\n",
    "        mu_zca = outputs[:, 0, ...]\n",
    "        log_sigma_zca = outputs[:, 1, ...]\n",
    "        mu_zca_expanded = mu_zca.unsqueeze(1)\n",
    "        ubm_pred_mu = apply_inverse_zca_whitening_4d_torch(mu_zca_expanded, Vt, scale, mean)\n",
    "        # BM prediction using original SSH scale\n",
    "        bm_pred_mu = ssh_batch_original - ubm_pred_mu\n",
    "        \n",
    "        # Generate ensemble samples\n",
    "        zca_samples = generate_gaussian_samples(mu_zca, log_sigma_zca, n_samples=30)\n",
    "        B, n_samples, H, W = zca_samples.shape\n",
    "        zca_samples_flat = zca_samples.reshape(B * n_samples, 1, H, W)\n",
    "        ubm_samples_flat = apply_inverse_zca_whitening_4d_torch(zca_samples_flat, Vt, scale, mean)\n",
    "        ubm_samples = ubm_samples_flat.reshape(B, n_samples, 1, H, W)\n",
    "        \n",
    "        # Use original SSH for ensemble BM calculation\n",
    "        ssh_expanded = ssh_batch_original.unsqueeze(1).expand(-1, n_samples, -1, -1, -1)\n",
    "        bm_samples = ssh_expanded - ubm_samples\n",
    "        \n",
    "        # Store results \n",
    "        results_ssh_only['ssh'].append(ssh_batch_original.cpu().numpy())\n",
    "        results_ssh_only['ubm_true'].append(ubm_true.cpu().numpy())\n",
    "        results_ssh_only['bm_true'].append(bm_true.cpu().numpy())\n",
    "        results_ssh_only['ubm_pred_mu'].append(ubm_pred_mu.cpu().numpy())\n",
    "        results_ssh_only['bm_pred_mu'].append(bm_pred_mu.cpu().numpy())\n",
    "        results_ssh_only['ubm_pred_ensembles'].append(ubm_samples.cpu().numpy())\n",
    "        results_ssh_only['bm_pred_ensembles'].append(bm_samples.cpu().numpy())\n",
    "\n",
    "for key in results_ssh_only:\n",
    "    results_ssh_only[key] = np.concatenate(results_ssh_only[key], axis=0)\n",
    "\n",
    "print(\"Model 2 evaluation complete!\")\n",
    "\n",
    "# Model 3: MSE loss only\n",
    "model_mse_only = UNet(in_channels=2, out_channels=2, initial_features=32, depth=4)\n",
    "model_mse_only.to(device)\n",
    "\n",
    "checkpoint = torch.load('/home/jovyan/GRL_ssh/checkpoints/mse_loss_only.pth', map_location=device)\n",
    "model_mse_only.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Evaluate model\n",
    "model_mse_only.eval()\n",
    "results_mse_only = {\n",
    "    'ssh': [], 'sst': [], 'ubm_true': [], 'bm_true': [],\n",
    "    'ubm_pred_mu': [], 'bm_pred_mu': []\n",
    "}\n",
    "\n",
    "sample_indices_mse = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (batch_x, batch_y) in enumerate(test_loader_sst):  \n",
    "        \n",
    "        batch_start = i * test_loader_sst.batch_size\n",
    "        batch_end = min(batch_start + test_loader_sst.batch_size, len(test_dataset_sst))\n",
    "        current_batch_indices = list(range(batch_start, batch_end))\n",
    "        sample_indices_mse.extend(current_batch_indices)\n",
    "            \n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y_physical = batch_y[:, 0:1, ...].to(device)\n",
    "        \n",
    "        outputs = model_mse_only(batch_x)\n",
    "        \n",
    "        # Use original scale SSH and SST for BM calculation\n",
    "        ssh_batch_original = x_test_ssh_original[current_batch_indices]\n",
    "        sst_batch_original = x_test_sst_original[current_batch_indices]\n",
    "        \n",
    "        ubm_true = batch_y_physical\n",
    "        bm_true = ssh_batch_original - ubm_true\n",
    "        \n",
    "        # For MSE model, only use mean prediction (no sampling)\n",
    "        mu_zca_expanded = outputs[:, 0:1, ...]  # Use first channel as mean\n",
    "        ubm_pred_mu = apply_inverse_zca_whitening_4d_torch(mu_zca_expanded, Vt, scale, mean)\n",
    "        # BM prediction using original SSH scale\n",
    "        bm_pred_mu = ssh_batch_original - ubm_pred_mu\n",
    "        \n",
    "        # Store results\n",
    "        results_mse_only['ssh'].append(ssh_batch_original.cpu().numpy())\n",
    "        results_mse_only['sst'].append(sst_batch_original.cpu().numpy())\n",
    "        results_mse_only['ubm_true'].append(ubm_true.cpu().numpy())\n",
    "        results_mse_only['bm_true'].append(bm_true.cpu().numpy())\n",
    "        results_mse_only['ubm_pred_mu'].append(ubm_pred_mu.cpu().numpy())\n",
    "        results_mse_only['bm_pred_mu'].append(bm_pred_mu.cpu().numpy())\n",
    "\n",
    "for key in results_mse_only:\n",
    "    results_mse_only[key] = np.concatenate(results_mse_only[key], axis=0)\n",
    "\n",
    "print(\"Model 3 evaluation complete!\")\n",
    "\n",
    "# Create xarray datasets and save results\n",
    "models_results = [\n",
    "    ('sst_ssh', results_sst_ssh, True, True),\n",
    "    ('ssh_only', results_ssh_only, True, False), \n",
    "    ('mse_only', results_mse_only, False, True)\n",
    "]\n",
    "\n",
    "# Store all datasets\n",
    "eval_datasets = {}\n",
    "\n",
    "for model_name, results, has_ensembles, has_sst in models_results:\n",
    "    print(f\"Creating dataset for {model_name}...\")\n",
    "    \n",
    "    eval_dataset = create_evaluation_dataset(results, model_name, has_ensembles, has_sst)\n",
    "    \n",
    "    # Store the dataset\n",
    "    eval_datasets[model_name] = eval_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8677b355-4d83-4285-8024-df2ae8ac457e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Structure View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b834b711-fcd1-4b27-abb1-7e9b0494c1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3645, 80, 80)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_datasets['sst_ssh'].ubm_truth\n",
    "eval_datasets['sst_ssh'].bm_truth\n",
    "eval_datasets['sst_ssh'].ubm_pred_mean\n",
    "eval_datasets['sst_ssh'].bm_pred_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ecfec64-738c-471e-91fc-c951e7f7ce29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3645, 80, 80)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_datasets['ssh_only'].ubm_truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f8223c1-c935-43e3-a4a2-2f02e58f55a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(\n",
       "    --jp-content-font-color0,\n",
       "    var(--pst-color-text-base rgba(0, 0, 0, 1))\n",
       "  );\n",
       "  --xr-font-color2: var(\n",
       "    --jp-content-font-color2,\n",
       "    var(--pst-color-text-base, rgba(0, 0, 0, 0.54))\n",
       "  );\n",
       "  --xr-font-color3: var(\n",
       "    --jp-content-font-color3,\n",
       "    var(--pst-color-text-base, rgba(0, 0, 0, 0.38))\n",
       "  );\n",
       "  --xr-border-color: var(\n",
       "    --jp-border-color2,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 10))\n",
       "  );\n",
       "  --xr-disabled-color: var(\n",
       "    --jp-layout-color3,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 40))\n",
       "  );\n",
       "  --xr-background-color: var(\n",
       "    --jp-layout-color0,\n",
       "    var(--pst-color-on-background, white)\n",
       "  );\n",
       "  --xr-background-color-row-even: var(\n",
       "    --jp-layout-color1,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 5))\n",
       "  );\n",
       "  --xr-background-color-row-odd: var(\n",
       "    --jp-layout-color2,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 15))\n",
       "  );\n",
       "}\n",
       "\n",
       "html[theme=\"dark\"],\n",
       "html[data-theme=\"dark\"],\n",
       "body[data-theme=\"dark\"],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: var(\n",
       "    --jp-content-font-color0,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 1))\n",
       "  );\n",
       "  --xr-font-color2: var(\n",
       "    --jp-content-font-color2,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 0.54))\n",
       "  );\n",
       "  --xr-font-color3: var(\n",
       "    --jp-content-font-color3,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 0.38))\n",
       "  );\n",
       "  --xr-border-color: var(\n",
       "    --jp-border-color2,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 10))\n",
       "  );\n",
       "  --xr-disabled-color: var(\n",
       "    --jp-layout-color3,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 40))\n",
       "  );\n",
       "  --xr-background-color: var(\n",
       "    --jp-layout-color0,\n",
       "    var(--pst-color-on-background, #111111)\n",
       "  );\n",
       "  --xr-background-color-row-even: var(\n",
       "    --jp-layout-color1,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 5))\n",
       "  );\n",
       "  --xr-background-color-row-odd: var(\n",
       "    --jp-layout-color2,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 15))\n",
       "  );\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: inline-block;\n",
       "  opacity: 0;\n",
       "  height: 0;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "  border: 2px solid transparent !important;\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:focus + label {\n",
       "  border: 2px solid var(--xr-font-color0) !important;\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: \"►\";\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: \"▼\";\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: \"(\";\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: \")\";\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: \",\";\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  border-color: var(--xr-background-color-row-odd);\n",
       "  margin-bottom: 0;\n",
       "  padding-top: 2px;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "  border-color: var(--xr-background-color-row-even);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  border-top: 2px dotted var(--xr-background-color);\n",
       "  padding-bottom: 20px !important;\n",
       "  padding-top: 10px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in + label,\n",
       ".xr-var-data-in + label,\n",
       ".xr-index-data-in + label {\n",
       "  padding: 0 1px;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-data > pre,\n",
       ".xr-index-data > pre,\n",
       ".xr-var-data > table > tbody > tr {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked + label > .xr-icon-file-text2,\n",
       ".xr-var-data-in:checked + label > .xr-icon-database,\n",
       ".xr-index-data-in:checked + label > .xr-icon-database {\n",
       "  color: var(--xr-font-color0);\n",
       "  filter: drop-shadow(1px 1px 5px var(--xr-font-color2));\n",
       "  stroke-width: 0.8px;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 560MB\n",
       "Dimensions:        (sample: 3645, i: 80, j: 80)\n",
       "Coordinates:\n",
       "  * sample         (sample) int64 29kB 0 1 2 3 4 5 ... 3640 3641 3642 3643 3644\n",
       "  * i              (i) int64 640B 0 1 2 3 4 5 6 7 8 ... 72 73 74 75 76 77 78 79\n",
       "  * j              (j) int64 640B 0 1 2 3 4 5 6 7 8 ... 72 73 74 75 76 77 78 79\n",
       "Data variables:\n",
       "    ssh            (sample, i, j) float32 93MB 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
       "    ubm_truth      (sample, i, j) float32 93MB nan nan nan nan ... nan nan nan\n",
       "    bm_truth       (sample, i, j) float32 93MB nan nan nan nan ... nan nan nan\n",
       "    ubm_pred_mean  (sample, i, j) float32 93MB -0.002933 -0.003443 ... 0.007049\n",
       "    bm_pred_mean   (sample, i, j) float32 93MB 0.002933 0.003443 ... -0.007049\n",
       "    sst            (sample, i, j) float32 93MB 0.06335 0.05314 ... 0.0 0.0</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-cb2f4858-f3fd-4552-8d39-1630fc5d5912' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-cb2f4858-f3fd-4552-8d39-1630fc5d5912' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>sample</span>: 3645</li><li><span class='xr-has-index'>i</span>: 80</li><li><span class='xr-has-index'>j</span>: 80</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-059303dc-0388-4ddc-aa7f-e909a734f275' class='xr-section-summary-in' type='checkbox'  checked><label for='section-059303dc-0388-4ddc-aa7f-e909a734f275' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>sample</span></div><div class='xr-var-dims'>(sample)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 1 2 3 4 ... 3641 3642 3643 3644</div><input id='attrs-d4333d1a-9475-49e3-8d07-29f658c45d3f' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-d4333d1a-9475-49e3-8d07-29f658c45d3f' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e140b86a-fed8-44e5-81de-aaa6dac6a177' class='xr-var-data-in' type='checkbox'><label for='data-e140b86a-fed8-44e5-81de-aaa6dac6a177' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([   0,    1,    2, ..., 3642, 3643, 3644], shape=(3645,))</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>i</span></div><div class='xr-var-dims'>(i)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 1 2 3 4 5 6 ... 74 75 76 77 78 79</div><input id='attrs-159ad105-4972-4474-9bf5-f34800c01709' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-159ad105-4972-4474-9bf5-f34800c01709' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1e772309-838e-40b0-ab8e-07aa9244706c' class='xr-var-data-in' type='checkbox'><label for='data-1e772309-838e-40b0-ab8e-07aa9244706c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
       "       72, 73, 74, 75, 76, 77, 78, 79])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>j</span></div><div class='xr-var-dims'>(j)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 1 2 3 4 5 6 ... 74 75 76 77 78 79</div><input id='attrs-a9af0826-44ee-4f5a-851e-1908d2b68fc7' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-a9af0826-44ee-4f5a-851e-1908d2b68fc7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-0181407f-5054-4c8c-85eb-a84658d873be' class='xr-var-data-in' type='checkbox'><label for='data-0181407f-5054-4c8c-85eb-a84658d873be' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
       "       72, 73, 74, 75, 76, 77, 78, 79])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-961e4208-6f4b-4270-a1e4-2fa5536e7b5a' class='xr-section-summary-in' type='checkbox'  checked><label for='section-961e4208-6f4b-4270-a1e4-2fa5536e7b5a' class='xr-section-summary' >Data variables: <span>(6)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>ssh</span></div><div class='xr-var-dims'>(sample, i, j)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0</div><input id='attrs-c6657453-22f5-4e88-b6ed-f38c1c30681c' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-c6657453-22f5-4e88-b6ed-f38c1c30681c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4417bd82-0866-405d-a3ca-f91f2f2baf65' class='xr-var-data-in' type='checkbox'><label for='data-4417bd82-0866-405d-a3ca-f91f2f2baf65' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.9875431 ,\n",
       "         -0.98513395, -0.98261875],\n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.9878764 ,\n",
       "         -0.9854802 , -0.9830881 ],\n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.98815304,\n",
       "         -0.9857874 , -0.9833264 ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "...\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]], shape=(3645, 80, 80), dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>ubm_truth</span></div><div class='xr-var-dims'>(sample, i, j)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-6a25d935-a9ef-4f6e-bd63-7e8f2712106d' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-6a25d935-a9ef-4f6e-bd63-7e8f2712106d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-7bc43bd6-d4de-4540-be49-507f418c3095' class='xr-var-data-in' type='checkbox'><label for='data-7bc43bd6-d4de-4540-be49-507f418c3095' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[[           nan,            nan,            nan, ...,\n",
       "                    nan,            nan,            nan],\n",
       "        [           nan,            nan,            nan, ...,\n",
       "                    nan,            nan,            nan],\n",
       "        [           nan,            nan,            nan, ...,\n",
       "                    nan,            nan,            nan],\n",
       "        ...,\n",
       "        [           nan,            nan,            nan, ...,\n",
       "          3.8802624e-05, -4.3153763e-05, -9.9837780e-05],\n",
       "        [           nan,            nan,            nan, ...,\n",
       "         -4.1687489e-04, -4.5609474e-04, -5.5640936e-04],\n",
       "        [           nan,            nan,            nan, ...,\n",
       "         -8.8351965e-04, -9.0229511e-04, -8.8536739e-04]],\n",
       "\n",
       "       [[           nan,            nan,            nan, ...,\n",
       "                    nan,            nan,            nan],\n",
       "        [           nan,            nan,            nan, ...,\n",
       "                    nan,            nan,            nan],\n",
       "        [           nan,            nan,            nan, ...,\n",
       "                    nan,            nan,            nan],\n",
       "...\n",
       "                    nan,            nan,            nan],\n",
       "        [           nan,            nan,            nan, ...,\n",
       "                    nan,            nan,            nan],\n",
       "        [           nan,            nan,            nan, ...,\n",
       "                    nan,            nan,            nan]],\n",
       "\n",
       "       [[           nan,            nan,            nan, ...,\n",
       "                    nan,            nan,            nan],\n",
       "        [           nan,            nan,            nan, ...,\n",
       "                    nan,            nan,            nan],\n",
       "        [           nan,            nan,            nan, ...,\n",
       "                    nan,            nan,            nan],\n",
       "        ...,\n",
       "        [           nan,            nan,            nan, ...,\n",
       "                    nan,            nan,            nan],\n",
       "        [           nan,            nan,            nan, ...,\n",
       "                    nan,            nan,            nan],\n",
       "        [           nan,            nan,            nan, ...,\n",
       "                    nan,            nan,            nan]]],\n",
       "      shape=(3645, 80, 80), dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>bm_truth</span></div><div class='xr-var-dims'>(sample, i, j)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-8108f279-993c-4c94-b48a-1febd9d6b3d3' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-8108f279-993c-4c94-b48a-1febd9d6b3d3' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b339b673-ca27-4447-a670-8d33595cc462' class='xr-var-data-in' type='checkbox'><label for='data-b339b673-ca27-4447-a670-8d33595cc462' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[[        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan],\n",
       "        [        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan],\n",
       "        [        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan],\n",
       "        ...,\n",
       "        [        nan,         nan,         nan, ..., -0.9875819 ,\n",
       "         -0.9850908 , -0.9825189 ],\n",
       "        [        nan,         nan,         nan, ..., -0.98745954,\n",
       "         -0.9850241 , -0.98253167],\n",
       "        [        nan,         nan,         nan, ..., -0.9872695 ,\n",
       "         -0.9848851 , -0.982441  ]],\n",
       "\n",
       "       [[        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan],\n",
       "        [        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan],\n",
       "        [        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan],\n",
       "...\n",
       "        [        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan],\n",
       "        [        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan],\n",
       "        [        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan]],\n",
       "\n",
       "       [[        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan],\n",
       "        [        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan],\n",
       "        [        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan],\n",
       "        ...,\n",
       "        [        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan],\n",
       "        [        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan],\n",
       "        [        nan,         nan,         nan, ...,         nan,\n",
       "                 nan,         nan]]], shape=(3645, 80, 80), dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>ubm_pred_mean</span></div><div class='xr-var-dims'>(sample, i, j)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>-0.002933 -0.003443 ... 0.007049</div><input id='attrs-9ef20664-cdda-4eb7-b59b-0c1a531ca691' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-9ef20664-cdda-4eb7-b59b-0c1a531ca691' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-68ba928a-ba82-4e14-a0d9-46796bf8f98d' class='xr-var-data-in' type='checkbox'><label for='data-68ba928a-ba82-4e14-a0d9-46796bf8f98d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[[-0.00293314, -0.0034431 , -0.00368952, ..., -0.00088373,\n",
       "          0.00069513,  0.00175922],\n",
       "        [-0.00282574, -0.0033408 , -0.00367189, ..., -0.00250512,\n",
       "          0.00056246,  0.00221479],\n",
       "        [-0.00269613, -0.00304379, -0.00348506, ..., -0.00548835,\n",
       "         -0.00028835,  0.00244894],\n",
       "        ...,\n",
       "        [-0.00046952, -0.00021022, -0.00014752, ..., -0.00521447,\n",
       "         -0.0046018 , -0.00435693],\n",
       "        [ 0.00010305,  0.0002352 ,  0.00019241, ..., -0.0051528 ,\n",
       "         -0.00462525, -0.00430682],\n",
       "        [ 0.00031754,  0.00064528,  0.0005356 , ..., -0.00542153,\n",
       "         -0.00499446, -0.00473361]],\n",
       "\n",
       "       [[-0.00383173, -0.00366517, -0.00373997, ..., -0.00125114,\n",
       "         -0.00187183, -0.00202501],\n",
       "        [-0.00346876, -0.00354658, -0.003609  , ..., -0.00157129,\n",
       "         -0.0019854 , -0.00218371],\n",
       "        [-0.00295711, -0.00304319, -0.00323059, ..., -0.0020959 ,\n",
       "         -0.00198655, -0.00185573],\n",
       "...\n",
       "        [ 0.00083054,  0.00045667,  0.00073783, ..., -0.02376245,\n",
       "         -0.01343514, -0.00540997],\n",
       "        [ 0.0026324 ,  0.00219466,  0.00238695, ..., -0.00756494,\n",
       "         -0.0024204 ,  0.00097234],\n",
       "        [ 0.00453468,  0.00420022,  0.00349459, ...,  0.00719559,\n",
       "          0.00728595,  0.00704876]],\n",
       "\n",
       "       [[-0.00441667, -0.00457221, -0.00488237, ...,  0.00893092,\n",
       "          0.01151186,  0.01316027],\n",
       "        [-0.00392641, -0.00405237, -0.00476097, ...,  0.00732007,\n",
       "          0.01222298,  0.01467438],\n",
       "        [-0.00374704, -0.00391086, -0.00505148, ...,  0.00456589,\n",
       "          0.01139048,  0.01519408],\n",
       "        ...,\n",
       "        [ 0.00083054,  0.00045667,  0.00073783, ..., -0.02376245,\n",
       "         -0.01343514, -0.00540997],\n",
       "        [ 0.0026324 ,  0.00219466,  0.00238695, ..., -0.00756494,\n",
       "         -0.0024204 ,  0.00097234],\n",
       "        [ 0.00453468,  0.00420022,  0.00349459, ...,  0.00719559,\n",
       "          0.00728595,  0.00704876]]], shape=(3645, 80, 80), dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>bm_pred_mean</span></div><div class='xr-var-dims'>(sample, i, j)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.002933 0.003443 ... -0.007049</div><input id='attrs-327f7594-2b17-4c30-b8a3-05bf1289f1ef' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-327f7594-2b17-4c30-b8a3-05bf1289f1ef' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9a283a8a-4173-4feb-a77c-a7e1973b6538' class='xr-var-data-in' type='checkbox'><label for='data-9a283a8a-4173-4feb-a77c-a7e1973b6538' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[[ 2.93314364e-03,  3.44309979e-03,  3.68951773e-03, ...,\n",
       "          8.83728208e-04, -6.95129158e-04, -1.75922201e-03],\n",
       "        [ 2.82574398e-03,  3.34080309e-03,  3.67188570e-03, ...,\n",
       "          2.50512338e-03, -5.62455796e-04, -2.21479032e-03],\n",
       "        [ 2.69613066e-03,  3.04378662e-03,  3.48506193e-03, ...,\n",
       "          5.48835425e-03,  2.88354815e-04, -2.44894112e-03],\n",
       "        ...,\n",
       "        [ 4.69521096e-04,  2.10222570e-04,  1.47518920e-04, ...,\n",
       "         -9.82328653e-01, -9.80532169e-01, -9.78261828e-01],\n",
       "        [-1.03045139e-04, -2.35203537e-04, -1.92413951e-04, ...,\n",
       "         -9.82723594e-01, -9.80854928e-01, -9.78781283e-01],\n",
       "        [-3.17540456e-04, -6.45277556e-04, -5.35597792e-04, ...,\n",
       "         -9.82731521e-01, -9.80792940e-01, -9.78592753e-01]],\n",
       "\n",
       "       [[ 3.83172650e-03,  3.66516877e-03,  3.73996887e-03, ...,\n",
       "          1.25114177e-03,  1.87182636e-03,  2.02501193e-03],\n",
       "        [ 3.46875773e-03,  3.54658207e-03,  3.60899675e-03, ...,\n",
       "          1.57128810e-03,  1.98539742e-03,  2.18370697e-03],\n",
       "        [ 2.95710587e-03,  3.04318964e-03,  3.23058851e-03, ...,\n",
       "          2.09590211e-03,  1.98655133e-03,  1.85573089e-03],\n",
       "...\n",
       "          2.37624459e-02,  1.34351421e-02,  5.40996995e-03],\n",
       "        [-2.63240421e-03, -2.19466211e-03, -2.38694809e-03, ...,\n",
       "          7.56493956e-03,  2.42040120e-03, -9.72341688e-04],\n",
       "        [-4.53467760e-03, -4.20022476e-03, -3.49459471e-03, ...,\n",
       "         -7.19559146e-03, -7.28595443e-03, -7.04876054e-03]],\n",
       "\n",
       "       [[ 4.41667251e-03,  4.57220757e-03,  4.88237431e-03, ...,\n",
       "         -8.93091504e-03, -1.15118632e-02, -1.31602678e-02],\n",
       "        [ 3.92640848e-03,  4.05236520e-03,  4.76097036e-03, ...,\n",
       "         -7.32006645e-03, -1.22229811e-02, -1.46743804e-02],\n",
       "        [ 3.74704367e-03,  3.91085725e-03,  5.05148014e-03, ...,\n",
       "         -4.56589274e-03, -1.13904765e-02, -1.51940836e-02],\n",
       "        ...,\n",
       "        [-8.30538804e-04, -4.56669979e-04, -7.37834838e-04, ...,\n",
       "          2.37624459e-02,  1.34351421e-02,  5.40996995e-03],\n",
       "        [-2.63240421e-03, -2.19466211e-03, -2.38694809e-03, ...,\n",
       "          7.56493956e-03,  2.42040120e-03, -9.72341688e-04],\n",
       "        [-4.53467760e-03, -4.20022476e-03, -3.49459471e-03, ...,\n",
       "         -7.19559146e-03, -7.28595443e-03, -7.04876054e-03]]],\n",
       "      shape=(3645, 80, 80), dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sst</span></div><div class='xr-var-dims'>(sample, i, j)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.06335 0.05314 0.04311 ... 0.0 0.0</div><input id='attrs-26c0dbc0-8770-415a-aaa7-fe39ef5e2e76' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-26c0dbc0-8770-415a-aaa7-fe39ef5e2e76' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-fff3a354-6b00-499b-970a-64943204cb82' class='xr-var-data-in' type='checkbox'><label for='data-fff3a354-6b00-499b-970a-64943204cb82' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[[ 0.0633513 ,  0.0531364 ,  0.0431099 , ..., -0.08406647,\n",
       "         -0.01475945,  0.05133429],\n",
       "        [ 0.09089742,  0.0775504 ,  0.06604463, ..., -0.08611035,\n",
       "         -0.01710306,  0.04756058],\n",
       "        [ 0.13465838,  0.11634272,  0.09942938, ..., -0.09098018,\n",
       "         -0.02154351,  0.04309926],\n",
       "        ...,\n",
       "        [-0.12097012, -0.0827501 , -0.02774495, ...,  0.72168005,\n",
       "          0.7616945 ,  0.776136  ],\n",
       "        [-0.07432289, -0.00296129,  0.08331981, ...,  0.72576654,\n",
       "          0.76498467,  0.7796    ],\n",
       "        [ 0.02056021,  0.10879346,  0.1631293 , ...,  0.73383856,\n",
       "          0.7644877 ,  0.7778805 ]],\n",
       "\n",
       "       [[ 0.1101438 ,  0.17575079,  0.263021  , ...,  1.3611863 ,\n",
       "          1.3501372 ,  1.3332578 ],\n",
       "        [ 0.10504638,  0.17449847,  0.26657817, ...,  1.370343  ,\n",
       "          1.361524  ,  1.352816  ],\n",
       "        [ 0.099796  ,  0.17123082,  0.26822317, ...,  1.380578  ,\n",
       "          1.3726778 ,  1.3617136 ],\n",
       "...\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]], shape=(3645, 80, 80), dtype=float32)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-eb9faa93-5b42-4c19-95cc-101f5f040674' class='xr-section-summary-in' type='checkbox'  ><label for='section-eb9faa93-5b42-4c19-95cc-101f5f040674' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>sample</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-ea494fe9-b936-454b-bdaa-6bb4b656df73' class='xr-index-data-in' type='checkbox'/><label for='index-ea494fe9-b936-454b-bdaa-6bb4b656df73' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "       ...\n",
       "       3635, 3636, 3637, 3638, 3639, 3640, 3641, 3642, 3643, 3644],\n",
       "      dtype=&#x27;int64&#x27;, name=&#x27;sample&#x27;, length=3645))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>i</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-b0972942-d5da-4b19-bca8-96960b3385c7' class='xr-index-data-in' type='checkbox'/><label for='index-b0972942-d5da-4b19-bca8-96960b3385c7' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
       "       72, 73, 74, 75, 76, 77, 78, 79],\n",
       "      dtype=&#x27;int64&#x27;, name=&#x27;i&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>j</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-d97c83a8-0958-4332-a7cc-682c9a1f1e62' class='xr-index-data-in' type='checkbox'/><label for='index-d97c83a8-0958-4332-a7cc-682c9a1f1e62' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
       "       72, 73, 74, 75, 76, 77, 78, 79],\n",
       "      dtype=&#x27;int64&#x27;, name=&#x27;j&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-0a006356-583b-4ceb-b0bc-0f0229bd38ed' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-0a006356-583b-4ceb-b0bc-0f0229bd38ed' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 560MB\n",
       "Dimensions:        (sample: 3645, i: 80, j: 80)\n",
       "Coordinates:\n",
       "  * sample         (sample) int64 29kB 0 1 2 3 4 5 ... 3640 3641 3642 3643 3644\n",
       "  * i              (i) int64 640B 0 1 2 3 4 5 6 7 8 ... 72 73 74 75 76 77 78 79\n",
       "  * j              (j) int64 640B 0 1 2 3 4 5 6 7 8 ... 72 73 74 75 76 77 78 79\n",
       "Data variables:\n",
       "    ssh            (sample, i, j) float32 93MB 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
       "    ubm_truth      (sample, i, j) float32 93MB nan nan nan nan ... nan nan nan\n",
       "    bm_truth       (sample, i, j) float32 93MB nan nan nan nan ... nan nan nan\n",
       "    ubm_pred_mean  (sample, i, j) float32 93MB -0.002933 -0.003443 ... 0.007049\n",
       "    bm_pred_mean   (sample, i, j) float32 93MB 0.002933 0.003443 ... -0.007049\n",
       "    sst            (sample, i, j) float32 93MB 0.06335 0.05314 ... 0.0 0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_datasets['mse_only']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8e9980-63d9-4de5-afaa-417a92f3503c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b0e36b0-9918-4639-8ad5-9402ca7a0804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as ticker\n",
    "import cmocean.cm as cmo\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Constants \n",
    "g = 9.81       \n",
    "dx = 1500.0   # m   (1.5 km grid)\n",
    "dy = 1500.0   # m\n",
    "f_cor = -8.6e-5  #  (Agulhas region)\n",
    "\n",
    "def flatten_clean(da, clean_idx):\n",
    "    return da.isel(sample=clean_idx).stack(pixels=(\"i\", \"j\")).values\n",
    "\n",
    "def calculate_geostrophic_speed(field):\n",
    "    \"\"\"Calculate the geostrophic speed from a 2D field of sea surface height.\"\"\"\n",
    "    dη_dy = np.gradient(field, dy, axis=0, edge_order=2)\n",
    "    dη_dx = np.gradient(field, dx, axis=1, edge_order=2)\n",
    "    u_g = -g / f_cor * dη_dy\n",
    "    v_g = g / f_cor * dη_dx\n",
    "    speed = np.sqrt(u_g**2 + v_g**2)\n",
    "    return speed\n",
    "\n",
    "def find_extreme_samples(model_pred, truth, clean_idx, model_name=\"Selected Model\"):\n",
    "    \"\"\"Find sample indices with maximum, median, and minimum R² values\"\"\"\n",
    "    r2_vals = []\n",
    "    \n",
    "    for t, p in zip(flatten_clean(truth, clean_idx), flatten_clean(model_pred, clean_idx)):\n",
    "        m = np.isfinite(t) & np.isfinite(p)\n",
    "        if m.sum() < 2:\n",
    "            r2_vals.append(np.nan)\n",
    "        else:\n",
    "            r2_vals.append(r2_score(t[m], p[m]))\n",
    "    \n",
    "    r2_vals = np.array(r2_vals)\n",
    "    non_nan_indices = np.where(~np.isnan(r2_vals))[0]\n",
    "    valid_r2 = r2_vals[non_nan_indices]\n",
    "    \n",
    "    max_local_idx = np.argmax(valid_r2)\n",
    "    min_local_idx = np.argmin(valid_r2)\n",
    "    sorted_indices = np.argsort(valid_r2)\n",
    "    median_local_idx = sorted_indices[len(sorted_indices) // 2]\n",
    "    \n",
    "    max_sample_idx = clean_idx[non_nan_indices[max_local_idx]]\n",
    "    min_sample_idx = clean_idx[non_nan_indices[min_local_idx]]\n",
    "    median_sample_idx = clean_idx[non_nan_indices[median_local_idx]]\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        \"max\": {\"sample_idx\": int(max_sample_idx), \"r2\": float(valid_r2[max_local_idx])},\n",
    "        \"median\": {\"sample_idx\": int(median_sample_idx), \"r2\": float(valid_r2[median_local_idx])},\n",
    "        \"min\": {\"sample_idx\": int(min_sample_idx), \"r2\": float(valid_r2[min_local_idx])}\n",
    "    }\n",
    "\n",
    "def format_ax(ax, title=None, row_label=None):\n",
    "    \"\"\"Format axis for 4x4 comparison plots\"\"\"\n",
    "    size = 80\n",
    "    title_fontsize = 32\n",
    "    title_pad = 15\n",
    "    \n",
    "    tick_positions = np.linspace(0, size-1, 9)\n",
    "    tick_positions = np.round(tick_positions).astype(int)\n",
    "    \n",
    "    ax.set_xticks(tick_positions)\n",
    "    ax.set_yticks(tick_positions)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.tick_params(axis='both', which='major', length=6, width=1.5, color='black')\n",
    "    \n",
    "    if title is not None:\n",
    "        ax.set_title(title, fontsize=title_fontsize, pad=title_pad, fontweight='bold')\n",
    "    \n",
    "    if row_label:\n",
    "        ax.text(-0.15, 0.5, row_label, transform=ax.transAxes, \n",
    "                fontsize=title_fontsize, ha='center', va='center', rotation=90,\n",
    "                fontweight='bold')\n",
    "\n",
    "def format_ax_ssh(ax, title):\n",
    "    \"\"\"Format axis for SSH plots\"\"\"\n",
    "    size = 80\n",
    "    title_fontsize = 28\n",
    "    title_pad = 15\n",
    "\n",
    "    # Calculate tick positions in pixel units - 8 sections of 10 pixels each\n",
    "    tick_positions = np.linspace(0, size-1, 9)  # 9 points to create 8 sections\n",
    "    tick_positions = np.round(tick_positions).astype(int)  # Round to integers\n",
    "    \n",
    "    # Calculate km values (each pixel = 1.5km)\n",
    "    km_ticks = tick_positions * 1.5\n",
    "    \n",
    "    # Set ticks\n",
    "    ax.set_xticks(tick_positions)\n",
    "    ax.set_yticks(tick_positions)\n",
    "    \n",
    "    # Add km labels every other tick (show labels at positions 0, 2, 4, 6, 8)\n",
    "    x_labels = []\n",
    "    y_labels = []\n",
    "    for i, km in enumerate(km_ticks):\n",
    "        if i % 2 == 0:  # Every even index (0, 2, 4, 6, 8)\n",
    "            x_labels.append(f'{km:.0f}')\n",
    "            y_labels.append(f'{km:.0f}')\n",
    "        else:\n",
    "            x_labels.append('')  # Empty string for odd indices\n",
    "            y_labels.append('')  # Empty string for odd indices\n",
    "    \n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.set_yticklabels(y_labels)\n",
    "\n",
    "    # Make ticks and labels more visible\n",
    "    ax.tick_params(axis='both', which='major', length=7, width=1.5, labelsize=26)\n",
    "    \n",
    "    # Set title\n",
    "    ax.set_title(title, fontsize=title_fontsize, pad=title_pad, loc='center', fontweight='bold')\n",
    "    \n",
    "    # Add km labels to axes\n",
    "    ax.set_xlabel('Distance (km)', fontsize=28)\n",
    "\n",
    "\n",
    "\n",
    "# Clean sample mask (no NaNs in truth UBM)\n",
    "clean_mask = ~test.ubm.isnull().any(dim=(\"i\", \"j\")).values\n",
    "clean_idx = np.where(clean_mask)[0]\n",
    "\n",
    "# Find extreme samples for each model using their UBM predictions\n",
    "extreme_samples = {}\n",
    "\n",
    "# For ZCA+SST model\n",
    "extreme_samples['sst_ssh'] = find_extreme_samples(\n",
    "    eval_datasets['sst_ssh'].ubm_pred_mean, \n",
    "    test.ubm, clean_idx, \n",
    "    model_name=\"ZCA+SST\"\n",
    ")\n",
    "\n",
    "# For SSH-only model  \n",
    "extreme_samples['ssh_only'] = find_extreme_samples(\n",
    "    eval_datasets['ssh_only'].ubm_pred_mean, \n",
    "    test.ubm, clean_idx, \n",
    "    model_name=\"SSH-only\"\n",
    ")\n",
    "\n",
    "# For MSE-only model\n",
    "extreme_samples['mse_only'] = find_extreme_samples(\n",
    "    eval_datasets['mse_only'].ubm_pred_mean, \n",
    "    test.ubm, clean_idx, \n",
    "    model_name=\"MSE-only\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07bc29b1-735d-4358-9007-0a8798f6d30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best sample comparison saved (Sample #3041, R²=0.9127)\n",
      "Best SSH visualization saved (Sample #3041, R²=0.9127)\n",
      "Median sample comparison saved (Sample #519, R²=0.0866)\n",
      "Median SSH visualization saved (Sample #519, R²=0.0866)\n",
      "Worst sample comparison saved (Sample #3323, R²=-6.2663)\n",
      "Worst SSH visualization saved (Sample #3323, R²=-6.2663)\n"
     ]
    }
   ],
   "source": [
    "# Function to create the 4x4 comparison plot\n",
    "def create_comparison_plot(sample_idx, sample_type, r2_value, \n",
    "                          vmin_ubm=-0.04, vmax_ubm=0.04,\n",
    "                          vmin_bm=-0.1, vmax_bm=0.1,\n",
    "                          vmin_grad=0.0, vmax_grad=0.8):\n",
    "    \"\"\"Create 4x4 comparison plot for UBM, BM, and speeds\"\"\"\n",
    "    \n",
    "    # Extract data for the sample\n",
    "    ssh_true = test.ssh.isel(sample=sample_idx).values\n",
    "    ubm_true = test.ubm.isel(sample=sample_idx).values  \n",
    "    bm_true = test.bm.isel(sample=sample_idx).values\n",
    "\n",
    "    # Model predictions for the sample\n",
    "    ubm_pred_sst_ssh = eval_datasets['sst_ssh'].ubm_pred_mean.isel(sample=sample_idx).values\n",
    "    ubm_pred_ssh_only = eval_datasets['ssh_only'].ubm_pred_mean.isel(sample=sample_idx).values\n",
    "    ubm_pred_mse_only = eval_datasets['mse_only'].ubm_pred_mean.isel(sample=sample_idx).values\n",
    "\n",
    "    # Calculate BM from UBM predictions\n",
    "    bm_pred_sst_ssh = ssh_true - ubm_pred_sst_ssh\n",
    "    bm_pred_ssh_only = ssh_true - ubm_pred_ssh_only\n",
    "    bm_pred_mse_only = ssh_true - ubm_pred_mse_only\n",
    "\n",
    "    # Calculate geostrophic speeds\n",
    "    ubm_true_speed = calculate_geostrophic_speed(ubm_true)\n",
    "    ubm_pred_sst_ssh_speed = calculate_geostrophic_speed(ubm_pred_sst_ssh)\n",
    "    ubm_pred_ssh_only_speed = calculate_geostrophic_speed(ubm_pred_ssh_only)\n",
    "    ubm_pred_mse_only_speed = calculate_geostrophic_speed(ubm_pred_mse_only)\n",
    "\n",
    "    bm_true_speed = calculate_geostrophic_speed(bm_true)\n",
    "    bm_pred_sst_ssh_speed = calculate_geostrophic_speed(bm_pred_sst_ssh)\n",
    "    bm_pred_ssh_only_speed = calculate_geostrophic_speed(bm_pred_ssh_only)\n",
    "    bm_pred_mse_only_speed = calculate_geostrophic_speed(bm_pred_mse_only)\n",
    "\n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(20, 20), dpi=300)\n",
    "    gs = gridspec.GridSpec(4, 5, width_ratios=[1, 1, 1, 1, 0.05], \n",
    "                          height_ratios=[1, 1, 1, 1], wspace=0.01, hspace=0.1)\n",
    "\n",
    "    col_titles = ['True', 'MSE+SST', 'ZCA', 'ZCA+SST']\n",
    "    row_types = ['UBM', 'BM', 'UBM Speed', 'BM Speed']\n",
    "\n",
    "    all_data = [\n",
    "        [ubm_true, ubm_pred_mse_only, ubm_pred_ssh_only, ubm_pred_sst_ssh],\n",
    "        [bm_true, bm_pred_mse_only, bm_pred_ssh_only, bm_pred_sst_ssh],\n",
    "        [ubm_true_speed, ubm_pred_mse_only_speed, ubm_pred_ssh_only_speed, ubm_pred_sst_ssh_speed],\n",
    "        [bm_true_speed, bm_pred_mse_only_speed, bm_pred_ssh_only_speed, bm_pred_sst_ssh_speed]\n",
    "    ]\n",
    "\n",
    "    all_cmaps = [cmo.ice, cmo.ice, cmo.thermal, cmo.thermal]\n",
    "    all_vmins = [vmin_ubm, vmin_bm, vmin_grad, vmin_grad]\n",
    "    all_vmaxs = [vmax_ubm, vmax_bm, vmax_grad, vmax_grad]\n",
    "\n",
    "    # Define colorbar ticks for each row based on the ranges\n",
    "    def create_ticks(vmin, vmax, num_ticks=5):\n",
    "        \"\"\"Create evenly spaced ticks between vmin and vmax\"\"\"\n",
    "        return np.linspace(vmin, vmax, num_ticks)\n",
    "\n",
    "    all_ticks = [\n",
    "        create_ticks(vmin_ubm, vmax_ubm, 5),  # UBM row\n",
    "        create_ticks(vmin_bm, vmax_bm, 5),    # BM row\n",
    "        create_ticks(vmin_grad, vmax_grad, 5), # UBM Speed row\n",
    "        create_ticks(vmin_grad, vmax_grad, 5)  # BM Speed row\n",
    "    ]\n",
    "\n",
    "    # Plot all rows\n",
    "    for row in range(4):\n",
    "        for col, data in enumerate(all_data[row]):\n",
    "            ax = fig.add_subplot(gs[row, col])\n",
    "            im = ax.imshow(data, cmap=all_cmaps[row], vmin=all_vmins[row], vmax=all_vmaxs[row])\n",
    "            \n",
    "            col_title = col_titles[col] if row == 0 else None\n",
    "            row_label = row_types[row] if col == 0 else None\n",
    "            \n",
    "            format_ax(ax, title=col_title, row_label=row_label)\n",
    "            \n",
    "            if col == 0:\n",
    "                first_im = im\n",
    "        \n",
    "        # Add colorbar for each row\n",
    "        cax = fig.add_subplot(gs[row, 4])\n",
    "        cbar = plt.colorbar(first_im, cax=cax, extend='both')\n",
    "        \n",
    "        # Style colorbar\n",
    "        pos = cax.get_position()\n",
    "        new_pos = [pos.x0 * 1.0, pos.y0 + pos.height * -0.01, pos.width * 1.3, pos.height * 1.02]\n",
    "        cax.set_position(new_pos)\n",
    "        \n",
    "        cbar.set_ticks(all_ticks[row])\n",
    "        \n",
    "        # Format colorbar ticks to 2 decimal places\n",
    "        cbar.ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.2f'))\n",
    "        \n",
    "        if row < 2:\n",
    "            cbar.ax.set_ylabel('(m)', rotation=270, labelpad=30, fontsize=28)\n",
    "        else:\n",
    "            cbar.ax.set_ylabel('(m/s)', rotation=270, labelpad=40, fontsize=28)\n",
    "        \n",
    "        cbar.ax.tick_params(axis='y', length=8, width=1.5, labelsize=24)\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(f'/home/jovyan/GRL_ssh/figures/Figure_2/{sample_type}_sample_comparison.png', \n",
    "                dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.savefig(f'/home/jovyan/GRL_ssh/figures/Figure_2/{sample_type}_sample_comparison.pdf', \n",
    "                dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    \n",
    "    plt.show()\n",
    "    print(f\"{sample_type.capitalize()} sample comparison saved (Sample #{sample_idx}, R²={r2_value:.4f})\")\n",
    "\n",
    "def create_ssh_plot(sample_idx, sample_type, r2_value,\n",
    "                   vmin_ssh=-0.04, vmax_ssh=0.04,\n",
    "                   vmin_grad=0.0, vmax_grad=0.8):\n",
    "    \"\"\"Create 1x2 SSH plot\"\"\"\n",
    "    \n",
    "    # Extract SSH data\n",
    "    ssh_sample = test.ssh.isel(sample=sample_idx).values\n",
    "    ssh_grad_sample = calculate_geostrophic_speed(ssh_sample)\n",
    "\n",
    "    # Create figure\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4.5), dpi=300)\n",
    "    fig.subplots_adjust(wspace=0.75)  \n",
    "\n",
    "    # Panel A: SSH Raw\n",
    "    im1 = ax1.imshow(ssh_sample, cmap=cmo.ice, vmin=vmin_ssh, vmax=vmax_ssh, \n",
    "                     extent=[0, 80, 0, 80])\n",
    "    format_ax_ssh(ax1, 'SSH Raw')\n",
    "\n",
    "    # Colorbar for Panel A with custom ticks\n",
    "    cbar1 = plt.colorbar(im1, ax=ax1, pad=0.05, aspect=12.7, fraction=0.07, extend='both')\n",
    "    cbar1.set_label('(m)', rotation=270, fontsize=26, labelpad=18)\n",
    "    \n",
    "    # Set custom ticks for SSH colorbar\n",
    "    ssh_ticks = np.linspace(vmin_ssh, vmax_ssh, 5)\n",
    "    cbar1.set_ticks(ssh_ticks)\n",
    "    \n",
    "    cbar1.ax.tick_params(labelsize=26, length=8, width=1.5)\n",
    "    cbar1.ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.2f'))\n",
    "\n",
    "    # Panel B: SSH Gradient Speed\n",
    "    im2 = ax2.imshow(ssh_grad_sample, cmo.thermal, vmin=vmin_grad, vmax=vmax_grad, \n",
    "                     extent=[0, 80, 0, 80])\n",
    "    format_ax_ssh(ax2, 'SSH GSpeed')\n",
    "\n",
    "    # Colorbar for Panel B with custom ticks\n",
    "    cbar2 = plt.colorbar(im2, ax=ax2, pad=0.05, aspect=12.7, fraction=0.07, extend='both')\n",
    "    cbar2.set_label('(m/s)', rotation=270, fontsize=26, labelpad=25)\n",
    "    \n",
    "    # Set custom ticks for gradient speed colorbar\n",
    "    grad_ticks = np.linspace(vmin_grad, vmax_grad, 5)\n",
    "    cbar2.set_ticks(grad_ticks)\n",
    "    \n",
    "    cbar2.ax.tick_params(labelsize=26, length=8, width=1.5)\n",
    "    cbar2.ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.2f'))\n",
    "\n",
    "    # Ensure equal aspect ratios\n",
    "    ax1.set_aspect('equal')\n",
    "    ax2.set_aspect('equal')\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(f'/home/jovyan/GRL_ssh/figures/Figure_2/{sample_type}_ssh_comparison.png', \n",
    "               dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none', format='png')\n",
    "    plt.savefig(f'/home/jovyan/GRL_ssh/figures/Figure_2/{sample_type}_ssh_comparison.pdf', \n",
    "               bbox_inches='tight', facecolor='white', edgecolor='none', format='pdf')\n",
    "    \n",
    "    plt.show()\n",
    "    print(f\"{sample_type.capitalize()} SSH visualization saved (Sample #{sample_idx}, R²={r2_value:.4f})\")\n",
    "\n",
    "\n",
    "    \n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['Arial', 'DejaVu Sans', 'Helvetica', 'sans-serif'],\n",
    "    'axes.linewidth': 1.0,\n",
    "    'xtick.major.width': 1.0,\n",
    "    'ytick.major.width': 1.0,\n",
    "    'xtick.minor.width': 0.8,\n",
    "    'ytick.minor.width': 0.8,\n",
    "    'lines.linewidth': 1.5,\n",
    "    'mathtext.fontset': 'stix',  \n",
    "    'axes.grid': False,\n",
    "    'figure.facecolor': 'white',\n",
    "    'axes.facecolor': 'white'\n",
    "})\n",
    "\n",
    "title_fontsize = 32\n",
    "title_pad = 15\n",
    "\n",
    "\n",
    "sample_types = ['best', 'median', 'worst']\n",
    "sample_keys = ['max', 'median', 'min']\n",
    "\n",
    "# Define custom color ranges for each sample type\n",
    "color_ranges = {\n",
    "    'best': {\n",
    "        'vmin_ubm': -0.08, 'vmax_ubm': 0.08,\n",
    "        'vmin_bm': -0.08, 'vmax_bm': 0.08,\n",
    "        'vmin_grad': 0.0, 'vmax_grad': 0.8,\n",
    "        'vmin_ssh': -0.08, 'vmax_ssh': 0.08\n",
    "    },\n",
    "    'median': {\n",
    "        'vmin_ubm': -0.02, 'vmax_ubm': 0.02,\n",
    "        'vmin_bm': -1.4, 'vmax_bm': -1.0,\n",
    "        'vmin_grad': 0.0, 'vmax_grad': 1.0,\n",
    "        'vmin_ssh': -1.4, 'vmax_ssh': -1.0\n",
    "    },\n",
    "    'worst': {\n",
    "        'vmin_ubm': -0.04, 'vmax_ubm': 0.04,\n",
    "        'vmin_bm': -1.6, 'vmax_bm': -1.2,\n",
    "        'vmin_grad': 0.0, 'vmax_grad': 1.2,\n",
    "        'vmin_ssh': -1.6, 'vmax_ssh': -1.2\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for sample_type, sample_key in zip(sample_types, sample_keys):\n",
    "    sample_idx = extreme_samples['sst_ssh'][sample_key]['sample_idx']\n",
    "    r2_value = extreme_samples['sst_ssh'][sample_key]['r2']\n",
    "    ranges = color_ranges[sample_type]\n",
    "    \n",
    "    \n",
    "    # Create 4x4 comparison plot with custom ranges\n",
    "    create_comparison_plot(sample_idx, sample_type, r2_value,\n",
    "                          vmin_ubm=ranges['vmin_ubm'], vmax_ubm=ranges['vmax_ubm'],\n",
    "                          vmin_bm=ranges['vmin_bm'], vmax_bm=ranges['vmax_bm'],\n",
    "                          vmin_grad=ranges['vmin_grad'], vmax_grad=ranges['vmax_grad'])\n",
    "    \n",
    "    # Create 1x2 SSH plot with custom ranges\n",
    "    create_ssh_plot(sample_idx, sample_type, r2_value,\n",
    "                   vmin_ssh=ranges['vmin_ssh'], vmax_ssh=ranges['vmax_ssh'],\n",
    "                   vmin_grad=ranges['vmin_grad'], vmax_grad=ranges['vmax_grad'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b92c21-c251-4518-9084-8e58aef697f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Figure 1 (Stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a661d366-b7a8-4b8f-90f2-45a8688d0185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models    = [\"MSE+SST\", \"ZCA\", \"ZCA+SST\"]\n",
    "variables = [\"UBM\", \"BM\", \"UBM GSpeed\", \"BM GSpeed\"]\n",
    "\n",
    "# R^2\n",
    "r2_mean = np.array([\n",
    "    [-0.25, 0.96, 0.76, 0.75],   # MSE+SST\n",
    "    [-0.18, 0.96, 0.81, 0.81],   # ZCA\n",
    "    [ 0.01, 0.97, 0.85, 0.85],   # ZCA+SST\n",
    "])\n",
    "r2_p5 = np.array([\n",
    "    [-1.58, 0.81, 0.28, 0.21],\n",
    "    [-1.35, 0.80, 0.45, 0.40],\n",
    "    [-0.94, 0.87, 0.57, 0.58],\n",
    "])\n",
    "r2_p95 = np.array([\n",
    "    [0.61, 1.00, 0.97, 0.97],\n",
    "    [0.59, 1.00, 0.97, 0.98],\n",
    "    [0.73, 1.00, 0.98, 0.98],\n",
    "])\n",
    "\n",
    "# Correlation\n",
    "corr_mean = np.array([\n",
    "    [0.39, 0.98, 0.89, 0.88],   # MSE+SST\n",
    "    [0.40, 0.98, 0.90, 0.90],   # ZCA\n",
    "    [0.48, 0.99, 0.93, 0.92],   # ZCA+SST\n",
    "])\n",
    "corr_p5 = np.array([\n",
    "    [-0.08, 0.92, 0.65, 0.62],\n",
    "    [-0.11, 0.91, 0.70, 0.68],\n",
    "    [0.01, 0.94, 0.78, 0.77],\n",
    "])\n",
    "corr_p95 = np.array([\n",
    "    [0.82, 1.00, 0.98, 0.98],\n",
    "    [0.82, 1.00, 0.99, 0.99],\n",
    "    [0.87, 1.00, 0.99, 0.99],\n",
    "])\n",
    "\n",
    "# ---------------------------\n",
    "# ---------------------------\n",
    "color_map = {\n",
    "    \"MSE+SST\": \"#2ECC71\",  \n",
    "    \"ZCA\":     \"#3498DB\",   \n",
    "    \"ZCA+SST\": \"#E74C3C\",  \n",
    "}\n",
    "\n",
    "# styling parameters\n",
    "cap_size = 3\n",
    "marker_size = 7\n",
    "line_width = 1.2\n",
    "mark_edge_width = 1.5\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['DejaVu Sans', 'Helvetica', 'Arial', 'sans-serif'],\n",
    "    'font.size': 24,  \n",
    "    'axes.linewidth': 0.8,\n",
    "    'xtick.major.width': 0.8,\n",
    "    'ytick.major.width': 0.8,\n",
    "    'xtick.minor.width': 0.6,\n",
    "    'ytick.minor.width': 0.6,\n",
    "    'lines.linewidth': line_width,\n",
    "    'patch.linewidth': 0.8,\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "})\n",
    "\n",
    "def combined_points(ax, r2_means, r2_p5, r2_p95, corr_means, corr_p5, corr_p95, var_name, is_first=False):\n",
    "    \"\"\"Plot both R² (dots) and correlation (crosses) with confidence intervals.\"\"\"\n",
    "    x = np.arange(len(models))\n",
    "    \n",
    "    # Plot R^2 values with dots\n",
    "    for i, m in enumerate(models):\n",
    "        r2_mean = r2_means[i]\n",
    "        r2_low  = r2_p5[i]\n",
    "        r2_high = r2_p95[i]\n",
    "        \n",
    "        ax.errorbar(\n",
    "            i - 0.1, r2_mean,  # slight offset to avoid overlap\n",
    "            yerr=[[r2_mean - r2_low], [r2_high - r2_mean]],\n",
    "            fmt='o', color=color_map[m], \n",
    "            markersize=marker_size, capsize=cap_size, \n",
    "            linewidth=line_width, markeredgewidth=mark_edge_width,\n",
    "            capthick=line_width, alpha=1.0,\n",
    "            label=f\"{m} ($R^2$)\" if is_first else None\n",
    "        )\n",
    "    \n",
    "    # Plot correlation values with crosses\n",
    "    for i, m in enumerate(models):\n",
    "        corr_mean = corr_means[i]\n",
    "        corr_low  = corr_p5[i]\n",
    "        corr_high = corr_p95[i]\n",
    "        \n",
    "        ax.errorbar(\n",
    "            i + 0.1, corr_mean,  # slight offset to avoid overlap\n",
    "            yerr=[[corr_mean - corr_low], [corr_high - corr_mean]],\n",
    "            fmt='x', color=color_map[m], \n",
    "            markersize=marker_size + 2, capsize=cap_size, \n",
    "            linewidth=line_width, markeredgewidth=mark_edge_width + 0.5,\n",
    "            capthick=line_width, alpha=1.0,\n",
    "            label=f\"{m} (Corr)\" if is_first else None\n",
    "        )\n",
    "    \n",
    "    ax.set_title(var_name, fontsize=18, pad=8)\n",
    "    \n",
    "    # Set y-limits\n",
    "    ax.set_ylim(-2, 1.5)\n",
    "    ax.set_yticks([-2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5])\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=18) \n",
    "    ax.grid(axis=\"y\", linestyle=\":\", linewidth=0.4, alpha=0.5, color='gray')\n",
    "\n",
    "# ---------------------------\n",
    "# Create 1x4 subplot\n",
    "# ---------------------------\n",
    "fig, axes = plt.subplots(1, 4, figsize=(30, 6))  \n",
    "plt.subplots_adjust(left=0.1, right=0.92, top=0.85, bottom=0.25, wspace=0.4)\n",
    "\n",
    "# Plot all variables\n",
    "for j, var in enumerate(variables):\n",
    "    combined_points(\n",
    "        axes[j],\n",
    "        r2_mean[:, j], r2_p5[:, j], r2_p95[:, j],\n",
    "        corr_mean[:, j], corr_p5[:, j], corr_p95[:, j],\n",
    "        var_name=var,\n",
    "        is_first=(j == 0)\n",
    "    )\n",
    "\n",
    "# Create legend \n",
    "legend_elements = [\n",
    "    plt.Line2D([0],[0], marker='o', color='w',\n",
    "               markerfacecolor='black', markersize=10, \n",
    "               markeredgecolor='black', markeredgewidth=mark_edge_width,\n",
    "               label=\"$R^2$\"),\n",
    "    plt.Line2D([0],[0], marker='x', color='black',\n",
    "               markersize=10, markeredgewidth=mark_edge_width+0.5,\n",
    "               label=\"Correlation\", linestyle='None')\n",
    "]\n",
    "\n",
    "legend = fig.legend(\n",
    "    legend_elements, [elem.get_label() for elem in legend_elements],\n",
    "    loc=\"lower center\", bbox_to_anchor=(0.5, -0.05),\n",
    "    frameon=False, fontsize=22, handletextpad=0.5, ncol=2\n",
    ")\n",
    "\n",
    "plt.savefig(\"figures/Figure_1/stats.png\", dpi=300, bbox_inches=\"tight\", \n",
    "           facecolor='white', edgecolor='none')\n",
    "plt.savefig(\"figures/Figure_1/stats.pdf\", dpi=300, bbox_inches=\"tight\", \n",
    "           facecolor='white', edgecolor='none')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b334f1a-d254-42ab-adf7-e6482f35bdf3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Figure 1 (ESR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a616a5b2-27dc-4850-ba77-e618e287daab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESR Plot for BM\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import xarray as xr\n",
    "import xrft\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def calculate_average_e2sr_from_datasets(eval_datasets, test_data, clean_idx_subset):\n",
    "    \"\"\"Calculate average ESR for BM\"\"\"\n",
    "    model_e2sr_sums = {}\n",
    "    sample_count = 0\n",
    "    first_sample = True\n",
    "    \n",
    "    models = {\n",
    "        'ZCA+SST': 'sst_ssh',\n",
    "        'ZCA': 'ssh_only', \n",
    "        'MSE+SST': 'mse_only' \n",
    "    }\n",
    "    \n",
    "    # Process each clean sample\n",
    "    for sample_idx in clean_idx_subset:\n",
    "        # Get the true BM for this sample\n",
    "        true_bm = test_data.bm.isel(sample=sample_idx).values\n",
    "        \n",
    "        # Skip samples with NaNs\n",
    "        if np.any(np.isnan(true_bm)):\n",
    "            continue\n",
    "            \n",
    "        # Calculate PSD of true BM\n",
    "        try:\n",
    "            psd_true = calculate_psd_km(true_bm)\n",
    "            wavenumbers = psd_true[list(psd_true.coords.keys())[0]].values\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        \n",
    "        # For each model, calculate ESR\n",
    "        for model_name, dataset_key in models.items():\n",
    "            try:\n",
    "                # Get predicted BM for this sample (SSH - UBM_pred)\n",
    "                ssh_sample = test_data.ssh.isel(sample=sample_idx).values\n",
    "                ubm_pred = eval_datasets[dataset_key].ubm_pred_mean.isel(sample=sample_idx).values\n",
    "                pred_bm = ssh_sample - ubm_pred\n",
    "                \n",
    "                # Skip if prediction contains NaNs\n",
    "                if np.any(np.isnan(pred_bm)):\n",
    "                    continue\n",
    "                    \n",
    "                # Calculate PSD of the difference (error)\n",
    "                error = true_bm - pred_bm\n",
    "                psd_diff = calculate_psd_km(error)\n",
    "                \n",
    "                # Calculate E2SR: PSD(error) / PSD(true)\n",
    "                e2sr = psd_diff.values / psd_true.values\n",
    "                \n",
    "                # Initialize sum on first valid sample\n",
    "                if first_sample or model_name not in model_e2sr_sums:\n",
    "                    model_e2sr_sums[model_name] = e2sr.copy()\n",
    "                else:\n",
    "                    model_e2sr_sums[model_name] += e2sr\n",
    "                    \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        sample_count += 1\n",
    "        first_sample = False\n",
    "    \n",
    "    # Calculate averages\n",
    "    model_e2sr_avg = {}\n",
    "    for model, e2sr_sum in model_e2sr_sums.items():\n",
    "        model_e2sr_avg[model] = e2sr_sum / sample_count\n",
    "    \n",
    "    return model_e2sr_avg, wavenumbers\n",
    "\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['Arial', 'DejaVu Sans', 'Helvetica', 'sans-serif'],\n",
    "    'mathtext.fontset': 'stix',  \n",
    "    'axes.grid': False,\n",
    "    'figure.facecolor': 'white',\n",
    "    'axes.facecolor': 'white', \n",
    "    'text.usetex': False,\n",
    "})\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "esr_colors = {\n",
    "    'ZCA+SST': '#1f77b4',    # Blue\n",
    "    'ZCA': '#ff7f0e',        # Orange  \n",
    "    'MSE+SST': '#2ca02c',    # Green\n",
    "}\n",
    "\n",
    "# Calculate ESR for all models\n",
    "avg_e2sr, wavenumbers = calculate_average_e2sr_from_datasets(eval_datasets, test, clean_idx)\n",
    "\n",
    "# Plot E2SR lines for each model\n",
    "for model_name, e2sr in avg_e2sr.items():\n",
    "    ax.loglog(wavenumbers, e2sr, color=esr_colors[model_name], \n",
    "             linewidth=3.5, label=model_name, solid_capstyle='round')\n",
    "\n",
    "# Add horizontal reference line at y = 1.0\n",
    "ax.axhline(y=1.0, color='black', linestyle='-', linewidth=2, alpha=0.4)\n",
    "ax.text(ax.get_xlim()[0]*1.3, 1.2, 'Error = 100% of True Signal', \n",
    "         fontsize=22, color='black', alpha=0.8)\n",
    "\n",
    "\n",
    "ax.set_xlim(8e-3, 5e-1)\n",
    "ax.tick_params(axis='both', which='major', labelsize=28, length=12, \n",
    "                width=2.5, direction='in', top=True, right=True)\n",
    "ax.tick_params(axis='both', which='minor', length=8, \n",
    "                width=1.5, direction='in', top=True, right=True)\n",
    "\n",
    "ax.set_xlabel(r'Wavenumber (cpkm)', fontsize=28)\n",
    "ax.set_ylabel(r'Average ESR (BM)', fontsize=28)  \n",
    "ax.legend(loc='lower right', fontsize=24, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('/home/jovyan/GRL_ssh/figures/Figure_1/esr_bm.png', \n",
    "            bbox_inches='tight', dpi=300, facecolor='white', \n",
    "            edgecolor='none', format='png')\n",
    "plt.savefig('/home/jovyan/GRL_ssh/figures/Figure_1/esr_bm.pdf', \n",
    "            bbox_inches='tight', facecolor='white', \n",
    "            edgecolor='none', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "590a536c-974b-4db2-a250-1d3c2e7a2798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESR Plot for UBM\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import xarray as xr\n",
    "import xrft\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def calculate_average_e2sr_from_datasets(eval_datasets, test_data, clean_idx_subset):\n",
    "    \"\"\"Calculate average ESR for models from eval_datasets for UBM\"\"\"\n",
    "    model_e2sr_sums = {}\n",
    "    sample_count = 0\n",
    "    first_sample = True\n",
    "    \n",
    "    models = {\n",
    "        'ZCA+SST': 'sst_ssh',\n",
    "        'ZCA': 'ssh_only', \n",
    "        'MSE+SST': 'mse_only'  \n",
    "    }\n",
    "    \n",
    "\n",
    "    for sample_idx in clean_idx_subset:\n",
    "        # Get the true UBM for this sample\n",
    "        true_ubm = test_data.ubm.isel(sample=sample_idx).values  \n",
    "        \n",
    "        # Skip samples with NaNs\n",
    "        if np.any(np.isnan(true_ubm)):\n",
    "            continue\n",
    "            \n",
    "        # Calculate PSD of true UBM\n",
    "        try:\n",
    "            psd_true = calculate_psd_km(true_ubm)\n",
    "            wavenumbers = psd_true[list(psd_true.coords.keys())[0]].values\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        \n",
    "        # For each model, calculate ESR\n",
    "        for model_name, dataset_key in models.items():\n",
    "            try:\n",
    "                # Get predicted UBM for this sample \n",
    "                pred_ubm = eval_datasets[dataset_key].ubm_pred_mean.isel(sample=sample_idx).values\n",
    "                \n",
    "                # Skip if prediction contains NaNs\n",
    "                if np.any(np.isnan(pred_ubm)):\n",
    "                    continue\n",
    "                    \n",
    "                # Calculate PSD of the difference (error)\n",
    "                error = true_ubm - pred_ubm\n",
    "                psd_diff = calculate_psd_km(error)\n",
    "                \n",
    "                # Calculate E2SR: PSD(error) / PSD(true)\n",
    "                e2sr = psd_diff.values / psd_true.values\n",
    "                \n",
    "                # Initialize sum on first valid sample\n",
    "                if first_sample or model_name not in model_e2sr_sums:\n",
    "                    model_e2sr_sums[model_name] = e2sr.copy()\n",
    "                else:\n",
    "                    model_e2sr_sums[model_name] += e2sr\n",
    "                    \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        sample_count += 1\n",
    "        first_sample = False\n",
    "    \n",
    "    # Calculate averages\n",
    "    model_e2sr_avg = {}\n",
    "    for model, e2sr_sum in model_e2sr_sums.items():\n",
    "        model_e2sr_avg[model] = e2sr_sum / sample_count\n",
    "    \n",
    "    return model_e2sr_avg, wavenumbers\n",
    "\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['Arial', 'DejaVu Sans', 'Helvetica', 'sans-serif'],\n",
    "    'mathtext.fontset': 'stix',  \n",
    "    'axes.grid': False,\n",
    "    'figure.facecolor': 'white',\n",
    "    'axes.facecolor': 'white', \n",
    "    'text.usetex': False,\n",
    "})\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "esr_colors = {\n",
    "    'ZCA+SST': '#1f77b4',    # Blue\n",
    "    'ZCA': '#ff7f0e',        # Orange  \n",
    "    'MSE+SST': '#2ca02c',    # Green\n",
    "}\n",
    "\n",
    "# Calculate ESR for all models\n",
    "avg_e2sr, wavenumbers = calculate_average_e2sr_from_datasets(eval_datasets, test, clean_idx)\n",
    "\n",
    "# Plot E2SR lines for each model\n",
    "for model_name, e2sr in avg_e2sr.items():\n",
    "    ax.loglog(wavenumbers, e2sr, color=esr_colors[model_name], \n",
    "             linewidth=3.5, label=model_name, solid_capstyle='round')\n",
    "\n",
    "# Add horizontal reference line at y = 1.0\n",
    "ax.axhline(y=1.0, color='black', linestyle='-', linewidth=2, alpha=0.4)\n",
    "# ax.text(ax.get_xlim()[0]*1.3, 1.2, 'Error = 100% of True Signal', \n",
    "#          fontsize=22, color='black', alpha=0.8)\n",
    "\n",
    "ax.set_xlim(8e-3, 5e-1)\n",
    "ax.tick_params(axis='both', which='major', labelsize=28, length=12, \n",
    "                width=2.5, direction='in', top=True, right=True)\n",
    "ax.tick_params(axis='both', which='minor', length=8, \n",
    "                width=1.5, direction='in', top=True, right=True)\n",
    "\n",
    "ax.set_xlabel(r'Wavenumber (cpkm)', fontsize=28)\n",
    "ax.set_ylabel(r'Average ESR (UBM)', fontsize=28)  \n",
    "\n",
    "ax.legend(loc='lower left', fontsize=24, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('/home/jovyan/GRL_ssh/figures/Figure_1/esr_ubm.png', \n",
    "            bbox_inches='tight', dpi=300, facecolor='white', \n",
    "            edgecolor='none', format='png')\n",
    "plt.savefig('/home/jovyan/GRL_ssh/figures/Figure_1/esr_ubm.pdf', \n",
    "            bbox_inches='tight', facecolor='white', \n",
    "            edgecolor='none', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa454ed4-0671-495f-b302-6f826fbe0034",
   "metadata": {},
   "source": [
    "# Figure 1 (PSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dc2b8a9-981a-43b4-a715-1acfe1a20432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSD Plot\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import xarray as xr\n",
    "import xrft\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def calculate_average_psd_and_envelopes(eval_dataset, test_data, clean_idx_subset):\n",
    "    \"\"\"Calculate average PSD and envelopes for ensemble predictions\"\"\"\n",
    "    \n",
    "    # Discover PSD length & wavenumbers from the first valid sample\n",
    "    wavenumbers = None\n",
    "    psd_len = None\n",
    "    first_valid = None\n",
    "    \n",
    "    for sample_idx in clean_idx_subset:\n",
    "        try:\n",
    "            ssh_raw = eval_dataset.ssh.isel(sample=sample_idx).values\n",
    "            ubm_true = eval_dataset.ubm_truth.isel(sample=sample_idx).values\n",
    "            bm_true = eval_dataset.bm_truth.isel(sample=sample_idx).values\n",
    "            \n",
    "            \n",
    "            if np.any(np.isnan(ubm_true)) or np.any(np.isnan(bm_true)):\n",
    "                continue\n",
    "                \n",
    "            psd_ubm_true = calculate_psd_km(ubm_true)\n",
    "            wavenumbers = psd_ubm_true[list(psd_ubm_true.coords.keys())[0]].values\n",
    "            psd_len = psd_ubm_true.values.size\n",
    "            first_valid = sample_idx\n",
    "            break\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "            \n",
    "    if first_valid is None:\n",
    "        raise ValueError(\"No valid samples to determine PSD shape.\")\n",
    "\n",
    "    # Check ensemble dimensions\n",
    "    if \"stochastic_sample\" in eval_dataset.ubm_pred_samples.dims:\n",
    "        ens_members = eval_dataset.ubm_pred_samples.sizes[\"stochastic_sample\"]\n",
    "    else:\n",
    "        ens_members = eval_dataset.ubm_pred_samples.isel(sample=first_valid).values.shape[0]\n",
    "\n",
    "    # Initialize running sums\n",
    "    ssh_raw_sum = np.zeros(psd_len, dtype=np.float32)\n",
    "    ubm_true_sum = np.zeros(psd_len, dtype=np.float32)\n",
    "    bm_true_sum = np.zeros(psd_len, dtype=np.float32)\n",
    "    ubm_env_lower_sum = np.zeros(psd_len, dtype=np.float32)\n",
    "    ubm_env_upper_sum = np.zeros(psd_len, dtype=np.float32)\n",
    "    bm_env_lower_sum = np.zeros(psd_len, dtype=np.float32)\n",
    "    bm_env_upper_sum = np.zeros(psd_len, dtype=np.float32)\n",
    "\n",
    "    n_valid = 0\n",
    "\n",
    "    # Preallocate ensemble-PSD buffers\n",
    "    ubm_ens_psds = np.empty((ens_members, psd_len), dtype=np.float32)\n",
    "    bm_ens_psds = np.empty((ens_members, psd_len), dtype=np.float32)\n",
    "\n",
    "    # Process each sample\n",
    "    for sample_idx in clean_idx_subset:\n",
    "        try:\n",
    "            # Get truth data\n",
    "            ssh_raw = eval_dataset.ssh.isel(sample=sample_idx).values\n",
    "            ubm_true = eval_dataset.ubm_truth.isel(sample=sample_idx).values\n",
    "            bm_true = eval_dataset.bm_truth.isel(sample=sample_idx).values\n",
    "            \n",
    "            if np.any(np.isnan(ubm_true)) or np.any(np.isnan(bm_true)):\n",
    "                continue\n",
    "\n",
    "            # Calculate truth PSDs\n",
    "            psd_ssh_raw = calculate_psd_km(ssh_raw).values.astype(np.float32)\n",
    "            psd_ubm_true = calculate_psd_km(ubm_true).values.astype(np.float32)\n",
    "            psd_bm_true = calculate_psd_km(bm_true).values.astype(np.float32)\n",
    "            ssh_raw_sum += psd_ssh_raw\n",
    "            ubm_true_sum += psd_ubm_true\n",
    "            bm_true_sum += psd_bm_true\n",
    "\n",
    "            # Get ensemble data\n",
    "            ubm_ens = eval_dataset.ubm_pred_samples.isel(sample=sample_idx).values\n",
    "            bm_ens = eval_dataset.bm_pred_samples.isel(sample=sample_idx).values\n",
    "\n",
    "            # Process UBM ensemble\n",
    "            valid_e_ubm = 0\n",
    "            for e in range(ens_members):\n",
    "                arr = ubm_ens[e, :, :]\n",
    "                if not np.all(np.isnan(arr)):\n",
    "                    ubm_ens_psds[valid_e_ubm] = calculate_psd_km(arr).values.astype(np.float32)\n",
    "                    valid_e_ubm += 1\n",
    "                    \n",
    "            if valid_e_ubm > 0:\n",
    "                ubm_env_lower_sum += np.nanpercentile(ubm_ens_psds[:valid_e_ubm], 5, axis=0).astype(np.float32)\n",
    "                ubm_env_upper_sum += np.nanpercentile(ubm_ens_psds[:valid_e_ubm], 95, axis=0).astype(np.float32)\n",
    "\n",
    "            # Process BM ensemble\n",
    "            valid_e_bm = 0\n",
    "            for e in range(ens_members):\n",
    "                arr = bm_ens[e, :, :]\n",
    "                if not np.all(np.isnan(arr)):\n",
    "                    bm_ens_psds[valid_e_bm] = calculate_psd_km(arr).values.astype(np.float32)\n",
    "                    valid_e_bm += 1\n",
    "                    \n",
    "            if valid_e_bm > 0:\n",
    "                bm_env_lower_sum += np.nanpercentile(bm_ens_psds[:valid_e_bm], 5, axis=0).astype(np.float32)\n",
    "                bm_env_upper_sum += np.nanpercentile(bm_ens_psds[:valid_e_bm], 95, axis=0).astype(np.float32)\n",
    "\n",
    "            n_valid += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    if n_valid == 0:\n",
    "        raise ValueError(\"No valid samples found.\")\n",
    "\n",
    "    # Calculate averages\n",
    "    avg_ssh_raw_psd = ssh_raw_sum / n_valid\n",
    "    avg_ubm_true_psd = ubm_true_sum / n_valid\n",
    "    avg_bm_true_psd = bm_true_sum / n_valid\n",
    "    avg_ubm_envelope_lower = ubm_env_lower_sum / n_valid\n",
    "    avg_ubm_envelope_upper = ubm_env_upper_sum / n_valid\n",
    "    avg_bm_envelope_lower = bm_env_lower_sum / n_valid\n",
    "    avg_bm_envelope_upper = bm_env_upper_sum / n_valid\n",
    "\n",
    "    return {\n",
    "        'wavenumbers': wavenumbers,\n",
    "        'ssh_raw_psd': avg_ssh_raw_psd,\n",
    "        'ubm_true_psd': avg_ubm_true_psd,\n",
    "        'bm_true_psd': avg_bm_true_psd,\n",
    "        'ubm_envelope_lower': avg_ubm_envelope_lower,\n",
    "        'ubm_envelope_upper': avg_ubm_envelope_upper,\n",
    "        'bm_envelope_lower': avg_bm_envelope_lower,\n",
    "        'bm_envelope_upper': avg_bm_envelope_upper\n",
    "    }\n",
    "\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['Arial', 'DejaVu Sans', 'Helvetica', 'sans-serif'],\n",
    "    'mathtext.fontset': 'stix',  \n",
    "    'axes.grid': False,\n",
    "    'figure.facecolor': 'white',\n",
    "    'axes.facecolor': 'white', \n",
    "    'text.usetex': False,\n",
    "})\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "# Color set\n",
    "psd_colors = {\n",
    "    'bm_true': '#d62728',     # Red\n",
    "    'ubm_true': '#1f77b4',   # Blue\n",
    "    'ubm_envelope': '#ff7f0e',  # Orange\n",
    "    'bm_envelope': '#2ca02c',   # Green\n",
    "    'ssh_raw': '#9467bd'    # Purple \n",
    "}\n",
    "\n",
    "# Calculate PSD data for ZCA+SST model\n",
    "psd_data = calculate_average_psd_and_envelopes(eval_datasets['sst_ssh'], test, clean_idx)\n",
    "\n",
    "# Plot true PSD lines\n",
    "ax.loglog(psd_data['wavenumbers'], psd_data['ssh_raw_psd'], color=psd_colors['ssh_raw'], \n",
    "         linewidth=3.5, label='SSH Raw', solid_capstyle='round')\n",
    "ax.loglog(psd_data['wavenumbers'], psd_data['bm_true_psd'], color=psd_colors['bm_true'], \n",
    "         linewidth=3.5, label='BM True', solid_capstyle='round')\n",
    "ax.loglog(psd_data['wavenumbers'], psd_data['ubm_true_psd'], color=psd_colors['ubm_true'], \n",
    "         linewidth=3.5, label='UBM True', solid_capstyle='round')\n",
    "\n",
    "\n",
    "# Plot uncertainty envelopes\n",
    "ax.fill_between(psd_data['wavenumbers'], psd_data['bm_envelope_lower'], psd_data['bm_envelope_upper'], \n",
    "                alpha=0.6, color=psd_colors['bm_envelope'], label='BM 90% CI', edgecolor='none')\n",
    "ax.fill_between(psd_data['wavenumbers'], psd_data['ubm_envelope_lower'], psd_data['ubm_envelope_upper'], \n",
    "                alpha=0.6, color=psd_colors['ubm_envelope'], label='UBM 90% CI', edgecolor='none')\n",
    "\n",
    "\n",
    "ax.set_xlim(8e-3, 5e-1)\n",
    "ax.tick_params(axis='both', which='major', labelsize=28, length=12, \n",
    "                width=2.5, direction='in', top=True, right=True)\n",
    "ax.tick_params(axis='both', which='minor', length=8, \n",
    "                width=1.5, direction='in', top=True, right=True)\n",
    "\n",
    "y_ticks_labeled = [10**j for j in range(-10, 1, 2)]\n",
    "ax.yaxis.set_major_locator(ticker.FixedLocator(y_ticks_labeled))\n",
    "ax.yaxis.set_major_formatter(ticker.LogFormatterMathtext())\n",
    "\n",
    "ax.set_xlabel(r'Wavenumber (cpkm)', fontsize=28)\n",
    "ax.set_ylabel(r'PSD (m$^2$ cpkm$^{-1}$)', fontsize=28)\n",
    "\n",
    "ax.legend(loc='upper right', fontsize=24, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('/home/jovyan/GRL_ssh/figures/Figure_1/psd.png', \n",
    "            bbox_inches='tight', dpi=300, facecolor='white', \n",
    "            edgecolor='none', format='png')\n",
    "plt.savefig('/home/jovyan/GRL_ssh/figures/Figure_1/psd.pdf', \n",
    "            bbox_inches='tight', facecolor='white', \n",
    "            edgecolor='none', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91cdf4d0-2be4-420a-b31a-63fcf5c8085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSD Plot - Final Production Version\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import xarray as xr\n",
    "import xrft\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set matplotlib backend\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def calculate_average_psd_and_envelopes(eval_dataset, test_data, clean_idx_subset):\n",
    "    \"\"\"Calculate average PSD and envelopes for ensemble predictions\"\"\"\n",
    "    \n",
    "    # Discover PSD length & wavenumbers from the first valid sample\n",
    "    wavenumbers = None\n",
    "    psd_len = None\n",
    "    first_valid = None\n",
    "    \n",
    "    for sample_idx in clean_idx_subset:\n",
    "        try:\n",
    "            ubm_true = eval_dataset.ubm_truth.isel(sample=sample_idx).values\n",
    "            bm_true = eval_dataset.bm_truth.isel(sample=sample_idx).values\n",
    "            \n",
    "            if np.any(np.isnan(ubm_true)) or np.any(np.isnan(bm_true)):\n",
    "                continue\n",
    "                \n",
    "            psd_ubm_true = calculate_psd_km(ubm_true)\n",
    "            wavenumbers = psd_ubm_true[list(psd_ubm_true.coords.keys())[0]].values\n",
    "            psd_len = psd_ubm_true.values.size\n",
    "            first_valid = sample_idx\n",
    "            break\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "            \n",
    "    if first_valid is None:\n",
    "        raise ValueError(\"No valid samples to determine PSD shape.\")\n",
    "\n",
    "    # Check ensemble dimensions\n",
    "    if \"stochastic_sample\" in eval_dataset.ubm_pred_samples.dims:\n",
    "        ens_members = eval_dataset.ubm_pred_samples.sizes[\"stochastic_sample\"]\n",
    "    else:\n",
    "        ens_members = eval_dataset.ubm_pred_samples.isel(sample=first_valid).values.shape[0]\n",
    "\n",
    "    # Initialize running sums\n",
    "    ubm_true_sum = np.zeros(psd_len, dtype=np.float32)\n",
    "    bm_true_sum = np.zeros(psd_len, dtype=np.float32)\n",
    "    ubm_env_lower_sum = np.zeros(psd_len, dtype=np.float32)\n",
    "    ubm_env_upper_sum = np.zeros(psd_len, dtype=np.float32)\n",
    "    bm_env_lower_sum = np.zeros(psd_len, dtype=np.float32)\n",
    "    bm_env_upper_sum = np.zeros(psd_len, dtype=np.float32)\n",
    "\n",
    "    n_valid = 0\n",
    "\n",
    "    # Preallocate ensemble-PSD buffers\n",
    "    ubm_ens_psds = np.empty((ens_members, psd_len), dtype=np.float32)\n",
    "    bm_ens_psds = np.empty((ens_members, psd_len), dtype=np.float32)\n",
    "\n",
    "    # Process each sample\n",
    "    for sample_idx in clean_idx_subset:\n",
    "        try:\n",
    "            # Get truth data\n",
    "            ubm_true = eval_dataset.ubm_truth.isel(sample=sample_idx).values\n",
    "            bm_true = eval_dataset.bm_truth.isel(sample=sample_idx).values\n",
    "            \n",
    "            if np.any(np.isnan(ubm_true)) or np.any(np.isnan(bm_true)):\n",
    "                continue\n",
    "\n",
    "            # Calculate truth PSDs\n",
    "            psd_ubm_true = calculate_psd_km(ubm_true).values.astype(np.float32)\n",
    "            psd_bm_true = calculate_psd_km(bm_true).values.astype(np.float32)\n",
    "            ubm_true_sum += psd_ubm_true\n",
    "            bm_true_sum += psd_bm_true\n",
    "\n",
    "            # Get ensemble data\n",
    "            ubm_ens = eval_dataset.ubm_pred_samples.isel(sample=sample_idx).values\n",
    "            bm_ens = eval_dataset.bm_pred_samples.isel(sample=sample_idx).values\n",
    "\n",
    "            # Process UBM ensemble\n",
    "            valid_e_ubm = 0\n",
    "            for e in range(ens_members):\n",
    "                arr = ubm_ens[e, :, :]\n",
    "                if not np.all(np.isnan(arr)):\n",
    "                    ubm_ens_psds[valid_e_ubm] = calculate_psd_km(arr).values.astype(np.float32)\n",
    "                    valid_e_ubm += 1\n",
    "                    \n",
    "            if valid_e_ubm > 0:\n",
    "                ubm_env_lower_sum += np.nanpercentile(ubm_ens_psds[:valid_e_ubm], 5, axis=0).astype(np.float32)\n",
    "                ubm_env_upper_sum += np.nanpercentile(ubm_ens_psds[:valid_e_ubm], 95, axis=0).astype(np.float32)\n",
    "\n",
    "            # Process BM ensemble\n",
    "            valid_e_bm = 0\n",
    "            for e in range(ens_members):\n",
    "                arr = bm_ens[e, :, :]\n",
    "                if not np.all(np.isnan(arr)):\n",
    "                    bm_ens_psds[valid_e_bm] = calculate_psd_km(arr).values.astype(np.float32)\n",
    "                    valid_e_bm += 1\n",
    "                    \n",
    "            if valid_e_bm > 0:\n",
    "                bm_env_lower_sum += np.nanpercentile(bm_ens_psds[:valid_e_bm], 5, axis=0).astype(np.float32)\n",
    "                bm_env_upper_sum += np.nanpercentile(bm_ens_psds[:valid_e_bm], 95, axis=0).astype(np.float32)\n",
    "\n",
    "            n_valid += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    if n_valid == 0:\n",
    "        raise ValueError(\"No valid samples found.\")\n",
    "\n",
    "    # Calculate averages\n",
    "    avg_ubm_true_psd = ubm_true_sum / n_valid\n",
    "    avg_bm_true_psd = bm_true_sum / n_valid\n",
    "    avg_ubm_envelope_lower = ubm_env_lower_sum / n_valid\n",
    "    avg_ubm_envelope_upper = ubm_env_upper_sum / n_valid\n",
    "    avg_bm_envelope_lower = bm_env_lower_sum / n_valid\n",
    "    avg_bm_envelope_upper = bm_env_upper_sum / n_valid\n",
    "\n",
    "    return {\n",
    "        'wavenumbers': wavenumbers,\n",
    "        'ubm_true_psd': avg_ubm_true_psd,\n",
    "        'bm_true_psd': avg_bm_true_psd,\n",
    "        'ubm_envelope_lower': avg_ubm_envelope_lower,\n",
    "        'ubm_envelope_upper': avg_ubm_envelope_upper,\n",
    "        'bm_envelope_lower': avg_bm_envelope_lower,\n",
    "        'bm_envelope_upper': avg_bm_envelope_upper\n",
    "    }\n",
    "\n",
    "# Professional publication settings\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['Arial', 'DejaVu Sans', 'Helvetica', 'sans-serif'],\n",
    "    'mathtext.fontset': 'stix',  \n",
    "    'axes.grid': False,\n",
    "    'figure.facecolor': 'white',\n",
    "    'axes.facecolor': 'white', \n",
    "    'text.usetex': False,\n",
    "})\n",
    "\n",
    "# Use all clean samples\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "# Color palette\n",
    "psd_colors = {\n",
    "    'bm_true': '#d62728',     # Red\n",
    "    'ubm_true': '#1f77b4',   # Blue\n",
    "    'ubm_envelope': '#ff7f0e',  # Orange\n",
    "    'bm_envelope': '#2ca02c',   # Green\n",
    "}\n",
    "\n",
    "# Calculate PSD data for ZCA+SST model\n",
    "psd_data = calculate_average_psd_and_envelopes(eval_datasets['sst_ssh'], test, clean_idx)\n",
    "\n",
    "# Plot true PSD lines\n",
    "ax.loglog(psd_data['wavenumbers'], psd_data['bm_true_psd'], color=psd_colors['bm_true'], \n",
    "         linewidth=2.5, label='BM True', solid_capstyle='round')\n",
    "ax.loglog(psd_data['wavenumbers'], psd_data['ubm_true_psd'], color=psd_colors['ubm_true'], \n",
    "         linewidth=2.5, label='UBM True', solid_capstyle='round')\n",
    "\n",
    "# Plot uncertainty envelopes\n",
    "ax.fill_between(psd_data['wavenumbers'], psd_data['bm_envelope_lower'], psd_data['bm_envelope_upper'], \n",
    "                alpha=0.6, color=psd_colors['bm_envelope'], label='BM 90% CI', edgecolor='none')\n",
    "ax.fill_between(psd_data['wavenumbers'], psd_data['ubm_envelope_lower'], psd_data['ubm_envelope_upper'], \n",
    "                alpha=0.6, color=psd_colors['ubm_envelope'], label='UBM 90% CI', edgecolor='none')\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xlim(8e-3, 5e-1)\n",
    "ax.tick_params(axis='both', which='major', labelsize=22, length=8, \n",
    "                width=1.5, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', length=4, \n",
    "                width=0.8, direction='in')\n",
    "\n",
    "# Set custom tick locations for y-axis\n",
    "y_ticks_labeled = [10**j for j in range(-10, 1, 2)]\n",
    "ax.yaxis.set_major_locator(ticker.FixedLocator(y_ticks_labeled))\n",
    "ax.yaxis.set_major_formatter(ticker.LogFormatterMathtext())\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(r'Wavenumber (cpkm)', fontsize=24, fontweight='normal')\n",
    "ax.set_ylabel(r'PSD (m$^2$ cpkm$^{-1}$)', fontsize=24, fontweight='normal')\n",
    "\n",
    "# Legend\n",
    "ax.legend(loc='upper right', fontsize=22, frameon=True, \n",
    "           framealpha=0.9, edgecolor='black', facecolor='white',\n",
    "           fancybox=True, shadow=False, columnspacing=2.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('/home/jovyan/GRL_ssh/figures/Figure_1/psd.png', \n",
    "            bbox_inches='tight', dpi=300, facecolor='white', \n",
    "            edgecolor='none', format='png')\n",
    "plt.savefig('/home/jovyan/GRL_ssh/figures/Figure_1/psd.pdf', \n",
    "            bbox_inches='tight', facecolor='white', \n",
    "            edgecolor='none', format='pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685811ba-ed12-4fa7-8741-6a661d47a27b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Figure 1 (ESR Bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b72bdb1b-45d0-452b-8ad0-4ab12eb89454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin edges (spatial scale in km):\n",
      "Bin 1: [44.5, 125.0) km\n",
      "Bin 2: [15.8, 44.5) km\n",
      "Bin 3: [5.6, 15.8) km\n",
      "Bin 4: [2.0, 5.6) km\n",
      "\n",
      "Intersection Statistics:\n",
      "Total clean samples: 2907\n",
      "Samples with no intersection: 53 (1.8%)\n",
      "Samples with intersection: 2854 (98.2%)\n",
      "\n",
      "Bin Statistics:\n",
      "Bin 1 [44.5, 125.0) km: 123 samples\n",
      "Bin 2 [15.8, 44.5) km: 1747 samples\n",
      "Bin 3 [5.6, 15.8) km: 928 samples\n",
      "Bin 4 [2.0, 5.6) km: 56 samples\n",
      "\n",
      "No-intersection cases are 1.8% - proceeding with analysis\n",
      "\n",
      "Intersection Wavenumber Statistics:\n",
      "Mean: 0.0614\n",
      "Std: 0.0369\n",
      "Min: 0.0102\n",
      "Max: 0.4540\n"
     ]
    }
   ],
   "source": [
    "# ESR Analysis by PSD Intersection Bins (Log-spaced)\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import xarray as xr\n",
    "import xrft\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def isotropic_spectra(data):\n",
    "    \"\"\"Calculate the isotropic power spectrum of input data.\"\"\"\n",
    "    iso_psd = xrft.isotropic_power_spectrum(\n",
    "        data, \n",
    "        dim=['i', 'j'], \n",
    "        detrend='constant', \n",
    "        window=True,\n",
    "        nfactor=2\n",
    "    )\n",
    "    return iso_psd\n",
    "\n",
    "def calculate_psd_km(field, dx=1.5):\n",
    "    \"\"\"Calculate PSD with spatial coordinates in km.\"\"\"\n",
    "    i_km = np.arange(field.shape[0]) * dx\n",
    "    j_km = np.arange(field.shape[1]) * dx\n",
    "    da = xr.DataArray(\n",
    "        field,\n",
    "        dims=['i', 'j'],\n",
    "        coords={'i': i_km, 'j': j_km},\n",
    "        name='field'\n",
    "    )\n",
    "    return isotropic_spectra(da)\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def find_psd_intersection(bm_psd, ubm_psd, wavenumbers):\n",
    "    \"\"\"Find the first intersection point (smallest wavenumber) between BM and UBM PSDs\"\"\"\n",
    "    try:\n",
    "        # Find where UBM crosses above BM (or vice versa)\n",
    "        diff = ubm_psd - bm_psd\n",
    "        \n",
    "        # Look for sign changes\n",
    "        sign_changes = np.where(np.diff(np.sign(diff)))[0]\n",
    "        \n",
    "        if len(sign_changes) == 0:\n",
    "            return None  # No intersection found\n",
    "        \n",
    "        # Return the wavenumber of the first intersection (smallest wavenumber)\n",
    "        first_intersection_idx = sign_changes[0]\n",
    "        \n",
    "        # Linear interpolation to get more precise intersection point\n",
    "        k1, k2 = wavenumbers[first_intersection_idx], wavenumbers[first_intersection_idx + 1]\n",
    "        d1, d2 = diff[first_intersection_idx], diff[first_intersection_idx + 1]\n",
    "        \n",
    "        # Linear interpolation: find where diff crosses zero\n",
    "        intersection_k = k1 - d1 * (k2 - k1) / (d2 - d1)\n",
    "        \n",
    "        return intersection_k\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def create_log_bins(k_min=8e-3, k_max=5e-1, n_bins=4):\n",
    "    \"\"\"Create equally spaced log bins across the wavenumber range\"\"\"\n",
    "    log_min = np.log10(k_min)\n",
    "    log_max = np.log10(k_max)\n",
    "    \n",
    "    # Create bin edges in log space\n",
    "    log_edges = np.linspace(log_min, log_max, n_bins + 1)\n",
    "    bin_edges = 10**log_edges\n",
    "    \n",
    "    return bin_edges\n",
    "\n",
    "def bin_samples_by_intersection_logspace(eval_dataset, test_data, clean_idx_subset):\n",
    "    \"\"\"Bin samples based on BM-UBM PSD intersection wavenumbers using log-spaced bins\"\"\"\n",
    "    \n",
    "    # Create 4 equally spaced log bins\n",
    "    bin_edges = create_log_bins()\n",
    "    n_bins = len(bin_edges) - 1\n",
    "    \n",
    "    # Initialize bins\n",
    "    bins = {f'bin_{i}': [] for i in range(n_bins)}\n",
    "    no_intersection_samples = []\n",
    "    intersection_wavenumbers = []\n",
    "\n",
    "    print(\"Bin edges (spatial scale in km):\")\n",
    "    for i in range(n_bins):\n",
    "        km_low = 1/bin_edges[i+1]  # Note: reversed order since 1/k\n",
    "        km_high = 1/bin_edges[i]\n",
    "        print(f\"Bin {i+1}: [{km_low:.1f}, {km_high:.1f}) km\")\n",
    "    \n",
    "    # print(\"Bin edges (wavenumber):\")\n",
    "    # for i in range(n_bins):\n",
    "    #     print(f\"Bin {i+1}: [{bin_edges[i]:.4f}, {bin_edges[i+1]:.4f})\")\n",
    "    \n",
    "    for sample_idx in clean_idx_subset:\n",
    "        try:\n",
    "            # Get true BM and UBM for this sample\n",
    "            bm_true = eval_dataset.bm_truth.isel(sample=sample_idx).values\n",
    "            ubm_true = eval_dataset.ubm_truth.isel(sample=sample_idx).values\n",
    "            \n",
    "            # Skip samples with NaNs\n",
    "            if np.any(np.isnan(bm_true)) or np.any(np.isnan(ubm_true)):\n",
    "                continue\n",
    "                \n",
    "            # Calculate PSDs\n",
    "            psd_bm = calculate_psd_km(bm_true)\n",
    "            psd_ubm = calculate_psd_km(ubm_true)\n",
    "            wavenumbers = psd_bm[list(psd_bm.coords.keys())[0]].values\n",
    "            \n",
    "            # Find intersection\n",
    "            intersection_k = find_psd_intersection(psd_bm.values, psd_ubm.values, wavenumbers)\n",
    "            \n",
    "            # Bin the sample\n",
    "            if intersection_k is None:\n",
    "                no_intersection_samples.append(sample_idx)\n",
    "            else:\n",
    "                intersection_wavenumbers.append(intersection_k)\n",
    "                \n",
    "                # Find which bin this intersection falls into\n",
    "                bin_idx = np.digitize(intersection_k, bin_edges) - 1\n",
    "                \n",
    "                # Make sure it's within valid range\n",
    "                if 0 <= bin_idx < n_bins:\n",
    "                    bins[f'bin_{bin_idx}'].append(sample_idx)\n",
    "                else:\n",
    "                    no_intersection_samples.append(sample_idx)\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    return bins, no_intersection_samples, intersection_wavenumbers, bin_edges\n",
    "\n",
    "def calculate_esr_for_bin(eval_dataset, test_data, sample_indices):\n",
    "    \"\"\"Calculate average ESR for UBM for a specific bin of samples\"\"\"\n",
    "    if len(sample_indices) == 0:\n",
    "        return None, None\n",
    "    \n",
    "    esr_sum = None\n",
    "    wavenumbers = None\n",
    "    valid_count = 0\n",
    "    \n",
    "    for sample_idx in sample_indices:\n",
    "        try:\n",
    "            # Get true UBM for this sample\n",
    "            true_ubm = test_data.ubm.isel(sample=sample_idx).values\n",
    "            \n",
    "            # Skip samples with NaNs\n",
    "            if np.any(np.isnan(true_ubm)):\n",
    "                continue\n",
    "                \n",
    "            # Calculate PSD of true UBM\n",
    "            psd_true = calculate_psd_km(true_ubm)\n",
    "            if wavenumbers is None:\n",
    "                wavenumbers = psd_true[list(psd_true.coords.keys())[0]].values\n",
    "            \n",
    "            # Get predicted UBM for this sample (ZCA+SST model)\n",
    "            pred_ubm = eval_dataset.ubm_pred_mean.isel(sample=sample_idx).values\n",
    "            \n",
    "            # Skip if prediction contains NaNs\n",
    "            if np.any(np.isnan(pred_ubm)):\n",
    "                continue\n",
    "                \n",
    "            # Calculate PSD of the difference (error)\n",
    "            error = true_ubm - pred_ubm\n",
    "            psd_diff = calculate_psd_km(error)\n",
    "            \n",
    "            # Calculate ESR: PSD(error) / PSD(true)\n",
    "            esr = psd_diff.values / psd_true.values\n",
    "            \n",
    "            # Sum ESR values\n",
    "            if esr_sum is None:\n",
    "                esr_sum = esr.copy()\n",
    "            else:\n",
    "                esr_sum += esr\n",
    "                \n",
    "            valid_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    if valid_count == 0:\n",
    "        return None, None\n",
    "    \n",
    "    # Calculate average ESR\n",
    "    esr_avg = esr_sum / valid_count\n",
    "    \n",
    "    return esr_avg, wavenumbers\n",
    "\n",
    "# Set plotting parameters to match previous plots\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['Arial', 'DejaVu Sans', 'Helvetica', 'sans-serif'],\n",
    "    'mathtext.fontset': 'stix',  \n",
    "    'axes.grid': False,\n",
    "    'figure.facecolor': 'white',\n",
    "    'axes.facecolor': 'white', \n",
    "    'text.usetex': False,\n",
    "})\n",
    "\n",
    "# Main analysis\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "# Colors for the 4 bins\n",
    "bin_colors = ['#440154', '#31688e', '#35b779', '#fde725']\n",
    "\n",
    "# Bin samples by intersection wavenumbers\n",
    "bins, no_intersection, intersection_ks, bin_edges = bin_samples_by_intersection_logspace(\n",
    "    eval_datasets['sst_ssh'], test, clean_idx)\n",
    "\n",
    "# Print statistics\n",
    "total_samples = len(clean_idx)\n",
    "no_intersection_count = len(no_intersection)\n",
    "intersection_count = len(intersection_ks)\n",
    "\n",
    "print(f\"\\nIntersection Statistics:\")\n",
    "print(f\"Total clean samples: {total_samples}\")\n",
    "print(f\"Samples with no intersection: {no_intersection_count} ({no_intersection_count/total_samples*100:.1f}%)\")\n",
    "print(f\"Samples with intersection: {intersection_count} ({intersection_count/total_samples*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nBin Statistics:\")\n",
    "# for i, (bin_name, sample_list) in enumerate(bins.items()):\n",
    "#     bin_range = f\"[{bin_edges[i]:.3f}, {bin_edges[i+1]:.3f})\"\n",
    "#     print(f\"Bin {i+1} {bin_range}: {len(sample_list)} samples\")\n",
    "\n",
    "for i, (bin_name, sample_list) in enumerate(bins.items()):\n",
    "    km_low = 1/bin_edges[i+1]\n",
    "    km_high = 1/bin_edges[i]\n",
    "    bin_range = f\"[{km_low:.1f}, {km_high:.1f}) km\"\n",
    "    print(f\"Bin {i+1} {bin_range}: {len(sample_list)} samples\")\n",
    "\n",
    "# Only proceed if no-intersection cases are relatively small\n",
    "if no_intersection_count / total_samples < 0.2:  # Less than 20% no-intersection\n",
    "    print(f\"\\nNo-intersection cases are {no_intersection_count/total_samples*100:.1f}% - proceeding with analysis\")\n",
    "    \n",
    "    # Calculate and plot ESR for each bin\n",
    "    wavenumbers_ref = None\n",
    "    for i, (bin_name, sample_indices) in enumerate(bins.items()):\n",
    "        if len(sample_indices) > 0:\n",
    "            esr_avg, wavenumbers = calculate_esr_for_bin(eval_datasets['sst_ssh'], test, sample_indices)\n",
    "            \n",
    "            if esr_avg is not None:\n",
    "                if wavenumbers_ref is None:\n",
    "                    wavenumbers_ref = wavenumbers\n",
    "\n",
    "\n",
    "                km_low = 1/bin_edges[i+1]  \n",
    "                km_high = 1/bin_edges[i]\n",
    "                bin_range = f\"[{km_low:.1f}, {km_high:.1f}) km\"\n",
    "                ax.loglog(wavenumbers, esr_avg, color=bin_colors[i], \n",
    "                         linewidth=3.5, label=f\"Bin {i+1}: {bin_range} (N={len(sample_indices)})\", \n",
    "                         solid_capstyle='round')\n",
    "                \n",
    "                # bin_range = f\"[{bin_edges[i]:.3f}, {bin_edges[i+1]:.3f})\"\n",
    "                # ax.loglog(wavenumbers, esr_avg, color=bin_colors[i], \n",
    "                #          linewidth=3.5, label=f\"Bin {i+1}: {bin_range} (N={len(sample_indices)})\", \n",
    "                #          solid_capstyle='round')\n",
    "\n",
    "    # Add horizontal reference line at y = 1.0\n",
    "    ax.axhline(y=1.0, color='black', linestyle='-', linewidth=2, alpha=0.4)\n",
    "\n",
    "    # Set axis limits and formatting to match previous plots\n",
    "    ax.set_xlim(8e-3, 5e-1)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=28, length=12, \n",
    "                    width=2.5, direction='in', top=True, right=True)\n",
    "    ax.tick_params(axis='both', which='minor', length=8, \n",
    "                    width=1.5, direction='in', top=True, right=True)\n",
    "\n",
    "    # Labels\n",
    "    ax.set_xlabel(r'Wavenumber (cpkm)', fontsize=28)\n",
    "    ax.set_ylabel(r'Average ESR (UBM)', fontsize=28)\n",
    "\n",
    "    # Legend\n",
    "    ax.legend(loc='upper right', fontsize=18, frameon=False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig('/home/jovyan/GRL_ssh/figures/Figure_1/esr_ubm_binned_logspace.png', \n",
    "                bbox_inches='tight', dpi=300, facecolor='white', \n",
    "                edgecolor='none', format='png')\n",
    "    plt.savefig('/home/jovyan/GRL_ssh/figures/Figure_1/esr_ubm_binned_logspace.pdf', \n",
    "                bbox_inches='tight', facecolor='white', \n",
    "                edgecolor='none', format='pdf')\n",
    "\n",
    "    # Print intersection statistics\n",
    "    if intersection_ks:\n",
    "        print(f\"\\nIntersection Wavenumber Statistics:\")\n",
    "        print(f\"Mean: {np.mean(intersection_ks):.4f}\")\n",
    "        print(f\"Std: {np.std(intersection_ks):.4f}\")\n",
    "        print(f\"Min: {np.min(intersection_ks):.4f}\")\n",
    "        print(f\"Max: {np.max(intersection_ks):.4f}\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\nWarning: No-intersection cases are {no_intersection_count/total_samples*100:.1f}% - too high for analysis\")\n",
    "    print(\"Consider adjusting the intersection detection method or wavenumber range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aab466-bc65-4a6d-9499-d2160dab6916",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Averaged ESR & PSD over all samples Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b4c20-3fb1-475e-b735-6d493d9e48ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import xarray as xr\n",
    "import xrft\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def calculate_esr(pred, truth):\n",
    "    \"\"\"Calculate ESR (Error-to-Signal Ratio)\"\"\"\n",
    "    error = pred - truth\n",
    "    error_psd = calculate_psd_km(error)\n",
    "    truth_psd = calculate_psd_km(truth)\n",
    "    k_values = error_psd[list(error_psd.coords.keys())[0]].values\n",
    "    esr = error_psd.values / truth_psd.values\n",
    "    return k_values, esr\n",
    "\n",
    "def calculate_average_e2sr_from_datasets(eval_datasets, test_data, clean_idx):\n",
    "    \"\"\"Calculate average E2SR for models from eval_datasets\"\"\"\n",
    "    model_e2sr_sums = {}\n",
    "    sample_count = len(clean_idx)\n",
    "    first_sample = True\n",
    "    \n",
    "    # Model mapping\n",
    "    models = {\n",
    "        'ZCA+SST': 'sst_ssh',\n",
    "        'ZCA': 'ssh_only', \n",
    "        'MSE': 'mse_only'\n",
    "    }\n",
    "    \n",
    "    # Process each clean sample\n",
    "    for sample_idx in clean_idx:\n",
    "        # Get the true BM for this sample\n",
    "        true_bm = test_data.bm.isel(sample=sample_idx).values\n",
    "        \n",
    "        # Skip samples with NaNs\n",
    "        if np.any(np.isnan(true_bm)):\n",
    "            sample_count -= 1\n",
    "            continue\n",
    "            \n",
    "        # Calculate PSD of true BM\n",
    "        psd_true = calculate_psd_km(true_bm)\n",
    "        wavenumbers = psd_true[list(psd_true.coords.keys())[0]].values\n",
    "        \n",
    "        # For each model, calculate E2SR\n",
    "        for model_name, dataset_key in models.items():\n",
    "            # Get predicted BM for this sample (SSH - UBM_pred)\n",
    "            ssh_sample = test_data.ssh.isel(sample=sample_idx).values\n",
    "            ubm_pred = eval_datasets[dataset_key].ubm_pred_mean.isel(sample=sample_idx).values\n",
    "            pred_bm = ssh_sample - ubm_pred\n",
    "            \n",
    "            # Skip if prediction contains NaNs\n",
    "            if np.any(np.isnan(pred_bm)):\n",
    "                continue\n",
    "                \n",
    "            # Calculate PSD of the difference (error)\n",
    "            psd_diff = calculate_psd_km(true_bm - pred_bm)\n",
    "            \n",
    "            # Calculate E2SR: PSD(error) / PSD(true)\n",
    "            e2sr = psd_diff.values / psd_true.values\n",
    "            \n",
    "            # Initialize sum on first valid sample\n",
    "            if first_sample or model_name not in model_e2sr_sums:\n",
    "                model_e2sr_sums[model_name] = e2sr\n",
    "            else:\n",
    "                model_e2sr_sums[model_name] += e2sr\n",
    "        \n",
    "        first_sample = False\n",
    "    \n",
    "    # Calculate averages\n",
    "    model_e2sr_avg = {model: e2sr_sum / sample_count \n",
    "                      for model, e2sr_sum in model_e2sr_sums.items()}\n",
    "    \n",
    "    return model_e2sr_avg, wavenumbers\n",
    "\n",
    "def calculate_average_psd_and_envelopes(eval_dataset, test_data, clean_idx):\n",
    "    \"\"\"Calculate average PSD and uncertainty envelopes for ZCA+SST model\"\"\"\n",
    "    ubm_true_psds = []\n",
    "    bm_true_psds = []\n",
    "    ubm_envelope_lower_all = []\n",
    "    ubm_envelope_upper_all = []\n",
    "    bm_envelope_lower_all = []\n",
    "    bm_envelope_upper_all = []\n",
    "    \n",
    "    for sample_idx in clean_idx:\n",
    "        # Get true values\n",
    "        ubm_true = eval_dataset.ubm_truth.isel(sample=sample_idx).values\n",
    "        bm_true = eval_dataset.bm_truth.isel(sample=sample_idx).values\n",
    "        \n",
    "        # Skip samples with NaNs\n",
    "        if np.any(np.isnan(ubm_true)) or np.any(np.isnan(bm_true)):\n",
    "            continue\n",
    "        \n",
    "        # Calculate PSDs for true values\n",
    "        psd_ubm_true = calculate_psd_km(ubm_true)\n",
    "        psd_bm_true = calculate_psd_km(bm_true)\n",
    "        ubm_true_psds.append(psd_ubm_true.values)\n",
    "        bm_true_psds.append(psd_bm_true.values)\n",
    "        \n",
    "        # Get ensemble data and calculate envelopes for this sample\n",
    "        ubm_ensemble = eval_dataset.ubm_pred_samples.isel(sample=sample_idx).values\n",
    "        bm_ensemble = eval_dataset.bm_pred_samples.isel(sample=sample_idx).values\n",
    "        \n",
    "        # Calculate ensemble PSDs\n",
    "        ubm_ensemble_psds = []\n",
    "        bm_ensemble_psds = []\n",
    "        \n",
    "        for ens in range(30):\n",
    "            if not np.all(np.isnan(ubm_ensemble[ens, :, :])):\n",
    "                ubm_psd = calculate_psd_km(ubm_ensemble[ens, :, :])\n",
    "                ubm_ensemble_psds.append(ubm_psd.values)\n",
    "                \n",
    "            if not np.all(np.isnan(bm_ensemble[ens, :, :])):\n",
    "                bm_psd = calculate_psd_km(bm_ensemble[ens, :, :])\n",
    "                bm_ensemble_psds.append(bm_psd.values)\n",
    "        \n",
    "        # Calculate envelopes for this sample\n",
    "        if len(ubm_ensemble_psds) > 0:\n",
    "            ubm_ensemble_psds = np.array(ubm_ensemble_psds)\n",
    "            ubm_envelope_lower_all.append(np.nanpercentile(ubm_ensemble_psds, 5, axis=0))\n",
    "            ubm_envelope_upper_all.append(np.nanpercentile(ubm_ensemble_psds, 95, axis=0))\n",
    "            \n",
    "        if len(bm_ensemble_psds) > 0:\n",
    "            bm_ensemble_psds = np.array(bm_ensemble_psds)\n",
    "            bm_envelope_lower_all.append(np.nanpercentile(bm_ensemble_psds, 5, axis=0))\n",
    "            bm_envelope_upper_all.append(np.nanpercentile(bm_ensemble_psds, 95, axis=0))\n",
    "    \n",
    "    # Average over all samples\n",
    "    wavenumbers = psd_ubm_true[list(psd_ubm_true.coords.keys())[0]].values\n",
    "    avg_ubm_true_psd = np.mean(ubm_true_psds, axis=0)\n",
    "    avg_bm_true_psd = np.mean(bm_true_psds, axis=0)\n",
    "    \n",
    "    # Average the envelopes\n",
    "    avg_ubm_envelope_lower = np.mean(ubm_envelope_lower_all, axis=0)\n",
    "    avg_ubm_envelope_upper = np.mean(ubm_envelope_upper_all, axis=0)\n",
    "    avg_bm_envelope_lower = np.mean(bm_envelope_lower_all, axis=0)\n",
    "    avg_bm_envelope_upper = np.mean(bm_envelope_upper_all, axis=0)\n",
    "    \n",
    "    return {\n",
    "        'wavenumbers': wavenumbers,\n",
    "        'ubm_true_psd': avg_ubm_true_psd,\n",
    "        'bm_true_psd': avg_bm_true_psd,\n",
    "        'ubm_envelope_lower': avg_ubm_envelope_lower,\n",
    "        'ubm_envelope_upper': avg_ubm_envelope_upper,\n",
    "        'bm_envelope_lower': avg_bm_envelope_lower,\n",
    "        'bm_envelope_upper': avg_bm_envelope_upper\n",
    "    }\n",
    "\n",
    "# Professional publication settings\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['Arial', 'DejaVu Sans', 'Helvetica', 'sans-serif'],\n",
    "    'mathtext.fontset': 'stix',  \n",
    "    'axes.grid': False,\n",
    "    'figure.facecolor': 'white',\n",
    "    'axes.facecolor': 'white', \n",
    "    'text.usetex': False,\n",
    "})\n",
    "\n",
    "# Create figure with 1x2 subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Color palettes\n",
    "esr_colors = {\n",
    "    'ZCA+SST': '#dc143c',  # Crimson\n",
    "    'ZCA': '#ffd700',      # Gold\n",
    "    'MSE': '#ff9999',      # Light pink\n",
    "}\n",
    "\n",
    "psd_colors = {\n",
    "    'bm_true': '#d62728',     # Red\n",
    "    'ubm_true': '#1f77b4',   # Blue\n",
    "    'ubm_envelope': '#ff7f0e',  # Orange\n",
    "    'bm_envelope': '#2ca02c',   # Green\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# Left panel: ESR Comparison\n",
    "# ===============================\n",
    "ax1 = axes[0]\n",
    "\n",
    "print(\"Calculating average E2SR for all models...\")\n",
    "avg_e2sr, wavenumbers = calculate_average_e2sr_from_datasets(eval_datasets, test, clean_idx)\n",
    "\n",
    "# Plot E2SR lines for each model\n",
    "for model_name, e2sr in avg_e2sr.items():\n",
    "    ax1.plot(wavenumbers, e2sr, color=esr_colors[model_name], \n",
    "             linewidth=2.5, label=model_name, solid_capstyle='round')\n",
    "\n",
    "# Add horizontal reference line at y = 1.0\n",
    "ax1.axhline(y=1.0, color='black', linestyle='-', linewidth=1.5, alpha=0.3)\n",
    "ax1.text(ax1.get_xlim()[0]*1.5, 1.2, 'Error = 100% of True Signal', \n",
    "         fontsize=18, color='black', alpha=0.7)\n",
    "\n",
    "# Customize left panel\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_xlim(8e-3, 5e-1)\n",
    "\n",
    "# Tick styling\n",
    "ax1.tick_params(axis='both', which='major', labelsize=22, length=8, \n",
    "                width=1.5, direction='in', top=True, right=True)\n",
    "ax1.tick_params(axis='both', which='minor', length=4, \n",
    "                width=0.8, direction='in', top=True, right=True)\n",
    "\n",
    "# Labels\n",
    "ax1.set_xlabel(r'Wavenumber (cpkm)', fontsize=22)\n",
    "ax1.set_ylabel(r'Mean ESR', fontsize=22)\n",
    "\n",
    "# Panel label\n",
    "ax1.text(0.02, 0.98, 'a)', transform=ax1.transAxes, \n",
    "         fontsize=22, fontweight='bold', va='top', ha='left')\n",
    "\n",
    "# Legend for left panel\n",
    "ax1.legend(loc='upper right', fontsize=20, frameon=True, \n",
    "           framealpha=0.9, edgecolor='black', facecolor='white')\n",
    "\n",
    "# ===============================\n",
    "# Right panel: PSD Comparison\n",
    "# ===============================\n",
    "ax2 = axes[1]\n",
    "\n",
    "print(\"Calculating average PSD and envelopes for ZCA+SST model...\")\n",
    "psd_data = calculate_average_psd_and_envelopes(eval_datasets['sst_ssh'], test, clean_idx)\n",
    "\n",
    "# Plot true PSD lines\n",
    "ax2.plot(psd_data['wavenumbers'], psd_data['bm_true_psd'], color=psd_colors['bm_true'], \n",
    "         linewidth=2.5, label='BM True', solid_capstyle='round')\n",
    "ax2.plot(psd_data['wavenumbers'], psd_data['ubm_true_psd'], color=psd_colors['ubm_true'], \n",
    "         linewidth=2.5, label='UBM True', solid_capstyle='round')\n",
    "\n",
    "# Plot uncertainty envelopes\n",
    "ax2.fill_between(psd_data['wavenumbers'], psd_data['bm_envelope_lower'], psd_data['bm_envelope_upper'], \n",
    "                alpha=0.6, color=psd_colors['bm_envelope'], label='BM 90% CI', edgecolor='none')\n",
    "ax2.fill_between(psd_data['wavenumbers'], psd_data['ubm_envelope_lower'], psd_data['ubm_envelope_upper'], \n",
    "                alpha=0.6, color=psd_colors['ubm_envelope'], label='UBM 90% CI', edgecolor='none')\n",
    "\n",
    "# Customize right panel\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_xlim(8e-3, 5e-1)\n",
    "\n",
    "# Tick styling\n",
    "ax2.tick_params(axis='both', which='major', labelsize=22, length=8, \n",
    "                width=1.5, direction='in')\n",
    "ax2.tick_params(axis='both', which='minor', length=4, \n",
    "                width=0.8, direction='in')\n",
    "\n",
    "# Hide y-axis labels for right panel\n",
    "ax2.tick_params(axis='y', labelleft=False)\n",
    "\n",
    "# Labels\n",
    "ax2.set_xlabel(r'Wavenumber (cpkm)', fontsize=22)\n",
    "\n",
    "# Panel label\n",
    "ax2.text(0.02, 0.98, 'b)', transform=ax2.transAxes, \n",
    "         fontsize=22, fontweight='bold', va='top', ha='left')\n",
    "\n",
    "# Legend for right panel\n",
    "ax2.legend(loc='upper right', fontsize=20, frameon=True, \n",
    "           framealpha=0.9, edgecolor='black', facecolor='white', ncol=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('/home/jovyan/GRL_ssh/figures/combined_esr_psd_comparison.png', \n",
    "            bbox_inches='tight', dpi=300, facecolor='white', \n",
    "            edgecolor='none', format='png')\n",
    "plt.savefig('/home/jovyan/GRL_ssh/figures/combined_esr_psd_comparison.pdf', \n",
    "            bbox_inches='tight', facecolor='white', \n",
    "            edgecolor='none', format='pdf')\n",
    "\n",
    "\n",
    "print(\"Combined ESR and PSD comparison plot saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2740f89-6f35-4abe-96d2-d4cd10c3f365",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea6640c-6c73-4560-9cd4-ad021e392fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples=3645, clean=2907, skipped=738\n",
      "Processing model: sst_ssh\n",
      "Processing model: ssh_only\n",
      "Processing model: mse_only\n",
      "\n",
      "=== Summary metrics (mean over clean samples) ===\n",
      "          UBM_R2  UBM_corr  BM_R2  BM_corr   u_R2  u_corr   v_R2  v_corr  \\\n",
      "model                                                                      \n",
      "sst_ssh    0.010     0.478  0.969    0.987  0.848   0.925  0.849   0.924   \n",
      "ssh_only  -0.176     0.401  0.955    0.980  0.812   0.904  0.813   0.904   \n",
      "mse_only  -0.254     0.389  0.958    0.981  0.761   0.885  0.754   0.883   \n",
      "\n",
      "          avg_all  \n",
      "model              \n",
      "sst_ssh     0.749  \n",
      "ssh_only    0.699  \n",
      "mse_only    0.670  \n",
      "\n",
      "=== Summary metrics (5th percentile over clean samples) ===\n",
      "          UBM_R2  UBM_corr  BM_R2  BM_corr   u_R2  u_corr   v_R2  v_corr  \\\n",
      "model                                                                      \n",
      "sst_ssh   -0.938     0.010  0.869    0.942  0.567   0.778  0.582   0.774   \n",
      "ssh_only  -1.349    -0.107  0.800    0.909  0.445   0.701  0.399   0.682   \n",
      "mse_only  -1.579    -0.077  0.813    0.915  0.277   0.648  0.206   0.623   \n",
      "\n",
      "          avg_all  \n",
      "model              \n",
      "sst_ssh     0.448  \n",
      "ssh_only    0.310  \n",
      "mse_only    0.228  \n",
      "\n",
      "=== Summary metrics (95th percentile over clean samples) ===\n",
      "          UBM_R2  UBM_corr  BM_R2  BM_corr   u_R2  u_corr   v_R2  v_corr  \\\n",
      "model                                                                      \n",
      "sst_ssh    0.726     0.874  0.999    1.000  0.975   0.988  0.977   0.989   \n",
      "ssh_only   0.590     0.816  0.999    1.000  0.973   0.987  0.976   0.988   \n",
      "mse_only   0.613     0.816  0.999    0.999  0.967   0.984  0.968   0.984   \n",
      "\n",
      "          avg_all  \n",
      "model              \n",
      "sst_ssh     0.941  \n",
      "ssh_only    0.916  \n",
      "mse_only    0.916  \n",
      "\n",
      "=== Combined Summary (Mean ± Range) ===\n",
      "                          UBM_R2               UBM_corr                 BM_R2  \\\n",
      "model                                                                           \n",
      "sst_ssh     0.01 (-0.938, 0.726)    0.478 (0.01, 0.874)  0.969 (0.869, 0.999)   \n",
      "ssh_only   -0.176 (-1.349, 0.59)  0.401 (-0.107, 0.816)    0.955 (0.8, 0.999)   \n",
      "mse_only  -0.254 (-1.579, 0.613)  0.389 (-0.077, 0.816)  0.958 (0.813, 0.999)   \n",
      "\n",
      "                       BM_corr                  u_R2                u_corr  \\\n",
      "model                                                                        \n",
      "sst_ssh     0.987 (0.942, 1.0)  0.848 (0.567, 0.975)  0.925 (0.778, 0.988)   \n",
      "ssh_only     0.98 (0.909, 1.0)  0.812 (0.445, 0.973)  0.904 (0.701, 0.987)   \n",
      "mse_only  0.981 (0.915, 0.999)  0.761 (0.277, 0.967)  0.885 (0.648, 0.984)   \n",
      "\n",
      "                          v_R2                v_corr               avg_all  \n",
      "model                                                                       \n",
      "sst_ssh   0.849 (0.582, 0.977)  0.924 (0.774, 0.989)  0.749 (0.448, 0.941)  \n",
      "ssh_only  0.813 (0.399, 0.976)  0.904 (0.682, 0.988)   0.699 (0.31, 0.916)  \n",
      "mse_only  0.754 (0.206, 0.968)  0.883 (0.623, 0.984)   0.67 (0.228, 0.916)  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------------------------------\n",
    "# constants & grid info\n",
    "# -------------------------------------------------\n",
    "g      = 9.81       # m s⁻²\n",
    "dx     = 1_500.0    # m   (1.5 km grid)\n",
    "dy     = 1_500.0    # m\n",
    "f_cor  = -8.6e-5    # s⁻¹ (Agulhas region)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# clean-sample mask (no NaNs in truth UBM)\n",
    "# -------------------------------------------------\n",
    "clean_mask = ~test.ubm.isnull().any(dim=(\"i\", \"j\")).values\n",
    "clean_idx  = np.where(clean_mask)[0]\n",
    "print(f\"Total samples={len(clean_mask)}, clean={len(clean_idx)}, skipped={len(clean_mask)-len(clean_idx)}\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# helpers\n",
    "# -------------------------------------------------\n",
    "def flatten_clean(da):\n",
    "    \"\"\"Return (Nclean, P) NumPy array of flattened spatial dims.\"\"\"\n",
    "    return da.isel(sample=clean_idx).stack(pixels=(\"i\", \"j\")).values\n",
    "\n",
    "def r2_corr(truth, pred):\n",
    "    \"\"\"Per-sample R² & corr, with mean, 5th and 95th percentiles over clean samples.\"\"\"\n",
    "    r2_vals, c_vals = [], []\n",
    "    for t, p in zip(truth, pred):\n",
    "        m = np.isfinite(t) & np.isfinite(p)\n",
    "        if m.sum() < 2:\n",
    "            r2_vals.append(np.nan)\n",
    "            c_vals.append(np.nan)\n",
    "        else:\n",
    "            r2_vals.append(r2_score(t[m], p[m]))\n",
    "            c_vals.append(np.corrcoef(t[m], p[m])[0, 1])\n",
    "    \n",
    "    # Calculate mean and percentiles\n",
    "    r2_mean = np.nanmean(r2_vals)\n",
    "    r2_p05 = np.nanpercentile(r2_vals, 5)\n",
    "    r2_p95 = np.nanpercentile(r2_vals, 95)\n",
    "    \n",
    "    c_mean = np.nanmean(c_vals)\n",
    "    c_p05 = np.nanpercentile(c_vals, 5)\n",
    "    c_p95 = np.nanpercentile(c_vals, 95)\n",
    "    \n",
    "    return (r2_mean, r2_p05, r2_p95), (c_mean, c_p05, c_p95)\n",
    "\n",
    "def geostrophic_vel(field_2d_array):\n",
    "    \"\"\"Calculate geostrophic velocities from 2D SSH field.\"\"\"\n",
    "    dη_dy = np.gradient(field_2d_array, dy, axis=0, edge_order=2)\n",
    "    dη_dx = np.gradient(field_2d_array, dx, axis=1, edge_order=2)\n",
    "    u = -g / f_cor * dη_dy\n",
    "    v =  g / f_cor * dη_dx\n",
    "    return u, v\n",
    "\n",
    "def geostrophic_vel_xarray(da):\n",
    "    \"\"\"Calculate geostrophic velocities from xarray DataArray.\"\"\"\n",
    "    # Apply geostrophic_vel to each sample\n",
    "    u_list = []\n",
    "    v_list = []\n",
    "    for i in range(da.shape[0]):\n",
    "        u, v = geostrophic_vel(da.isel(sample=i).values)\n",
    "        u_list.append(u)\n",
    "        v_list.append(v)\n",
    "    \n",
    "    u_array = np.stack(u_list, axis=0)\n",
    "    v_array = np.stack(v_list, axis=0)\n",
    "    \n",
    "    # Create xarray DataArrays with same structure as input\n",
    "    u_da = da.copy()\n",
    "    u_da.values = u_array\n",
    "    v_da = da.copy() \n",
    "    v_da.values = v_array\n",
    "    \n",
    "    return u_da, v_da\n",
    "\n",
    "# Get true velocities from BM\n",
    "bm_true = test.bm\n",
    "u_true, v_true = geostrophic_vel_xarray(bm_true)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# models to evaluate from eval_datasets\n",
    "# -------------------------------------------------\n",
    "models = {\n",
    "    \"sst_ssh\": eval_datasets['sst_ssh'],\n",
    "    \"ssh_only\": eval_datasets['ssh_only'], \n",
    "    \"mse_only\": eval_datasets['mse_only']\n",
    "}\n",
    "\n",
    "# -------------------------------------------------\n",
    "# main loop\n",
    "# -------------------------------------------------\n",
    "records = []\n",
    "records_p05 = []  # For 5th percentile\n",
    "records_p95 = []  # For 95th percentile\n",
    "\n",
    "for name, dataset in models.items():\n",
    "    print(f\"Processing model: {name}\")\n",
    "    \n",
    "    # Get UBM predictions\n",
    "    ubm_pred = dataset.ubm_pred_mean\n",
    "    \n",
    "    # UBM metrics\n",
    "    (ubm_r2, ubm_r2_p05, ubm_r2_p95), (ubm_corr, ubm_corr_p05, ubm_corr_p95) = r2_corr(\n",
    "        flatten_clean(test.ubm), flatten_clean(ubm_pred))\n",
    "    \n",
    "    # BM metrics - calculate BM from SSH - UBM\n",
    "    bm_pred = test.ssh - ubm_pred\n",
    "    (bm_r2, bm_r2_p05, bm_r2_p95), (bm_corr, bm_corr_p05, bm_corr_p95) = r2_corr(\n",
    "        flatten_clean(bm_true), flatten_clean(bm_pred))\n",
    "    \n",
    "    # velocity metrics\n",
    "    u_pred, v_pred = geostrophic_vel_xarray(bm_pred)\n",
    "    (u_r2, u_r2_p05, u_r2_p95), (u_corr, u_corr_p05, u_corr_p95) = r2_corr(\n",
    "        flatten_clean(u_true), flatten_clean(u_pred))\n",
    "    (v_r2, v_r2_p05, v_r2_p95), (v_corr, v_corr_p05, v_corr_p95) = r2_corr(\n",
    "        flatten_clean(v_true), flatten_clean(v_pred))\n",
    "    \n",
    "    # average of all eight mean numbers\n",
    "    avg_all = np.nanmean([ubm_r2, ubm_corr, bm_r2, bm_corr,\n",
    "                          u_r2, u_corr, v_r2, v_corr])\n",
    "    \n",
    "    # average of all eight p05 numbers\n",
    "    avg_all_p05 = np.nanmean([ubm_r2_p05, ubm_corr_p05, bm_r2_p05, bm_corr_p05,\n",
    "                              u_r2_p05, u_corr_p05, v_r2_p05, v_corr_p05])\n",
    "    \n",
    "    # average of all eight p95 numbers\n",
    "    avg_all_p95 = np.nanmean([ubm_r2_p95, ubm_corr_p95, bm_r2_p95, bm_corr_p95,\n",
    "                              u_r2_p95, u_corr_p95, v_r2_p95, v_corr_p95])\n",
    "    \n",
    "    # Mean metrics\n",
    "    records.append(dict(model=name,\n",
    "                        UBM_R2=ubm_r2, UBM_corr=ubm_corr,\n",
    "                        BM_R2=bm_r2, BM_corr=bm_corr,\n",
    "                        u_R2=u_r2, u_corr=u_corr,\n",
    "                        v_R2=v_r2, v_corr=v_corr,\n",
    "                        avg_all=avg_all))\n",
    "    \n",
    "    # 5th percentile metrics\n",
    "    records_p05.append(dict(model=name,\n",
    "                            UBM_R2=ubm_r2_p05, UBM_corr=ubm_corr_p05,\n",
    "                            BM_R2=bm_r2_p05, BM_corr=bm_corr_p05,\n",
    "                            u_R2=u_r2_p05, u_corr=u_corr_p05,\n",
    "                            v_R2=v_r2_p05, v_corr=v_corr_p05,\n",
    "                            avg_all=avg_all_p05))\n",
    "    \n",
    "    # 95th percentile metrics\n",
    "    records_p95.append(dict(model=name,\n",
    "                            UBM_R2=ubm_r2_p95, UBM_corr=ubm_corr_p95,\n",
    "                            BM_R2=bm_r2_p95, BM_corr=bm_corr_p95,\n",
    "                            u_R2=u_r2_p95, u_corr=u_corr_p95,\n",
    "                            v_R2=v_r2_p95, v_corr=v_corr_p95,\n",
    "                            avg_all=avg_all_p95))\n",
    "\n",
    "# Create DataFrames for mean, p05, and p95\n",
    "metrics_all = (pd.DataFrame(records)\n",
    "               .set_index(\"model\")\n",
    "               .round(3)\n",
    "               .sort_values(\"avg_all\", ascending=False))\n",
    "\n",
    "metrics_p05 = (pd.DataFrame(records_p05)\n",
    "               .set_index(\"model\")\n",
    "               .round(3)\n",
    "               .sort_values(\"avg_all\", ascending=False))\n",
    "\n",
    "metrics_p95 = (pd.DataFrame(records_p95)\n",
    "               .set_index(\"model\")\n",
    "               .round(3)\n",
    "               .sort_values(\"avg_all\", ascending=False))\n",
    "\n",
    "\n",
    "print(\"\\n=== Combined Summary (Mean ± Range) ===\")\n",
    "combined_summary = pd.DataFrame(index=metrics_all.index)\n",
    "\n",
    "for col in ['UBM_R2', 'UBM_corr', 'BM_R2', 'BM_corr', 'u_R2', 'u_corr', 'v_R2', 'v_corr', 'avg_all']:\n",
    "    combined_summary[col] = (metrics_all[col].round(3).astype(str) + \n",
    "                            ' (' + metrics_p05[col].round(3).astype(str) + \n",
    "                            ', ' + metrics_p95[col].round(3).astype(str) + ')')\n",
    "\n",
    "print(combined_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366acde2-30a2-486b-8334-b56b9a5c8077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa36db21-75fb-4b87-8747-40c7638e9a94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SI Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceadec81-c5c2-45c3-9dfd-2bcfa50d7244",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Gaussin Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8b66e97-201e-4010-a937-04f70c1d6b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cmocean  # Added import for cmocean\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.colors import Normalize\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "best_sample_idx = extreme_samples['sst_ssh']['max']['sample_idx']\n",
    "best_r2_value = extreme_samples['sst_ssh']['max']['r2']\n",
    "\n",
    "# Get the true and predicted BM data for the best sample\n",
    "best_bm_true_sample = eval_datasets['sst_ssh'].bm_truth.isel(sample=best_sample_idx).values\n",
    "best_bm_pred_sample = eval_datasets['sst_ssh'].bm_pred_mean.isel(sample=best_sample_idx).values\n",
    "\n",
    "plt.rcParams.update({\n",
    "        'font.family': 'sans-serif',\n",
    "        'font.sans-serif': ['Arial', 'DejaVu Sans', 'Helvetica', 'sans-serif'],\n",
    "        'mathtext.fontset': 'stix',  \n",
    "        'axes.grid': False,\n",
    "        'figure.facecolor': 'white',\n",
    "        'axes.facecolor': 'white'\n",
    "    })\n",
    "\n",
    "# Set title parameters\n",
    "title_fontsize = 40 \n",
    "title_pad = 8\n",
    "\n",
    "# Set colorbar tick fontsize\n",
    "colorbar_tick_fontsize = 35\n",
    "\n",
    "# ----------------------\n",
    "# Define plotting parameters\n",
    "# ----------------------\n",
    "# Column 1: Original data\n",
    "vmin_orig, vmax_orig = -0.08, 0.08\n",
    "\n",
    "# Column 2: Features < 60km \n",
    "vmin_60, vmax_60 = -0.02, 0.02\n",
    "\n",
    "# Column 3: Features < 30km \n",
    "vmin_30, vmax_30 = -0.02, 0.02\n",
    "\n",
    "# Column 4: Features < 10km \n",
    "vmin_10, vmax_10 = -0.002, 0.002\n",
    "\n",
    "# Define parameters for normalized error\n",
    "# Using appropriate scales for each column \n",
    "vmin_norm_orig, vmax_norm_orig = 0, 2.0  # Normalized absolute error for original data\n",
    "vmin_norm_60, vmax_norm_60 = 0, 2.0  # Normalized absolute error for 60km features\n",
    "vmin_norm_30, vmax_norm_30 = 0, 2.0  # Normalized absolute error for 30km features\n",
    "vmin_norm_10, vmax_norm_10 = 0, 2.0  # Normalized absolute error for 10km features\n",
    "\n",
    "# Define tick values in actual data units \n",
    "ticks_orig_data = np.array([-0.08, -0.04, 0.0, 0.04, 0.08])\n",
    "ticks_60_data = np.array([-0.02, -0.01, 0.0, 0.01, 0.02])  \n",
    "ticks_30_data = np.array([-0.02, -0.01, 0.0, 0.01, 0.02])  \n",
    "ticks_10_data = np.array([-0.002, -0.001, 0.0, 0.001, 0.002])  \n",
    "\n",
    "# Define ticks for normalized absolute error (dimensionless)\n",
    "ticks_norm_orig_data = np.array([0, 0.5, 1.0, 1.5, 2.0])\n",
    "ticks_norm_60_data = np.array([0, 0.5, 1.0, 1.5, 2.0])\n",
    "ticks_norm_30_data = np.array([0, 0.5, 1.0, 1.5, 2.0])\n",
    "ticks_norm_10_data = np.array([0, 0.5, 1.0, 1.5, 2.0])\n",
    "\n",
    "# Create the size of arrays\n",
    "size = best_bm_true_sample.shape[0]\n",
    "i = np.arange(size)\n",
    "j = np.arange(size)\n",
    "\n",
    "# Calculate Gaussian filter parameters based on physical distance\n",
    "pixel_size = 1.5  # km per grid point\n",
    "\n",
    "# For features smaller than 60km\n",
    "scale_60km = 60 / pixel_size  # Convert to grid units\n",
    "sigma_60km = scale_60km / np.sqrt(12)  # Convert to Gaussian sigma using np.sqrt(12)\n",
    "\n",
    "# For features smaller than 30km\n",
    "scale_30km = 30 / pixel_size  # Convert to grid units\n",
    "sigma_30km = scale_30km / np.sqrt(12)  # Convert to Gaussian sigma using np.sqrt(12)\n",
    "\n",
    "# For features smaller than 10km\n",
    "scale_10km = 10 / pixel_size  # Convert to grid units\n",
    "sigma_10km = scale_10km / np.sqrt(12)  # Convert to Gaussian sigma using np.sqrt(12)\n",
    "\n",
    "# Apply Gaussian filter to get high-pass filtered versions\n",
    "# For 60km features\n",
    "true_low_pass_60km = gaussian_filter(best_bm_true_sample, sigma=sigma_60km)\n",
    "true_high_pass_60km = best_bm_true_sample - true_low_pass_60km\n",
    "pred_low_pass_60km = gaussian_filter(best_bm_pred_sample, sigma=sigma_60km)\n",
    "pred_high_pass_60km = best_bm_pred_sample - pred_low_pass_60km\n",
    "\n",
    "# For 30km features\n",
    "true_low_pass_30km = gaussian_filter(best_bm_true_sample, sigma=sigma_30km)\n",
    "true_high_pass_30km = best_bm_true_sample - true_low_pass_30km\n",
    "pred_low_pass_30km = gaussian_filter(best_bm_pred_sample, sigma=sigma_30km)\n",
    "pred_high_pass_30km = best_bm_pred_sample - pred_low_pass_30km\n",
    "\n",
    "# For 10km features\n",
    "true_low_pass_10km = gaussian_filter(best_bm_true_sample, sigma=sigma_10km)\n",
    "true_high_pass_10km = best_bm_true_sample - true_low_pass_10km\n",
    "pred_low_pass_10km = gaussian_filter(best_bm_pred_sample, sigma=sigma_10km)\n",
    "pred_high_pass_10km = best_bm_pred_sample - pred_low_pass_10km\n",
    "\n",
    "# Crop the arrays to remove boundary effects\n",
    "# Define crop width \n",
    "crop_width = 2\n",
    "\n",
    "# Crop for 60km features\n",
    "true_high_pass_60km_cropped = true_high_pass_60km[crop_width:-crop_width, crop_width:-crop_width]\n",
    "pred_high_pass_60km_cropped = pred_high_pass_60km[crop_width:-crop_width, crop_width:-crop_width]\n",
    "\n",
    "# Crop for 30km features\n",
    "true_high_pass_30km_cropped = true_high_pass_30km[crop_width:-crop_width, crop_width:-crop_width]\n",
    "pred_high_pass_30km_cropped = pred_high_pass_30km[crop_width:-crop_width, crop_width:-crop_width]\n",
    "\n",
    "# Crop for 10km features\n",
    "true_high_pass_10km_cropped = true_high_pass_10km[crop_width:-crop_width, crop_width:-crop_width]\n",
    "pred_high_pass_10km_cropped = pred_high_pass_10km[crop_width:-crop_width, crop_width:-crop_width]\n",
    "\n",
    "# Also crop the original data for consistency\n",
    "best_bm_true_sample_cropped = best_bm_true_sample[crop_width:-crop_width, crop_width:-crop_width]\n",
    "best_bm_pred_sample_cropped = best_bm_pred_sample[crop_width:-crop_width, crop_width:-crop_width]\n",
    "\n",
    "# Calculate normalized absolute errors \n",
    "# Normalized absolute error for original data\n",
    "squared_error_orig = np.abs(best_bm_pred_sample_cropped - best_bm_true_sample_cropped)\n",
    "std_orig = np.std(best_bm_true_sample_cropped)\n",
    "norm_absolute_error_orig = squared_error_orig / std_orig\n",
    "\n",
    "# Normalized absolute error for 60km features\n",
    "squared_error_60km = np.abs(pred_high_pass_60km_cropped - true_high_pass_60km_cropped)\n",
    "std_60km = np.std(true_high_pass_60km_cropped)\n",
    "norm_absolute_error_60km = squared_error_60km / std_60km\n",
    "\n",
    "# Normalized absolute error for 30km features\n",
    "squared_error_30km = np.abs(pred_high_pass_30km_cropped - true_high_pass_30km_cropped)\n",
    "std_30km = np.std(true_high_pass_30km_cropped)\n",
    "norm_absolute_error_30km = squared_error_30km / std_30km\n",
    "\n",
    "# Normalized absolute error for 10km features\n",
    "squared_error_10km = np.abs(pred_high_pass_10km_cropped - true_high_pass_10km_cropped)\n",
    "std_10km = np.std(true_high_pass_10km_cropped)\n",
    "norm_absolute_error_10km = squared_error_10km / std_10km\n",
    "\n",
    "# Create figure with subplots \n",
    "fig = plt.figure(figsize=(38, 20))  \n",
    "\n",
    "# Create a grid with proper alignment - 3 rows, 15 columns\n",
    "gs = gridspec.GridSpec(3, 15,  \n",
    "                      width_ratios=[0.94, 0.001, 0.08, 0.3, 0.94, 0.001, 0.08, 0.3, 0.94, 0.001, 0.08, 0.3, 0.94, 0.001, 0.08],  \n",
    "                      height_ratios=[1, 1, 1],\n",
    "                      wspace=-0.05, hspace=0.12)\n",
    "\n",
    "# Define colormap as cmocean thermal \n",
    "cmap_bm = cmocean.cm.ice\n",
    "cmap_norm_error = cmocean.cm.amp\n",
    "\n",
    "# Helper function to format the axes with centered titles\n",
    "def format_ax(ax, title):\n",
    "    # Remove all ticks\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    # Set title\n",
    "    ax.set_title(title, fontsize=title_fontsize, pad=title_pad, loc='center')\n",
    "    \n",
    "\n",
    "# Helper function to create colorbar with scientific notation header\n",
    "def create_colorbar_with_scientific(im, cax, ticks, unit, exponent, extend_type='both'):\n",
    "    cbar = plt.colorbar(im, cax=cax, extend=extend_type, ticks=ticks)\n",
    "    \n",
    "    # Set the ylabel with units\n",
    "    cbar.ax.set_ylabel(unit, rotation=270, labelpad=25, fontsize=30)\n",
    "    cbar.ax.yaxis.tick_right()\n",
    "    cbar.ax.yaxis.set_label_position('right')\n",
    "    \n",
    "    # Format tick labels as simple numbers \n",
    "    tick_labels = [f'{x * (10**(-exponent)):.1f}' for x in ticks]\n",
    "    cbar.ax.set_yticklabels(tick_labels)\n",
    "    cbar.ax.tick_params(labelsize=colorbar_tick_fontsize, length=8, width=2)\n",
    "    \n",
    "    # Add scientific notation multiplier at the top center\n",
    "    if exponent != 0:\n",
    "        multiplier_text = f'×10$^{{{exponent}}}$'\n",
    "        cbar.ax.text(0.75, 1.04, multiplier_text, transform=cbar.ax.transAxes, \n",
    "                    ha='center', va='bottom', fontsize=28)\n",
    "    \n",
    "    return cbar\n",
    "\n",
    "# Helper function for normalized error colorbars \n",
    "def create_normalized_colorbar(im, cax, ticks, extend_type='max'):\n",
    "    cbar = plt.colorbar(im, cax=cax, extend=extend_type, ticks=ticks)\n",
    "    cbar.ax.set_ylabel('', rotation=270, labelpad=25, fontsize=30)\n",
    "    cbar.ax.yaxis.tick_right()\n",
    "    cbar.ax.yaxis.set_label_position('right')\n",
    "    cbar.ax.set_yticklabels([f'{x:.1f}' for x in ticks])\n",
    "    cbar.ax.tick_params(labelsize=colorbar_tick_fontsize, length=8, width=2)\n",
    "    return cbar\n",
    "\n",
    "# Row 1: True Data\n",
    "# Column 1: Original data\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "im1 = ax1.imshow(best_bm_true_sample_cropped, cmap=cmap_bm, vmin=vmin_orig, vmax=vmax_orig)\n",
    "format_ax(ax1, '<120 km')\n",
    "\n",
    "# Column 2: Features < 60km \n",
    "ax1_5 = fig.add_subplot(gs[0, 4])\n",
    "im1_5 = ax1_5.imshow(true_high_pass_60km_cropped, cmap=cmap_bm, vmin=vmin_60, vmax=vmax_60)\n",
    "format_ax(ax1_5, '<60 km')\n",
    "\n",
    "# Column 3: Features < 30km\n",
    "ax2 = fig.add_subplot(gs[0, 8])\n",
    "im2 = ax2.imshow(true_high_pass_30km_cropped, cmap=cmap_bm, vmin=vmin_30, vmax=vmax_30)\n",
    "format_ax(ax2, '<30 km')\n",
    "\n",
    "# Column 4: Features < 10km\n",
    "ax3 = fig.add_subplot(gs[0, 12])\n",
    "im3 = ax3.imshow(true_high_pass_10km_cropped, cmap=cmap_bm, vmin=vmin_10, vmax=vmax_10)\n",
    "format_ax(ax3, '<10 km')\n",
    "\n",
    "# Add row label for first row\n",
    "ax1.text(-0.06, 0.5, 'True', transform=ax1.transAxes, rotation=90, \n",
    "         va='center', ha='center', fontsize=title_fontsize)\n",
    "\n",
    "# Row 2: Predicted Data\n",
    "# Column 1: Original data\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "im4 = ax4.imshow(best_bm_pred_sample_cropped, cmap=cmap_bm, vmin=vmin_orig, vmax=vmax_orig)\n",
    "format_ax(ax4, '')\n",
    "\n",
    "# Column 2: Features < 60km\n",
    "ax4_5 = fig.add_subplot(gs[1, 4])\n",
    "im4_5 = ax4_5.imshow(pred_high_pass_60km_cropped, cmap=cmap_bm, vmin=vmin_60, vmax=vmax_60)\n",
    "format_ax(ax4_5, '')\n",
    "\n",
    "# Column 3: Features < 30km\n",
    "ax5 = fig.add_subplot(gs[1, 8])\n",
    "im5 = ax5.imshow(pred_high_pass_30km_cropped, cmap=cmap_bm, vmin=vmin_30, vmax=vmax_30)\n",
    "format_ax(ax5, '')\n",
    "\n",
    "# Column 4: Features < 10km \n",
    "ax6 = fig.add_subplot(gs[1, 12])\n",
    "im6 = ax6.imshow(pred_high_pass_10km_cropped, cmap=cmap_bm, vmin=vmin_10, vmax=vmax_10)\n",
    "format_ax(ax6, '')\n",
    "\n",
    "# Add row label for second row\n",
    "ax4.text(-0.06, 0.5, 'ZCA+SST', transform=ax4.transAxes, rotation=90, \n",
    "         va='center', ha='center', fontsize=title_fontsize)\n",
    "\n",
    "# Row 3: Normalized absolute Error \n",
    "# Column 1: Normalized absolute error for original data\n",
    "ax7 = fig.add_subplot(gs[2, 0])\n",
    "im7 = ax7.imshow(norm_absolute_error_orig, cmap=cmap_norm_error, vmin=0, vmax=vmax_norm_orig)\n",
    "format_ax(ax7, '')\n",
    "\n",
    "# Column 2: Normalized absolute error for 60km features \n",
    "ax7_5 = fig.add_subplot(gs[2, 4])\n",
    "im7_5 = ax7_5.imshow(norm_absolute_error_60km, cmap=cmap_norm_error, vmin=0, vmax=vmax_norm_60)\n",
    "format_ax(ax7_5, '')\n",
    "\n",
    "# Column 3: Normalized absolute error for 30km features \n",
    "ax8 = fig.add_subplot(gs[2, 8])\n",
    "im8 = ax8.imshow(norm_absolute_error_30km, cmap=cmap_norm_error, vmin=0, vmax=vmax_norm_30)\n",
    "format_ax(ax8, '')\n",
    "\n",
    "# Column 4: Normalized absolute error for 10km features\n",
    "ax9 = fig.add_subplot(gs[2, 12])\n",
    "im9 = ax9.imshow(norm_absolute_error_10km, cmap=cmap_norm_error, vmin=0, vmax=vmax_norm_10)\n",
    "format_ax(ax9, '')\n",
    "\n",
    "# Add row label for third row\n",
    "ax7.text(-0.06, 0.5, 'Error', transform=ax7.transAxes, rotation=90, \n",
    "         va='center', ha='center', fontsize=title_fontsize)\n",
    "\n",
    "# Create colorbars for each panel with improved scientific notation\n",
    "# Row 1 colorbars (True data)\n",
    "# Colorbar for A1 (original data, -2 exponent)\n",
    "cax1 = fig.add_subplot(gs[0, 2])\n",
    "cbar1 = create_colorbar_with_scientific(im1, cax1, ticks_orig_data, '(m)', -2)\n",
    "\n",
    "# Colorbar for A2 (60km features, -2 exponent)\n",
    "cax1_5 = fig.add_subplot(gs[0, 6])\n",
    "cbar1_5 = create_colorbar_with_scientific(im1_5, cax1_5, ticks_60_data, '(m)', -2)\n",
    "\n",
    "# Colorbar for A3 (30km features, -2 exponent)\n",
    "cax2 = fig.add_subplot(gs[0, 10])\n",
    "cbar2 = create_colorbar_with_scientific(im2, cax2, ticks_30_data, '(m)', -2)\n",
    "\n",
    "# Colorbar for A4 (10km features, -3 exponent)\n",
    "cax3 = fig.add_subplot(gs[0, 14])\n",
    "cbar3 = create_colorbar_with_scientific(im3, cax3, ticks_10_data, '(m)', -3)\n",
    "\n",
    "# Row 2 colorbars (Predicted data)\n",
    "# Colorbar for B1\n",
    "cax4 = fig.add_subplot(gs[1, 2])\n",
    "cbar4 = create_colorbar_with_scientific(im4, cax4, ticks_orig_data, '(m)', -2)\n",
    "\n",
    "# Colorbar for B2\n",
    "cax4_5 = fig.add_subplot(gs[1, 6])\n",
    "cbar4_5 = create_colorbar_with_scientific(im4_5, cax4_5, ticks_60_data, '(m)', -2)\n",
    "\n",
    "# Colorbar for B3\n",
    "cax5 = fig.add_subplot(gs[1, 10])\n",
    "cbar5 = create_colorbar_with_scientific(im5, cax5, ticks_30_data, '(m)', -2)\n",
    "\n",
    "# Colorbar for B4\n",
    "cax6 = fig.add_subplot(gs[1, 14])\n",
    "cbar6 = create_colorbar_with_scientific(im6, cax6, ticks_10_data, '(m)', -3)\n",
    "\n",
    "# Row 3 colorbars (Normalized Absolute Error)\n",
    "# Colorbar for C1\n",
    "cax7 = fig.add_subplot(gs[2, 2])\n",
    "cbar7 = create_normalized_colorbar(im7, cax7, ticks_norm_orig_data)\n",
    "\n",
    "# Colorbar for C2\n",
    "cax7_5 = fig.add_subplot(gs[2, 6])\n",
    "cbar7_5 = create_normalized_colorbar(im7_5, cax7_5, ticks_norm_60_data)\n",
    "\n",
    "# Colorbar for C3\n",
    "cax8 = fig.add_subplot(gs[2, 10])\n",
    "cbar8 = create_normalized_colorbar(im8, cax8, ticks_norm_30_data)\n",
    "\n",
    "# Colorbar for C4\n",
    "cax9 = fig.add_subplot(gs[2, 14])\n",
    "cbar9 = create_normalized_colorbar(im9, cax9, ticks_norm_10_data)\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('/home/jovyan/GRL_ssh/figures/SI/scales_bm.png', bbox_inches='tight', dpi=300, transparent=True)\n",
    "plt.savefig('/home/jovyan/GRL_ssh/figures/SI/scales_bm.pdf', bbox_inches='tight', dpi=300, transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ef6f59-0444-47dc-bf8b-82fea3b12ae5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5e7125d-3edf-4c62-b500-6dd9ab010cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rcParams.update({\n",
    "    'font.size': 18,\n",
    "    'font.family': 'serif',\n",
    "    'axes.linewidth': 1.2,\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "    'xtick.major.width': 1.2,\n",
    "    'ytick.major.width': 1.2,\n",
    "    'xtick.minor.width': 0.8,\n",
    "    'ytick.minor.width': 0.8,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3,\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.labelsize': 18,\n",
    "    'ytick.labelsize': 18,\n",
    "    'axes.labelsize': 18,\n",
    "    'axes.titlesize': 18\n",
    "})\n",
    "\n",
    "\n",
    "models = ['mse_only', 'ssh_only', 'sst_ssh']\n",
    "model_titles = ['MSE+SST', 'ZCA', 'ZCA+SST']\n",
    "\n",
    "# Define outlier thresholds\n",
    "R2_MIN = 0.001  # Minimum R^2 to include (removes very negative values)\n",
    "R2_MAX = 1.0\n",
    "REL_MAG_MIN = 0.001  # Minimum relative magnitude\n",
    "REL_MAG_MAX = 1   # Maximum relative magnitude\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(22, 12))\n",
    "\n",
    "\n",
    "for col, model in enumerate(models):\n",
    "\n",
    "    ubm_truth = eval_datasets[model].ubm_truth\n",
    "    bm_truth = eval_datasets[model].bm_truth\n",
    "    ubm_pred = eval_datasets[model].ubm_pred_mean\n",
    "    bm_pred = eval_datasets[model].bm_pred_mean\n",
    "    \n",
    "    # Get number of samples\n",
    "    n_samples = ubm_truth.shape[0]\n",
    "    \n",
    "    # Initialize arrays to store metrics for each sample\n",
    "    bm_r2_values = []\n",
    "    ubm_r2_values = []\n",
    "    relative_magnitudes = []\n",
    "    \n",
    "    # Calculate metrics for each sample\n",
    "    for sample_idx in range(n_samples):\n",
    "        # Get 2D fields for current sample\n",
    "        ubm_true_2d = ubm_truth[sample_idx, :, :].values.flatten()\n",
    "        bm_true_2d = bm_truth[sample_idx, :, :].values.flatten()\n",
    "        ubm_pred_2d = ubm_pred[sample_idx, :, :].values.flatten()\n",
    "        bm_pred_2d = bm_pred[sample_idx, :, :].values.flatten()\n",
    "        \n",
    "        # Remove NaN values if any\n",
    "        valid_mask_ubm = ~(np.isnan(ubm_true_2d) | np.isnan(ubm_pred_2d))\n",
    "        valid_mask_bm = ~(np.isnan(bm_true_2d) | np.isnan(bm_pred_2d))\n",
    "        \n",
    "        # Calculate R^2 for UBM and BM\n",
    "        if np.sum(valid_mask_ubm) > 1:\n",
    "            ubm_r2 = r2_score(ubm_true_2d[valid_mask_ubm], ubm_pred_2d[valid_mask_ubm])\n",
    "        else:\n",
    "            ubm_r2 = np.nan\n",
    "            \n",
    "        if np.sum(valid_mask_bm) > 1:\n",
    "            bm_r2 = r2_score(bm_true_2d[valid_mask_bm], bm_pred_2d[valid_mask_bm])\n",
    "        else:\n",
    "            bm_r2 = np.nan\n",
    "        \n",
    "        # Calculate relative magnitude (mean absolute values to avoid division issues)\n",
    "        # Check if we have valid data before calculating magnitudes\n",
    "        if np.sum(~np.isnan(ubm_true_2d)) > 0:\n",
    "            ubm_magnitude = np.nanmean(np.abs(ubm_true_2d))\n",
    "        else:\n",
    "            ubm_magnitude = np.nan\n",
    "            \n",
    "        if np.sum(~np.isnan(bm_true_2d)) > 0:\n",
    "            bm_magnitude = np.nanmean(np.abs(bm_true_2d))\n",
    "        else:\n",
    "            bm_magnitude = np.nan\n",
    "        \n",
    "        if not np.isnan(bm_magnitude) and bm_magnitude != 0 and not np.isnan(ubm_magnitude):\n",
    "            rel_magnitude = ubm_magnitude / bm_magnitude\n",
    "        else:\n",
    "            rel_magnitude = np.nan\n",
    "        \n",
    "        # Store values\n",
    "        bm_r2_values.append(bm_r2)\n",
    "        ubm_r2_values.append(ubm_r2)\n",
    "        relative_magnitudes.append(rel_magnitude)\n",
    "    \n",
    "    # Convert to numpy arrays and remove NaN values for plotting\n",
    "    bm_r2_values = np.array(bm_r2_values)\n",
    "    ubm_r2_values = np.array(ubm_r2_values)\n",
    "    relative_magnitudes = np.array(relative_magnitudes)\n",
    "    \n",
    "    # Plot BM (top row)\n",
    "    valid_bm = ~(np.isnan(bm_r2_values) | np.isnan(relative_magnitudes))\n",
    "    if np.sum(valid_bm) > 0:\n",
    "        # Apply outlier filtering\n",
    "        bm_r2_filt = bm_r2_values[valid_bm]\n",
    "        rel_mag_filt = relative_magnitudes[valid_bm]\n",
    "        \n",
    "        # Filter outliers\n",
    "        outlier_mask = ((bm_r2_filt >= R2_MIN) & (bm_r2_filt <= R2_MAX) & \n",
    "                       (rel_mag_filt >= REL_MAG_MIN) & (rel_mag_filt <= REL_MAG_MAX))\n",
    "        \n",
    "        if np.sum(outlier_mask) > 0:\n",
    "            hb = axes[0, col].hexbin(rel_mag_filt[outlier_mask], bm_r2_filt[outlier_mask],\n",
    "                                   gridsize=60, cmap='Reds', mincnt=1, \n",
    "                                   xscale='log', yscale='log', vmin=0, vmax=3)\n",
    "    \n",
    "    axes[0, col].set_title(f'{model_titles[col]} (BM)', fontsize=18, fontweight='bold', pad=20)\n",
    "    # Only add x-axis label for bottom row\n",
    "    if col == 0:  # Only label y-axis for leftmost column\n",
    "        axes[0, col].set_ylabel('R²', fontsize=16)\n",
    "    axes[0, col].set_xscale('log')\n",
    "    axes[0, col].set_yscale('log')\n",
    "    axes[0, col].set_xlim(1e-3, 1e0)\n",
    "    axes[0, col].set_ylim(1e-3, 1e0)\n",
    "    axes[0, col].tick_params(which='both', direction='in', top=True, right=True)\n",
    "    \n",
    "    # Plot UBM (bottom row)\n",
    "    valid_ubm = ~(np.isnan(ubm_r2_values) | np.isnan(relative_magnitudes))\n",
    "    if np.sum(valid_ubm) > 0:\n",
    "        # Apply outlier filtering\n",
    "        ubm_r2_filt = ubm_r2_values[valid_ubm]\n",
    "        rel_mag_filt = relative_magnitudes[valid_ubm]\n",
    "        \n",
    "        # Filter outliers\n",
    "        outlier_mask = ((ubm_r2_filt >= R2_MIN) & (ubm_r2_filt <= R2_MAX) & \n",
    "                       (rel_mag_filt >= REL_MAG_MIN) & (rel_mag_filt <= REL_MAG_MAX))\n",
    "        \n",
    "        if np.sum(outlier_mask) > 0:\n",
    "            hb = axes[1, col].hexbin(rel_mag_filt[outlier_mask], ubm_r2_filt[outlier_mask],\n",
    "                                   gridsize=60, cmap='Blues', mincnt=1, \n",
    "                                   xscale='log', yscale='log', vmin=0, vmax=3)\n",
    "    \n",
    "    axes[1, col].set_title(f'{model_titles[col]} (UBM)', fontsize=18, fontweight='bold', pad=20)\n",
    "    axes[1, col].set_xlabel('Relative Magnitude (UBM/BM)', fontsize=16)  # x-axis label for bottom row\n",
    "    if col == 0:  # Only label y-axis for leftmost column\n",
    "        axes[1, col].set_ylabel('R²', fontsize=16)\n",
    "    axes[1, col].set_xscale('log')\n",
    "    axes[1, col].set_yscale('log')\n",
    "    axes[1, col].set_xlim(1e-3, 1e0)\n",
    "    axes[1, col].set_ylim(1e-3, 1e0)\n",
    "    axes[1, col].tick_params(which='both', direction='in', top=True, right=True)\n",
    "\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.93]) \n",
    "plt.subplots_adjust(hspace=0.35, wspace=0.15)  \n",
    "\n",
    "plt.savefig('figures/SI/scatter.png', dpi=300, bbox_inches='tight', \n",
    "            facecolor='white', edgecolor='none')\n",
    "plt.savefig('figures/SI/scatter.pdf', dpi=300, bbox_inches='tight', \n",
    "            facecolor='white', edgecolor='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c294bf7-0d75-4bfe-aedd-cb5f05509c27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## R^2 & Std Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94f327ab-1b28-4938-980e-075acb94a96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to: figures/SI/performance_maps.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.metrics import r2_score\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "def calculate_spatial_r2(true_data, pred_data):\n",
    "    \"\"\"\n",
    "    Calculate R^2 for each spatial location across the time dimension.\n",
    "    \n",
    "    Args:\n",
    "        true_data: Array of shape (n_samples, H, W)\n",
    "        pred_data: Array of shape (n_samples, H, W)\n",
    "    \n",
    "    Returns:\n",
    "        r2_map: Array of shape (H, W) with R^2 values for each spatial location\n",
    "    \"\"\"\n",
    "    n_samples, H, W = true_data.shape\n",
    "    r2_map = np.zeros((H, W))\n",
    "    \n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            # Extract time series for this spatial location\n",
    "            true_ts = true_data[:, i, j]\n",
    "            pred_ts = pred_data[:, i, j]\n",
    "            \n",
    "            # Filter out NaN values\n",
    "            valid_mask = ~(np.isnan(true_ts) | np.isnan(pred_ts))\n",
    "            true_ts_valid = true_ts[valid_mask]\n",
    "            pred_ts_valid = pred_ts[valid_mask]\n",
    "            \n",
    "            if len(true_ts_valid) < 2 or np.var(true_ts_valid) == 0:\n",
    "                r2_map[i, j] = np.nan\n",
    "            else:\n",
    "                r2_map[i, j] = r2_score(true_ts_valid, pred_ts_valid)\n",
    "    \n",
    "    return r2_map\n",
    "\n",
    "def create_discrete_colormap_and_norm(data, cmap_name, n_levels=10, percentile_range=(5, 95)):\n",
    "    \"\"\"\n",
    "    Create discrete colormap and normalization based on data distribution.\n",
    "    \n",
    "    Args:\n",
    "        data: Input data array\n",
    "        cmap_name: Name of the colormap\n",
    "        n_levels: Number of discrete levels\n",
    "        percentile_range: Tuple of (low, high) percentiles for range\n",
    "    \n",
    "    Returns:\n",
    "        cmap, norm, levels\n",
    "    \"\"\"\n",
    "    # Get data range based on percentiles\n",
    "    vmin, vmax = np.nanpercentile(data, percentile_range)\n",
    "    \n",
    "    # Create discrete levels\n",
    "    levels = np.linspace(vmin, vmax, n_levels + 1)\n",
    "    \n",
    "    # Create discrete colormap and normalization\n",
    "    cmap = plt.cm.get_cmap(cmap_name, n_levels)\n",
    "    norm = BoundaryNorm(levels, ncolors=cmap.N, clip=True)\n",
    "    \n",
    "    return cmap, norm, levels\n",
    "\n",
    "def plot_r2_and_uncertainty_maps(eval_dataset, figsize=(12, 6), dpi=300, save_path=\"figures/\", \n",
    "                                 n_levels_r2=10, n_levels_unc=10):\n",
    "\n",
    "    plt.style.use('default')  \n",
    "    \n",
    "    plt.rcParams.update({\n",
    "        'font.size': 11,\n",
    "        'font.family': 'sans-serif',\n",
    "        'axes.linewidth': 1.2,\n",
    "        'axes.spines.top': True,\n",
    "        'axes.spines.right': True,\n",
    "        'axes.spines.bottom': True,\n",
    "        'axes.spines.left': True,\n",
    "        'axes.grid': False,\n",
    "        'xtick.direction': 'in',\n",
    "        'ytick.direction': 'in',\n",
    "        'xtick.major.size': 4,\n",
    "        'ytick.major.size': 4,\n",
    "        'legend.frameon': True,\n",
    "        'legend.fancybox': False,\n",
    "        'legend.shadow': False,\n",
    "        'legend.edgecolor': 'black',\n",
    "        'savefig.dpi': dpi,\n",
    "        'savefig.bbox': 'tight',\n",
    "        'savefig.pad_inches': 0.1\n",
    "    })\n",
    "    \n",
    "\n",
    "    # Extract the data \n",
    "    ubm_true = eval_dataset['ubm_truth'].values\n",
    "    ubm_pred = eval_dataset['ubm_pred_mean'].values\n",
    "    \n",
    "    # Calculate R^2 map\n",
    "    ubm_r2_map = calculate_spatial_r2(ubm_true, ubm_pred)\n",
    "    ubm_r2_map = np.clip(ubm_r2_map, -1.0, 1.0)\n",
    "    \n",
    "    # Uncertainty calculation\n",
    "    # Extract ensemble predictions\n",
    "    ubm_ensemble = eval_dataset['ubm_pred_samples'].values\n",
    "\n",
    "    # Calculate std for each sample\n",
    "    ubm_ensemble_std_per_sample = np.std(ubm_ensemble, axis=1)  # Shape: (n_test_samples, H, W)\n",
    "    \n",
    "    # Geometric mean via log-space averaging\n",
    "    ubm_uncertainty = np.exp(np.mean(np.log(ubm_ensemble_std_per_sample + 1e-8), axis=0))  # Shape: (H, W)\n",
    "    \n",
    "    # Create discrete colormaps and normalizations\n",
    "    r2_cmap, r2_norm, r2_levels = create_discrete_colormap_and_norm(\n",
    "        ubm_r2_map, 'RdYlBu_r', n_levels_r2, (5, 95)\n",
    "    )\n",
    "    \n",
    "    unc_cmap, unc_norm, unc_levels = create_discrete_colormap_and_norm(\n",
    "        ubm_uncertainty, 'plasma', n_levels_unc, (5, 95)\n",
    "    )\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize, facecolor='white')\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    # Set up distance ticks\n",
    "    size = 80\n",
    "    tick_positions = np.linspace(0, size-1, 9)\n",
    "    tick_positions = np.round(tick_positions).astype(int)\n",
    "    km_ticks = tick_positions * 1.5  \n",
    "    \n",
    "    x_labels = []\n",
    "    y_labels = []\n",
    "    for i, km in enumerate(km_ticks):\n",
    "        if i % 2 == 0: \n",
    "            x_labels.append(f'{km:.0f}')\n",
    "            y_labels.append(f'{km:.0f}')\n",
    "        else:\n",
    "            x_labels.append('')\n",
    "            y_labels.append('')\n",
    "    \n",
    "    # First column\n",
    "    im1 = axes[0].imshow(ubm_r2_map, cmap=r2_cmap, norm=r2_norm, \n",
    "                          origin='lower', interpolation='bilinear')\n",
    "    \n",
    "    # Format axis with distance ticks \n",
    "    axes[0].set_xticks(tick_positions)\n",
    "    axes[0].set_yticks(tick_positions)\n",
    "    axes[0].set_xticklabels(x_labels)\n",
    "    axes[0].set_yticklabels(y_labels)\n",
    "    axes[0].tick_params(axis='both', which='major', length=7, width=1.5, labelsize=14)\n",
    "    axes[0].set_xlabel('Distance (km)', fontsize=18)\n",
    "    axes[0].set_ylabel('Distance (km)', fontsize=18)\n",
    "    axes[0].text(0.5, 1.05, '(a)', transform=axes[0].transAxes, \n",
    "             fontsize=26, fontweight='bold', ha='center', va='bottom')\n",
    "    \n",
    "    for spine in axes[0].spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_color('black')\n",
    "        spine.set_linewidth(1.2)\n",
    "    axes[0].grid(False)\n",
    "    \n",
    "    # Add discrete colorbar \n",
    "    cbar1 = fig.colorbar(im1, ax=axes[0], shrink=0.62, aspect=20, extend='both', \n",
    "                         boundaries=r2_levels, ticks=r2_levels)\n",
    "    cbar1.set_label(r'$R^2$', rotation=270, labelpad=25, fontsize=20)\n",
    "    cbar1.ax.tick_params(labelsize=14)\n",
    "    \n",
    "    # Format colorbar ticks\n",
    "    if np.max(np.abs(r2_levels)) < 1e-2:  # Use scientific notation\n",
    "        cbar1.ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:.2e}'))\n",
    "    else:\n",
    "        cbar1.ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:.2f}'))\n",
    "    \n",
    "    # Second column: Uncertainty plot with discrete colorbar\n",
    "    im2 = axes[1].imshow(ubm_uncertainty, cmap=unc_cmap, norm=unc_norm, \n",
    "                          origin='lower', interpolation='bilinear')\n",
    "    \n",
    "    # Format axis with distance ticks\n",
    "    axes[1].set_xticks(tick_positions)\n",
    "    axes[1].set_yticks(tick_positions)\n",
    "    axes[1].set_xticklabels(x_labels)\n",
    "    axes[1].set_yticklabels(y_labels)\n",
    "    axes[1].tick_params(axis='both', which='major', length=7, width=1.5, labelsize=14)\n",
    "    axes[1].set_xlabel('Distance (km)', fontsize=18)\n",
    "    axes[1].set_ylabel('Distance (km)', fontsize=18)\n",
    "    axes[1].text(0.5, 1.05, '(b)', transform=axes[1].transAxes,\n",
    "             fontsize=26, fontweight='bold', ha='center', va='bottom')\n",
    "    \n",
    "    for spine in axes[1].spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_color('black')\n",
    "        spine.set_linewidth(1.2)\n",
    "    axes[1].grid(False)\n",
    "    \n",
    "    # Add discrete colorbar for uncertainty\n",
    "    cbar2 = fig.colorbar(im2, ax=axes[1], shrink=0.62, aspect=20, extend='both',\n",
    "                         boundaries=unc_levels, ticks=unc_levels)\n",
    "    cbar2.set_label(r'$\\sigma_{geo}$', rotation=270, labelpad=30, fontsize=22)\n",
    "    cbar2.ax.tick_params(labelsize=14)\n",
    "    \n",
    "    # Format uncertainty colorbar ticks\n",
    "    cbar2.ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:.2e}'))\n",
    "    \n",
    "    # Adjust layout with proper spacing\n",
    "    plt.tight_layout(pad=2.0, w_pad=3.0, h_pad=3.0)\n",
    "    \n",
    "    # Save figure\n",
    "    if save_path:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        full_path = os.path.join(save_path, 'performance_maps.png')\n",
    "        plt.savefig(full_path, dpi=dpi, bbox_inches='tight', \n",
    "                   facecolor='white', edgecolor='none')\n",
    "        print(f\"Figure saved to: {full_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig, ubm_r2_map, ubm_uncertainty\n",
    "\n",
    "\n",
    "fig, ubm_r2_map, ubm_uncertainty = plot_r2_and_uncertainty_maps(\n",
    "    eval_datasets['sst_ssh'], \n",
    "    figsize=(12, 6), \n",
    "    dpi=300,\n",
    "    save_path='figures/SI',\n",
    "    n_levels_r2=10,      \n",
    "    n_levels_unc=10    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4ea72-8abe-425e-ba69-3526db21f702",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3 PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "977ad975-86f2-489a-a67d-27ff44ef954b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSDs for best sample #3041...\n",
      "Computing PSDs for median sample #519...\n",
      "Computing PSDs for worst sample #3323...\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import xarray as xr\n",
    "import xrft\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module='xrft')\n",
    "\n",
    "def get_sample_psd_data(sample_idx, eval_data):\n",
    "    \"\"\"Get PSD data for a specific sample using ensemble mean PSDs\"\"\"\n",
    "    # Get data for the sample\n",
    "    ubm_true = eval_data.ubm_truth.isel(sample=sample_idx).values\n",
    "    bm_true = eval_data.bm_truth.isel(sample=sample_idx).values\n",
    "    \n",
    "    # Get ensemble data\n",
    "    ubm_ensemble = eval_data.ubm_pred_samples.isel(sample=sample_idx).values\n",
    "    bm_ensemble = eval_data.bm_pred_samples.isel(sample=sample_idx).values\n",
    "    \n",
    "    # Calculate PSDs for truth\n",
    "    psd_ubm_true = calculate_psd_km(ubm_true)\n",
    "    psd_bm_true = calculate_psd_km(bm_true)\n",
    "    \n",
    "    # Calculate ensemble PSDs\n",
    "    ubm_ensemble_psds = []\n",
    "    bm_ensemble_psds = []\n",
    "    \n",
    "    for ens in range(30):\n",
    "        if not np.all(np.isnan(ubm_ensemble[ens, :, :])):\n",
    "            ubm_psd = calculate_psd_km(ubm_ensemble[ens, :, :])\n",
    "            ubm_ensemble_psds.append(ubm_psd.values)\n",
    "            \n",
    "        if not np.all(np.isnan(bm_ensemble[ens, :, :])):\n",
    "            bm_psd = calculate_psd_km(bm_ensemble[ens, :, :])\n",
    "            bm_ensemble_psds.append(bm_psd.values)\n",
    "    \n",
    "    # Calculate envelope bounds (no mean needed)\n",
    "    ubm_ensemble_psds = np.array(ubm_ensemble_psds)\n",
    "    bm_ensemble_psds = np.array(bm_ensemble_psds)\n",
    "    \n",
    "    ubm_psd_05 = np.nanpercentile(ubm_ensemble_psds, 5, axis=0)\n",
    "    ubm_psd_95 = np.nanpercentile(ubm_ensemble_psds, 95, axis=0)\n",
    "    bm_psd_05 = np.nanpercentile(bm_ensemble_psds, 5, axis=0)\n",
    "    bm_psd_95 = np.nanpercentile(bm_ensemble_psds, 95, axis=0)\n",
    "    \n",
    "    return {\n",
    "        'freq': psd_ubm_true.freq_r.values,\n",
    "        'ubm_true': psd_ubm_true.values,\n",
    "        'bm_true': psd_bm_true.values,\n",
    "        'ubm_05': ubm_psd_05,\n",
    "        'ubm_95': ubm_psd_95,\n",
    "        'bm_05': bm_psd_05,\n",
    "        'bm_95': bm_psd_95\n",
    "    }\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['Arial', 'DejaVu Sans', 'Helvetica', 'sans-serif'],\n",
    "    'mathtext.fontset': 'stix',  \n",
    "    'axes.grid': False,\n",
    "    'figure.facecolor': 'white',\n",
    "    'axes.facecolor': 'white', \n",
    "    'text.usetex': False,\n",
    "})\n",
    "\n",
    "\n",
    "sample_types = ['best', 'median', 'worst']\n",
    "sample_keys = ['max', 'median', 'min']\n",
    "sample_indices = []\n",
    "\n",
    "for sample_key in sample_keys:\n",
    "    sample_idx = extreme_samples['sst_ssh'][sample_key]['sample_idx']\n",
    "    sample_indices.append(sample_idx)\n",
    "\n",
    "\n",
    "# Load the ZCA+SST evaluation dataset\n",
    "sst_ssh_data = eval_datasets['sst_ssh']\n",
    "\n",
    "# Create figure with 1x3 subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "colors = {\n",
    "    'ubm_true': '#d62728',      # Red\n",
    "    'bm_true': '#1f77b4',       # Blue\n",
    "    'ubm_envelope': '#ff7f0e',  # Orange\n",
    "    'bm_envelope': '#2ca02c',   # Green\n",
    "}\n",
    "\n",
    "# Per-panel R^2 for UBM prediction (best, median, worst)\n",
    "r2_vals = [0.9127, 0.0866, -6.2663]\n",
    "\n",
    "# Loop through each sample and create plots\n",
    "for i, (sample_idx, sample_type) in enumerate(zip(sample_indices, sample_types)):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Get PSD data for this sample\n",
    "    print(f\"Computing PSDs for {sample_type} sample #{sample_idx}...\")\n",
    "    psd_data = get_sample_psd_data(sample_idx, sst_ssh_data)\n",
    "    \n",
    "    # Plot true values (solid lines)\n",
    "    ax.loglog(psd_data['freq'], psd_data['ubm_true'], \n",
    "             color=colors['ubm_true'], linewidth=3.5, label='UBM True')\n",
    "    ax.loglog(psd_data['freq'], psd_data['bm_true'], \n",
    "             color=colors['bm_true'], linewidth=3.5, label='BM True')\n",
    "    \n",
    "    # Add uncertainty envelopes (no mean lines)\n",
    "    ax.fill_between(psd_data['freq'], psd_data['ubm_05'], psd_data['ubm_95'], \n",
    "                    alpha=0.6, color=colors['ubm_envelope'], label='UBM 90% CI', \n",
    "                    edgecolor='none')\n",
    "    ax.fill_between(psd_data['freq'], psd_data['bm_05'], psd_data['bm_95'], \n",
    "                    alpha=0.6, color=colors['bm_envelope'], label='BM 90% CI', \n",
    "                    edgecolor='none')\n",
    "    \n",
    "    # Customize plot appearance\n",
    "    ax.set_xlim(8e-3, 5e-1)\n",
    "    ax.set_ylim(1e-12, 1e1)\n",
    "    \n",
    "    # Set custom tick locations for y-axis\n",
    "    y_ticks_labeled = [10**j for j in range(-10, 1, 2)]\n",
    "    ax.yaxis.set_major_locator(ticker.FixedLocator(y_ticks_labeled))\n",
    "    ax.yaxis.set_major_formatter(ticker.LogFormatterMathtext())\n",
    "    \n",
    "    # Professional tick styling\n",
    "    ax.tick_params(axis='both', which='major', labelsize=22, length=8, \n",
    "                   width=1.5, direction='in') \n",
    "    ax.tick_params(axis='both', which='minor', length=4, \n",
    "                   width=0.8, direction='in')\n",
    "\n",
    "    # Hide y-axis labels for middle and right subplots\n",
    "    if i > 0:\n",
    "        ax.tick_params(axis='y', labelleft=False)\n",
    "\n",
    "    # Panel labels\n",
    "    letters = ['a', 'b', 'c']\n",
    "    ax.text(0.02, 0.98, f'{letters[i]})', transform=ax.transAxes, \n",
    "            fontsize=24, fontweight='bold', va='top', ha='left')\n",
    "    \n",
    "    # X-axis label for all subplots\n",
    "    ax.set_xlabel(r'Wavenumber (cpkm)', fontsize=24, fontweight='normal')\n",
    "\n",
    "    # Y-label only on leftmost subplot\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(r'PSD (m$^2$ cpkm$^{-1}$)', fontsize=24, fontweight='normal')\n",
    "    \n",
    "    # Annotation inside each panel (top-right corner)\n",
    "    ax.text(\n",
    "        0.98, 0.95, f\"R$^2$ (UBM pred) = {r2_vals[i]:.4f}\",\n",
    "        transform=ax.transAxes, ha='right', va='top',\n",
    "        fontsize=18\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(\n",
    "    handles, labels,\n",
    "    loc='lower center', bbox_to_anchor=(0.5, -0.15),\n",
    "    ncol=4, frameon=False, fontsize=22, columnspacing=2.5\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.2) \n",
    "plt.show()\n",
    "\n",
    "plt.savefig('/home/jovyan/GRL_ssh/figures/SI/3_psd.png', \n",
    "            bbox_inches='tight', dpi=300, facecolor='white', \n",
    "            edgecolor='none', format='png')\n",
    "plt.savefig('/home/jovyan/GRL_ssh/figures/SI/3_psd.pdf', \n",
    "            bbox_inches='tight', facecolor='white', \n",
    "            edgecolor='none', format='pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eab1a7-a1a1-4904-be44-61cfe8dcd96d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
