{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f73b9994-d2e1-41fe-aaee-07d7f139cfcf",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858e238c-3336-4532-84b3-998ec097d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from unet import *\n",
    "from train import *\n",
    "from loss import *\n",
    "\n",
    "base_path = \"gs://leap-persistent/YueWang/SSH/data\"\n",
    "\n",
    "def open_zarr(path):\n",
    "    return xr.open_zarr(path, consolidated=True)\n",
    "\n",
    "train = open_zarr(f\"{base_path}/train_80_sst.zarr\").compute()\n",
    "val = open_zarr(f\"{base_path}/val_80_sst.zarr\").compute()\n",
    "zca = open_zarr(f\"{base_path}/zca_80_sst.zarr\").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c1c780-b5d2-4667-92f2-4645c22d50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(tensor, min_values=None, max_values=None, feature_range=(0, 1)):\n",
    "\n",
    "    num_channels = tensor.shape[1]\n",
    "    \n",
    "    if min_values is None:\n",
    "        min_values = torch.zeros(num_channels, device=tensor.device)\n",
    "        for c in range(num_channels):\n",
    "            min_values[c] = tensor[:, c, :, :].min()\n",
    "    \n",
    "    if max_values is None:\n",
    "        max_values = torch.zeros(num_channels, device=tensor.device)\n",
    "        for c in range(num_channels):\n",
    "            max_values[c] = tensor[:, c, :, :].max()\n",
    "    \n",
    "    normalized_tensor = torch.zeros_like(tensor)\n",
    "    scale = (feature_range[1] - feature_range[0])\n",
    "    \n",
    "    # Normalize each channel independently\n",
    "    for c in range(num_channels):\n",
    "        channel_range = max_values[c] - min_values[c]\n",
    "        \n",
    "        # Handle edge case where min and max are the same\n",
    "        if channel_range == 0:\n",
    "            normalized_tensor[:, c, :, :] = feature_range[0]\n",
    "        else:\n",
    "            # Apply min-max formula: (x - min) / (max - min) * scale + min_range\n",
    "            normalized_tensor[:, c, :, :] = (\n",
    "                (tensor[:, c, :, :] - min_values[c]) / channel_range\n",
    "            ) * scale + feature_range[0]\n",
    "    \n",
    "    return normalized_tensor, min_values, max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "927b5d79-a48d-4ce0-88c7-9744d909c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Prepare training data\n",
    "x_train_channel_0 = torch.from_numpy(train.ssh.values).float().unsqueeze(1).to(device)\n",
    "x_train_channel_1 = torch.from_numpy(train.sst.values).float().unsqueeze(1).to(device)\n",
    "x_train = torch.cat([x_train_channel_0, x_train_channel_1], dim=1)\n",
    "x_train_normalized, min_values, max_values = min_max_normalize(x_train)\n",
    "\n",
    "y_train_channel_0 = torch.from_numpy(train.ubm.values).float().unsqueeze(1).to(device)\n",
    "y_train_channel_1 = torch.from_numpy(train.zca_ubm.values).float().unsqueeze(1).to(device)\n",
    "y_train = torch.cat([y_train_channel_0, y_train_channel_1], dim=1)\n",
    "\n",
    "\n",
    "# Prepare validation data \n",
    "x_val_channel_0 = torch.from_numpy(val.ssh.values).float().unsqueeze(1).to(device)\n",
    "x_val_channel_1 = torch.from_numpy(val.sst.values).float().unsqueeze(1).to(device)\n",
    "x_val = torch.cat([x_val_channel_0, x_val_channel_1], dim=1)\n",
    "x_val_normalized, _, _ = min_max_normalize(x_val, min_values=min_values, max_values=max_values)\n",
    "\n",
    "y_val_channel_0 = torch.from_numpy(val.ubm.values).float().unsqueeze(1).to(device)\n",
    "y_val_channel_1 = torch.from_numpy(val.zca_ubm.values).float().unsqueeze(1).to(device)  \n",
    "y_val = torch.cat([y_val_channel_0, y_val_channel_1], dim=1)  \n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(x_train_normalized, y_train)\n",
    "val_dataset = TensorDataset(x_val_normalized, y_val)\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "Vt = torch.from_numpy(zca.zca_Vt_ubm.values).float().to(device)\n",
    "scale = torch.from_numpy(zca.zca_scale_ubm.values).float().to(device)\n",
    "mean = torch.from_numpy(zca.zca_mean_ubm.values).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20388e9-fe72-46ad-b9ad-56d79ce36828",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc2209e8-1b02-4892-8039-25d81c196df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 3.88e-01 (ZCA-NLL: 3.88e-01, MSE-Phys: 1.04e-04, Grad-Phys: 2.44e-04), Val Loss: 2.31e+00, Epoch Time: 123.69s\n",
      "Best model so far saved at epoch 1 (Val Loss: 2.312e+00)\n",
      "Epoch 2, Train Loss: 1.23e-01 (ZCA-NLL: 1.23e-01, MSE-Phys: 1.33e-04, Grad-Phys: 2.15e-04), Val Loss: 1.87e+00, Epoch Time: 123.70s\n",
      "Best model so far saved at epoch 2 (Val Loss: 1.866e+00)\n",
      "Epoch 3, Train Loss: -1.45e-01 (ZCA-NLL: -1.45e-01, MSE-Phys: 9.89e-05, Grad-Phys: 1.67e-04), Val Loss: 1.81e+00, Epoch Time: 123.76s\n",
      "Best model so far saved at epoch 3 (Val Loss: 1.814e+00)\n",
      "Epoch 4, Train Loss: -1.94e-01 (ZCA-NLL: -1.94e-01, MSE-Phys: 9.65e-05, Grad-Phys: 1.64e-04), Val Loss: 1.81e+00, Epoch Time: 123.86s\n",
      "Best model so far saved at epoch 4 (Val Loss: 1.809e+00)\n",
      "Epoch 5, Train Loss: -2.18e-01 (ZCA-NLL: -2.18e-01, MSE-Phys: 8.86e-05, Grad-Phys: 1.53e-04), Val Loss: 1.71e+00, Epoch Time: 123.62s\n",
      "Best model so far saved at epoch 5 (Val Loss: 1.713e+00)\n",
      "Epoch 6, Train Loss: -2.35e-01 (ZCA-NLL: -2.35e-01, MSE-Phys: 7.80e-05, Grad-Phys: 1.37e-04), Val Loss: 1.63e+00, Epoch Time: 123.74s\n",
      "Best model so far saved at epoch 6 (Val Loss: 1.630e+00)\n",
      "Epoch 7, Train Loss: -2.47e-01 (ZCA-NLL: -2.47e-01, MSE-Phys: 7.29e-05, Grad-Phys: 1.29e-04), Val Loss: 1.62e+00, Epoch Time: 123.81s\n",
      "Best model so far saved at epoch 7 (Val Loss: 1.623e+00)\n",
      "Epoch 8, Train Loss: -2.56e-01 (ZCA-NLL: -2.56e-01, MSE-Phys: 7.20e-05, Grad-Phys: 1.27e-04), Val Loss: 1.62e+00, Epoch Time: 123.56s\n",
      "Best model so far saved at epoch 8 (Val Loss: 1.616e+00)\n",
      "Epoch 9, Train Loss: -2.62e-01 (ZCA-NLL: -2.62e-01, MSE-Phys: 6.98e-05, Grad-Phys: 1.24e-04), Val Loss: 1.57e+00, Epoch Time: 123.75s\n",
      "Best model so far saved at epoch 9 (Val Loss: 1.571e+00)\n",
      "Epoch 10, Train Loss: -2.70e-01 (ZCA-NLL: -2.70e-01, MSE-Phys: 6.82e-05, Grad-Phys: 1.22e-04), Val Loss: 1.53e+00, Epoch Time: 123.90s\n",
      "Best model so far saved at epoch 10 (Val Loss: 1.534e+00)\n",
      "Epoch 11, Train Loss: -2.74e-01 (ZCA-NLL: -2.74e-01, MSE-Phys: 6.63e-05, Grad-Phys: 1.20e-04), Val Loss: 1.56e+00, Epoch Time: 123.71s\n",
      "Patience counter: 1/50\n",
      "Epoch 12, Train Loss: -2.79e-01 (ZCA-NLL: -2.79e-01, MSE-Phys: 6.49e-05, Grad-Phys: 1.17e-04), Val Loss: 1.69e+00, Epoch Time: 123.74s\n",
      "Patience counter: 2/50\n",
      "Epoch 13, Train Loss: -2.83e-01 (ZCA-NLL: -2.83e-01, MSE-Phys: 6.32e-05, Grad-Phys: 1.15e-04), Val Loss: 1.54e+00, Epoch Time: 123.80s\n",
      "Patience counter: 3/50\n",
      "Epoch 14, Train Loss: -2.86e-01 (ZCA-NLL: -2.86e-01, MSE-Phys: 6.17e-05, Grad-Phys: 1.13e-04), Val Loss: 1.56e+00, Epoch Time: 123.60s\n",
      "Patience counter: 4/50\n",
      "Epoch 15, Train Loss: -2.91e-01 (ZCA-NLL: -2.91e-01, MSE-Phys: 5.94e-05, Grad-Phys: 1.10e-04), Val Loss: 1.58e+00, Epoch Time: 123.73s\n",
      "Patience counter: 5/50\n",
      "Epoch 16, Train Loss: -2.94e-01 (ZCA-NLL: -2.94e-01, MSE-Phys: 5.84e-05, Grad-Phys: 1.09e-04), Val Loss: 1.53e+00, Epoch Time: 123.81s\n",
      "Patience counter: 6/50\n",
      "Epoch 17, Train Loss: -3.04e-01 (ZCA-NLL: -3.04e-01, MSE-Phys: 5.37e-05, Grad-Phys: 1.03e-04), Val Loss: 1.49e+00, Epoch Time: 123.85s\n",
      "Best model so far saved at epoch 17 (Val Loss: 1.492e+00)\n",
      "Epoch 18, Train Loss: -3.06e-01 (ZCA-NLL: -3.06e-01, MSE-Phys: 5.28e-05, Grad-Phys: 1.02e-04), Val Loss: 1.50e+00, Epoch Time: 123.88s\n",
      "Patience counter: 1/50\n",
      "Epoch 19, Train Loss: -3.08e-01 (ZCA-NLL: -3.08e-01, MSE-Phys: 5.23e-05, Grad-Phys: 1.01e-04), Val Loss: 1.50e+00, Epoch Time: 123.90s\n",
      "Patience counter: 2/50\n",
      "Epoch 20, Train Loss: -3.10e-01 (ZCA-NLL: -3.10e-01, MSE-Phys: 5.19e-05, Grad-Phys: 1.01e-04), Val Loss: 1.52e+00, Epoch Time: 123.79s\n",
      "Patience counter: 3/50\n",
      "Epoch 21, Train Loss: -3.12e-01 (ZCA-NLL: -3.12e-01, MSE-Phys: 5.11e-05, Grad-Phys: 9.97e-05), Val Loss: 1.50e+00, Epoch Time: 123.85s\n",
      "Patience counter: 4/50\n",
      "Epoch 22, Train Loss: -3.13e-01 (ZCA-NLL: -3.13e-01, MSE-Phys: 5.03e-05, Grad-Phys: 9.86e-05), Val Loss: 1.52e+00, Epoch Time: 123.92s\n",
      "Patience counter: 5/50\n",
      "Epoch 23, Train Loss: -3.16e-01 (ZCA-NLL: -3.16e-01, MSE-Phys: 5.00e-05, Grad-Phys: 9.79e-05), Val Loss: 1.49e+00, Epoch Time: 124.01s\n",
      "Patience counter: 6/50\n",
      "Epoch 24, Train Loss: -3.20e-01 (ZCA-NLL: -3.20e-01, MSE-Phys: 4.79e-05, Grad-Phys: 9.55e-05), Val Loss: 1.50e+00, Epoch Time: 123.84s\n",
      "Patience counter: 7/50\n",
      "Epoch 25, Train Loss: -3.21e-01 (ZCA-NLL: -3.21e-01, MSE-Phys: 4.77e-05, Grad-Phys: 9.50e-05), Val Loss: 1.51e+00, Epoch Time: 123.81s\n",
      "Patience counter: 8/50\n",
      "Epoch 26, Train Loss: -3.23e-01 (ZCA-NLL: -3.23e-01, MSE-Phys: 4.72e-05, Grad-Phys: 9.43e-05), Val Loss: 1.50e+00, Epoch Time: 123.82s\n",
      "Patience counter: 9/50\n",
      "Epoch 27, Train Loss: -3.23e-01 (ZCA-NLL: -3.23e-01, MSE-Phys: 4.73e-05, Grad-Phys: 9.41e-05), Val Loss: 1.50e+00, Epoch Time: 123.91s\n",
      "Patience counter: 10/50\n",
      "Epoch 28, Train Loss: -3.24e-01 (ZCA-NLL: -3.24e-01, MSE-Phys: 4.68e-05, Grad-Phys: 9.35e-05), Val Loss: 1.51e+00, Epoch Time: 123.90s\n",
      "Patience counter: 11/50\n",
      "Epoch 29, Train Loss: -3.25e-01 (ZCA-NLL: -3.25e-01, MSE-Phys: 4.65e-05, Grad-Phys: 9.29e-05), Val Loss: 1.48e+00, Epoch Time: 123.85s\n",
      "Best model so far saved at epoch 29 (Val Loss: 1.479e+00)\n",
      "Epoch 30, Train Loss: -3.26e-01 (ZCA-NLL: -3.26e-01, MSE-Phys: 4.60e-05, Grad-Phys: 9.23e-05), Val Loss: 1.49e+00, Epoch Time: 123.78s\n",
      "Patience counter: 1/50\n",
      "Epoch 31, Train Loss: -3.27e-01 (ZCA-NLL: -3.27e-01, MSE-Phys: 4.59e-05, Grad-Phys: 9.19e-05), Val Loss: 1.49e+00, Epoch Time: 123.92s\n",
      "Patience counter: 2/50\n",
      "Epoch 32, Train Loss: -3.28e-01 (ZCA-NLL: -3.28e-01, MSE-Phys: 4.55e-05, Grad-Phys: 9.13e-05), Val Loss: 1.50e+00, Epoch Time: 123.97s\n",
      "Patience counter: 3/50\n",
      "Epoch 33, Train Loss: -3.28e-01 (ZCA-NLL: -3.28e-01, MSE-Phys: 4.53e-05, Grad-Phys: 9.09e-05), Val Loss: 1.49e+00, Epoch Time: 123.97s\n",
      "Patience counter: 4/50\n",
      "Epoch 34, Train Loss: -3.30e-01 (ZCA-NLL: -3.30e-01, MSE-Phys: 4.49e-05, Grad-Phys: 9.02e-05), Val Loss: 1.48e+00, Epoch Time: 123.72s\n",
      "Patience counter: 5/50\n",
      "Epoch 35, Train Loss: -3.30e-01 (ZCA-NLL: -3.30e-01, MSE-Phys: 4.47e-05, Grad-Phys: 8.99e-05), Val Loss: 1.49e+00, Epoch Time: 123.73s\n",
      "Patience counter: 6/50\n",
      "Epoch 36, Train Loss: -3.33e-01 (ZCA-NLL: -3.33e-01, MSE-Phys: 4.37e-05, Grad-Phys: 8.86e-05), Val Loss: 1.50e+00, Epoch Time: 123.78s\n",
      "Patience counter: 7/50\n",
      "Epoch 37, Train Loss: -3.33e-01 (ZCA-NLL: -3.33e-01, MSE-Phys: 4.35e-05, Grad-Phys: 8.83e-05), Val Loss: 1.50e+00, Epoch Time: 123.84s\n",
      "Patience counter: 8/50\n",
      "Epoch 38, Train Loss: -3.34e-01 (ZCA-NLL: -3.34e-01, MSE-Phys: 4.33e-05, Grad-Phys: 8.79e-05), Val Loss: 1.48e+00, Epoch Time: 123.88s\n",
      "Patience counter: 9/50\n",
      "Epoch 39, Train Loss: -3.34e-01 (ZCA-NLL: -3.34e-01, MSE-Phys: 4.34e-05, Grad-Phys: 8.79e-05), Val Loss: 1.49e+00, Epoch Time: 123.87s\n",
      "Patience counter: 10/50\n",
      "Epoch 40, Train Loss: -3.35e-01 (ZCA-NLL: -3.35e-01, MSE-Phys: 4.30e-05, Grad-Phys: 8.75e-05), Val Loss: 1.47e+00, Epoch Time: 123.91s\n",
      "Best model so far saved at epoch 40 (Val Loss: 1.472e+00)\n",
      "Epoch 41, Train Loss: -3.35e-01 (ZCA-NLL: -3.35e-01, MSE-Phys: 4.28e-05, Grad-Phys: 8.71e-05), Val Loss: 1.48e+00, Epoch Time: 123.93s\n",
      "Patience counter: 1/50\n",
      "Epoch 42, Train Loss: -3.35e-01 (ZCA-NLL: -3.35e-01, MSE-Phys: 4.25e-05, Grad-Phys: 8.69e-05), Val Loss: 1.48e+00, Epoch Time: 123.94s\n",
      "Patience counter: 2/50\n",
      "Epoch 43, Train Loss: -3.36e-01 (ZCA-NLL: -3.36e-01, MSE-Phys: 4.25e-05, Grad-Phys: 8.68e-05), Val Loss: 1.48e+00, Epoch Time: 123.97s\n",
      "Patience counter: 3/50\n",
      "Epoch 44, Train Loss: -3.37e-01 (ZCA-NLL: -3.37e-01, MSE-Phys: 4.23e-05, Grad-Phys: 8.65e-05), Val Loss: 1.49e+00, Epoch Time: 123.95s\n",
      "Patience counter: 4/50\n",
      "Epoch 45, Train Loss: -3.36e-01 (ZCA-NLL: -3.36e-01, MSE-Phys: 4.29e-05, Grad-Phys: 8.70e-05), Val Loss: 1.48e+00, Epoch Time: 123.88s\n",
      "Patience counter: 5/50\n",
      "Epoch 46, Train Loss: -3.37e-01 (ZCA-NLL: -3.37e-01, MSE-Phys: 4.17e-05, Grad-Phys: 8.59e-05), Val Loss: 1.49e+00, Epoch Time: 123.99s\n",
      "Patience counter: 6/50\n",
      "Epoch 47, Train Loss: -3.38e-01 (ZCA-NLL: -3.38e-01, MSE-Phys: 4.13e-05, Grad-Phys: 8.53e-05), Val Loss: 1.49e+00, Epoch Time: 123.97s\n",
      "Patience counter: 7/50\n",
      "Epoch 48, Train Loss: -3.39e-01 (ZCA-NLL: -3.39e-01, MSE-Phys: 4.12e-05, Grad-Phys: 8.51e-05), Val Loss: 1.48e+00, Epoch Time: 123.95s\n",
      "Patience counter: 8/50\n",
      "Epoch 49, Train Loss: -3.39e-01 (ZCA-NLL: -3.39e-01, MSE-Phys: 4.11e-05, Grad-Phys: 8.49e-05), Val Loss: 1.49e+00, Epoch Time: 123.68s\n",
      "Patience counter: 9/50\n",
      "Epoch 50, Train Loss: -3.39e-01 (ZCA-NLL: -3.39e-01, MSE-Phys: 4.10e-05, Grad-Phys: 8.48e-05), Val Loss: 1.48e+00, Epoch Time: 123.85s\n",
      "Patience counter: 10/50\n",
      "Epoch 51, Train Loss: -3.39e-01 (ZCA-NLL: -3.39e-01, MSE-Phys: 4.10e-05, Grad-Phys: 8.47e-05), Val Loss: 1.49e+00, Epoch Time: 123.90s\n",
      "Patience counter: 11/50\n",
      "Epoch 52, Train Loss: -3.40e-01 (ZCA-NLL: -3.40e-01, MSE-Phys: 4.09e-05, Grad-Phys: 8.46e-05), Val Loss: 1.49e+00, Epoch Time: 123.94s\n",
      "Patience counter: 12/50\n",
      "Epoch 53, Train Loss: -3.40e-01 (ZCA-NLL: -3.40e-01, MSE-Phys: 4.05e-05, Grad-Phys: 8.42e-05), Val Loss: 1.48e+00, Epoch Time: 123.96s\n",
      "Patience counter: 13/50\n",
      "Epoch 54, Train Loss: -3.41e-01 (ZCA-NLL: -3.41e-01, MSE-Phys: 4.06e-05, Grad-Phys: 8.41e-05), Val Loss: 1.49e+00, Epoch Time: 124.02s\n",
      "Patience counter: 14/50\n",
      "Epoch 55, Train Loss: -3.41e-01 (ZCA-NLL: -3.41e-01, MSE-Phys: 4.06e-05, Grad-Phys: 8.42e-05), Val Loss: 1.49e+00, Epoch Time: 124.16s\n",
      "Patience counter: 15/50\n",
      "Epoch 56, Train Loss: -3.41e-01 (ZCA-NLL: -3.41e-01, MSE-Phys: 4.05e-05, Grad-Phys: 8.42e-05), Val Loss: 1.49e+00, Epoch Time: 123.83s\n",
      "Patience counter: 16/50\n",
      "Epoch 57, Train Loss: -3.41e-01 (ZCA-NLL: -3.41e-01, MSE-Phys: 4.04e-05, Grad-Phys: 8.40e-05), Val Loss: 1.49e+00, Epoch Time: 123.75s\n",
      "Patience counter: 17/50\n",
      "Epoch 58, Train Loss: -3.41e-01 (ZCA-NLL: -3.41e-01, MSE-Phys: 4.04e-05, Grad-Phys: 8.40e-05), Val Loss: 1.48e+00, Epoch Time: 123.91s\n",
      "Patience counter: 18/50\n",
      "Epoch 59, Train Loss: -3.41e-01 (ZCA-NLL: -3.41e-01, MSE-Phys: 4.03e-05, Grad-Phys: 8.39e-05), Val Loss: 1.49e+00, Epoch Time: 124.08s\n",
      "Patience counter: 19/50\n",
      "Epoch 60, Train Loss: -3.41e-01 (ZCA-NLL: -3.41e-01, MSE-Phys: 4.02e-05, Grad-Phys: 8.37e-05), Val Loss: 1.49e+00, Epoch Time: 123.87s\n",
      "Patience counter: 20/50\n",
      "Epoch 61, Train Loss: -3.41e-01 (ZCA-NLL: -3.41e-01, MSE-Phys: 4.03e-05, Grad-Phys: 8.39e-05), Val Loss: 1.49e+00, Epoch Time: 123.90s\n",
      "Patience counter: 21/50\n",
      "Epoch 62, Train Loss: -3.41e-01 (ZCA-NLL: -3.41e-01, MSE-Phys: 4.04e-05, Grad-Phys: 8.39e-05), Val Loss: 1.49e+00, Epoch Time: 123.89s\n",
      "Patience counter: 22/50\n",
      "Epoch 63, Train Loss: -3.41e-01 (ZCA-NLL: -3.41e-01, MSE-Phys: 4.02e-05, Grad-Phys: 8.37e-05), Val Loss: 1.49e+00, Epoch Time: 123.91s\n",
      "Patience counter: 23/50\n",
      "Epoch 64, Train Loss: -3.41e-01 (ZCA-NLL: -3.41e-01, MSE-Phys: 4.00e-05, Grad-Phys: 8.35e-05), Val Loss: 1.49e+00, Epoch Time: 123.88s\n",
      "Patience counter: 24/50\n",
      "Epoch 65, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 4.00e-05, Grad-Phys: 8.35e-05), Val Loss: 1.49e+00, Epoch Time: 123.91s\n",
      "Patience counter: 25/50\n",
      "Epoch 66, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 4.01e-05, Grad-Phys: 8.36e-05), Val Loss: 1.48e+00, Epoch Time: 123.93s\n",
      "Patience counter: 26/50\n",
      "Epoch 67, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 4.01e-05, Grad-Phys: 8.37e-05), Val Loss: 1.49e+00, Epoch Time: 123.97s\n",
      "Patience counter: 27/50\n",
      "Epoch 68, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 4.01e-05, Grad-Phys: 8.36e-05), Val Loss: 1.49e+00, Epoch Time: 123.87s\n",
      "Patience counter: 28/50\n",
      "Epoch 69, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 4.02e-05, Grad-Phys: 8.37e-05), Val Loss: 1.48e+00, Epoch Time: 123.86s\n",
      "Patience counter: 29/50\n",
      "Epoch 70, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 3.99e-05, Grad-Phys: 8.34e-05), Val Loss: 1.49e+00, Epoch Time: 123.85s\n",
      "Patience counter: 30/50\n",
      "Epoch 71, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 4.00e-05, Grad-Phys: 8.34e-05), Val Loss: 1.49e+00, Epoch Time: 123.84s\n",
      "Patience counter: 31/50\n",
      "Epoch 72, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 4.00e-05, Grad-Phys: 8.34e-05), Val Loss: 1.49e+00, Epoch Time: 123.82s\n",
      "Patience counter: 32/50\n",
      "Epoch 73, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 4.00e-05, Grad-Phys: 8.34e-05), Val Loss: 1.49e+00, Epoch Time: 123.87s\n",
      "Patience counter: 33/50\n",
      "Epoch 74, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 3.99e-05, Grad-Phys: 8.34e-05), Val Loss: 1.49e+00, Epoch Time: 123.85s\n",
      "Patience counter: 34/50\n",
      "Epoch 75, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 3.99e-05, Grad-Phys: 8.34e-05), Val Loss: 1.49e+00, Epoch Time: 123.75s\n",
      "Patience counter: 35/50\n",
      "Epoch 76, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 3.99e-05, Grad-Phys: 8.34e-05), Val Loss: 1.49e+00, Epoch Time: 123.88s\n",
      "Patience counter: 36/50\n",
      "Epoch 77, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 4.01e-05, Grad-Phys: 8.35e-05), Val Loss: 1.49e+00, Epoch Time: 123.79s\n",
      "Patience counter: 37/50\n",
      "Epoch 78, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 3.99e-05, Grad-Phys: 8.33e-05), Val Loss: 1.49e+00, Epoch Time: 123.72s\n",
      "Patience counter: 38/50\n",
      "Epoch 79, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 3.99e-05, Grad-Phys: 8.33e-05), Val Loss: 1.49e+00, Epoch Time: 123.74s\n",
      "Patience counter: 39/50\n",
      "Epoch 80, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 3.99e-05, Grad-Phys: 8.34e-05), Val Loss: 1.48e+00, Epoch Time: 123.64s\n",
      "Patience counter: 40/50\n",
      "Epoch 81, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 3.99e-05, Grad-Phys: 8.33e-05), Val Loss: 1.49e+00, Epoch Time: 123.46s\n",
      "Patience counter: 41/50\n",
      "Epoch 82, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 3.99e-05, Grad-Phys: 8.33e-05), Val Loss: 1.49e+00, Epoch Time: 123.67s\n",
      "Patience counter: 42/50\n",
      "Epoch 83, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 4.00e-05, Grad-Phys: 8.34e-05), Val Loss: 1.49e+00, Epoch Time: 123.70s\n",
      "Patience counter: 43/50\n",
      "Epoch 84, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 3.98e-05, Grad-Phys: 8.32e-05), Val Loss: 1.48e+00, Epoch Time: 123.52s\n",
      "Patience counter: 44/50\n",
      "Epoch 85, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 3.99e-05, Grad-Phys: 8.33e-05), Val Loss: 1.49e+00, Epoch Time: 123.70s\n",
      "Patience counter: 45/50\n",
      "Epoch 86, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 4.00e-05, Grad-Phys: 8.35e-05), Val Loss: 1.49e+00, Epoch Time: 123.62s\n",
      "Patience counter: 46/50\n",
      "Epoch 87, Train Loss: -2.03e-01 (ZCA-NLL: -2.03e-01, MSE-Phys: 3.99e-05, Grad-Phys: 8.33e-05), Val Loss: 1.49e+00, Epoch Time: 123.68s\n",
      "Patience counter: 47/50\n",
      "Epoch 88, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 3.99e-05, Grad-Phys: 8.33e-05), Val Loss: 1.49e+00, Epoch Time: 123.70s\n",
      "Patience counter: 48/50\n",
      "Epoch 89, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 3.99e-05, Grad-Phys: 8.33e-05), Val Loss: 1.48e+00, Epoch Time: 123.67s\n",
      "Patience counter: 49/50\n",
      "Epoch 90, Train Loss: -3.42e-01 (ZCA-NLL: -3.42e-01, MSE-Phys: 3.97e-05, Grad-Phys: 8.32e-05), Val Loss: 1.49e+00, Epoch Time: 123.92s\n",
      "Patience counter: 50/50\n",
      "Early stopping triggered.\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n",
    "# Create model and optimizer\n",
    "model = UNet(in_channels=2, out_channels=2, initial_features=32, depth=4)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "train_model(model, train_loader, val_loader,\n",
    "            Vt, scale, mean,  \n",
    "            optimizer, device,\n",
    "            grad_loss_weight=0.0,      # Weight for gradient loss in physical space\n",
    "            mse_loss_weight=0.0,       # Weight for MSE loss in physical space  \n",
    "            zca_nll_weight=1.0,        # Weight for ZCA Gaussian NLL loss\n",
    "            save_path='/home/jovyan/grl_final/checkpoints/zca_sst.pth',\n",
    "            n_epochs=2000,\n",
    "            patience=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
